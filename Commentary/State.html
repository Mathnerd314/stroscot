<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Imperative programming &mdash; Stroscot  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/hexagon_favicon.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Syntax" href="Syntax.html" />
    <link rel="prev" title="Sets" href="Sets.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html">
            <img src="../_static/hexagon_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/index.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../HowTo/index.html">How to</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Reference/index.html">Language Reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Commentary</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Assembly.html">Assembly</a></li>
<li class="toctree-l2"><a class="reference internal" href="BuildSystem.html">Build system</a></li>
<li class="toctree-l2"><a class="reference internal" href="Code-Generation.html">Code generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Compiler.html">Compiler design</a></li>
<li class="toctree-l2"><a class="reference internal" href="CoreSyntax.html">Core syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="Evaluation-Strategy.html">Evaluation strategy</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exceptions.html">Exceptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="F2G2_example.html">F2 G2</a></li>
<li class="toctree-l2"><a class="reference internal" href="Fastest.html">As fast as C</a></li>
<li class="toctree-l2"><a class="reference internal" href="Fexprs.html">Macros</a></li>
<li class="toctree-l2"><a class="reference internal" href="Library.html">Library</a></li>
<li class="toctree-l2"><a class="reference internal" href="Logic.html">Logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="Memory-Management.html">Memory management</a></li>
<li class="toctree-l2"><a class="reference internal" href="Meta.html">About</a></li>
<li class="toctree-l2"><a class="reference internal" href="Modules.html">Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="Objects.html">Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="PackageManager.html">Package manager</a></li>
<li class="toctree-l2"><a class="reference internal" href="Programs.html">Exemplary programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction.html">Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction-Example.html">Reduction example</a></li>
<li class="toctree-l2"><a class="reference internal" href="Sets.html">Sets</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Imperative programming</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#purity">Purity</a></li>
<li class="toctree-l3"><a class="reference internal" href="#state">State</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tasks">Tasks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#continuations">Continuations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#vs-monads">vs Monads</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vs-yoneda">vs Yoneda</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vs-multi-prompt-delimited-continuations">vs multi-prompt delimited continuations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vs-world-token">vs world token</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vs-algebraic-effects">vs algebraic effects</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vs-call-by-push-value">vs Call by push value</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vs-applicative">vs Applicative</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#unsafe-i-o">“Unsafe” I/O</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concurrency">Concurrency</a></li>
<li class="toctree-l3"><a class="reference internal" href="#simulation">Simulation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parallelism">Parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="#os-model">OS Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Syntax.html">Syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="TermRewriting.html">Term rewriting</a></li>
<li class="toctree-l2"><a class="reference internal" href="Verification.html">Verification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../zzreferences.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Stroscot</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Commentary</a> &raquo;</li>
      <li>Imperative programming</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/Mathnerd314/stroscot/edit/master/docs/Commentary/State.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="imperative-programming">
<h1>Imperative programming<a class="headerlink" href="#imperative-programming" title="Permalink to this headline"></a></h1>
<section id="purity">
<h2>Purity<a class="headerlink" href="#purity" title="Permalink to this headline"></a></h2>
<p><span id="id1">[<a class="reference internal" href="../zzreferences.html#id79" title="Nicholas Pippenger. Pure versus impure Lisp. ACM Transactions on Programming Languages and Systems, 19(2):223–238, March 1997. URL: https://dl.acm.org/doi/10.1145/244795.244798 (visited on 2022-01-06), doi:10.1145/244795.244798.">Pip97</a>]</span> compares a pure CBV Lisp to one extended with mutation operators. He presents a problem, an O(n) impure solution, and a pure O(n log n) solution that simulates the impure one with a balanced binary tree. But the key result of the paper is that a pure algorithm in his system will require O(n log n) time. His proof is a combinatorial argument based on the small number of Lisp operations. <span id="id2">[<a class="reference internal" href="../zzreferences.html#id13" title="Richard Bird, Geraint Jones, and Oege De Moor. More haste, less speed: lazy versus eager evaluation. Journal of Functional Programming, 7(5):541–547, September 1997. URL: https://www.cambridge.org/core/journals/journal-of-functional-programming/article/more-haste-less-speed-lazy-versus-eager-evaluation/162B391CBCD864794C766CA2A2EC7CBE (visited on 2022-01-06), doi:10.1017/S0956796897002827.">BJM97</a>]</span> demonstrate that Haskell can solve the problem in amortized O(n) time, via the use of infinite lazy streams. <span id="id3">[<a class="reference internal" href="../zzreferences.html#id11" title="Amir M. Ben-amram. Notes on Pippenger's Comparison of Pure and Impure LISP. 1996.">Benamram96</a>]</span> says (without proof) that any problem of the form read-update-write similarly has an efficient lazy stream implemention. This seems to encompass all Haskell 1.0 programs as they use lazy streams for I/O. Generally it seems the thunk update mechanism is powerful enough to simulate imperative programming, it just requires mind-bending contortions to program efficiently as one has to pass around a large self-referential partially evaluated data/control structure. But nobody has formally proved this.</p>
<p>Another way around Pippinger’s proof is to provide an O(1) pure “array update” operation. The naive implementation of pure array update copies the array (O(n) update) or maintains a tree structure (O(log n) access time). But <span id="id4">[<a class="reference internal" href="../zzreferences.html#id48" title="Paul Hudak and Adrienne Bloss. The aggregate update problem in functional programming systems. In Proceedings of the 12th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages - POPL '85, 300–314. New Orleans, Louisiana, United States, 1985. ACM Press. URL: http://portal.acm.org/citation.cfm?doid=318593.318660 (visited on 2022-01-04), doi:10.1145/318593.318660.">HB85</a>]</span> shows that the compiler can search through possible evaluation orders for an evaluation order that never accesses the old version of an array after updating, and transform the program to use O(1) destructive update (“automatic destructive update”). This works for the class of “single-threaded” FP programs, which include all the “natural translations” of imperative programs. Some of <span id="id5">[<a class="reference internal" href="../zzreferences.html#id76" title="Chris Okasaki. Purely Functional Data Structures. Cambridge University Press, Cambridge, U.K. ; New York, 1998. ISBN 978-0-521-63124-2.">Oka98</a>]</span>’s data structures can only be used single-threaded as well. Roc seems to be going down this route. For non-single-threaded FP, there is a log(log(n)) lower bound on persistent arrays <span id="id6">[<a class="reference internal" href="../zzreferences.html#id95" title="missing journal in strakaFullyPersistentArrays">Str</a>]</span>, which applies to both lazy and impure programs. So if we use automatic destructive update with a fallback to the log(log(n)) arrays we’ve gotten the best possible asymptotic performance.</p>
<p>Haskell avoided automatic destructive update because it seemed too complicated, and instead relies on monads. Monadic style guarantees single threading, hence matching the performance of imperative languages. Ocaml does something similar by allowing programs with side effects.</p>
<p>Similarly Clean has uniqueness types, but this disallows a simple example of implementing id in terms of const:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">id</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">const</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="n">x</span><span class="w"></span>
<span class="nf">const</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">x</span><span class="w"></span>

<span class="nf">a</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">array</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span><span class="w"></span>
<span class="nf">b</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">id</span><span class="w"> </span><span class="n">a</span><span class="w"></span>
<span class="nf">b</span><span class="w"> </span><span class="o">!!</span><span class="w"> </span><span class="mi">10</span><span class="w"></span>
</pre></div>
</div>
<p>What’s slow are certain kinds of operations. E.g. dynamic lookups, weak typing, variant types. See examples of what makes PHP slow in this <a class="reference external" href="https://www.youtube.com/watch?v=p5S1K60mhQU">video</a>. In some cases you can replace these operations with faster ones (specialization). JIT has more information and can specialize based on the observed values. Profile-guided ahead of time optimization can do the same thing but with the JIT the profiling is built in and you don’t have to do a separate build.</p>
<p>Also speed isn’t why people use languages.</p>
</section>
<section id="state">
<h2>State<a class="headerlink" href="#state" title="Permalink to this headline"></a></h2>
<p>Stroscot sees all programs as functional manipulations of immutable values. So a state or snapshot is a value. Conceptually a state could include a lot of things, including the state of the CPU, details of other running threads, the stock market, quantum fluctuations, etc. - all as long as it is within the chronological past. But since we are running on hardware we only care about the hardware’s state, and since the hardware is all digital it is deterministic and expressible as a long binary string.</p>
<p>This dump would include the kernel and I/O devices and other processes not related to ours. If we assume we are running as a user process then we can limit ourselves to the process state. Conveniently the CRIU project has a <a class="reference external" href="https://criu.org/Images">list of what’s in the state of a process</a>: file descriptors, memory mappings and contents, network state, etc.</p>
<p>What operations are there on this state? Well, it’s a data structure, so we can read all we like. We can load the state with CRIU, step it forward a bit, and save it again. But we might run into syscalls. So stepping can either return another state, or call a syscall. Furthermore there are multiple threads in the process - so we could stop when the first thread hits a syscall, or when all of them do. Also we can return from sycalls, this is a well-documented calling convention.</p>
<p>So practically, the state can be represented by the next syscall, together with the state reached after returning from that syscall, if the syscall returns (the continuation).</p>
</section>
<section id="tasks">
<span id="id7"></span><h2>Tasks<a class="headerlink" href="#tasks" title="Permalink to this headline"></a></h2>
<p>Tasks are a direct approach to I/O - sequences of I/O operations are values of type <code class="docutils literal notranslate"><span class="pre">Task</span></code>, similar to a <a class="reference external" href="https://www.reddit.com/r/haskell/comments/swffy/why_do_we_not_define_io_as_a_free_monad/">free monad</a>. Statements that don’t return are directly of the Task type, like <code class="docutils literal notranslate"><span class="pre">Exit</span> <span class="pre">{</span> <span class="pre">code</span> <span class="pre">:</span> <span class="pre">Int}</span></code>. Statements that continue in a sequential fashion have a <code class="docutils literal notranslate"><span class="pre">continuation</span></code> argument, like <code class="docutils literal notranslate"><span class="pre">Print</span> <span class="pre">{</span> <span class="pre">s</span> <span class="pre">:</span> <span class="pre">String,</span> <span class="pre">continuation</span> <span class="pre">:</span> <span class="pre">Task</span> <span class="pre">}</span></code>, so are of type <code class="docutils literal notranslate"><span class="pre">Command</span> <span class="pre">=</span> <span class="pre">Task</span> <span class="pre">-&gt;</span> <span class="pre">Task</span></code>. Statements that return a value use a continuation of type <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">-&gt;</span> <span class="pre">Task</span></code>, e.g. <code class="docutils literal notranslate"><span class="pre">ReadFile</span> <span class="pre">{</span> <span class="pre">path</span> <span class="pre">:</span> <span class="pre">Fd,</span> <span class="pre">continuation</span> <span class="pre">:</span> <span class="pre">String</span> <span class="pre">-&gt;</span> <span class="pre">Task}</span></code>, so are of type <code class="docutils literal notranslate"><span class="pre">Operation</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">(a</span> <span class="pre">-&gt;</span> <span class="pre">Task)</span> <span class="pre">-&gt;</span> <span class="pre">Task</span></code>. And since tasks are values we can also use them as arguments, like the <code class="docutils literal notranslate"><span class="pre">delayed_task</span></code> in <code class="docutils literal notranslate"><span class="pre">SetTimeout</span> <span class="pre">{</span> <span class="pre">delay</span> <span class="pre">:</span> <span class="pre">Int,</span> <span class="pre">delayed_task</span> <span class="pre">:</span> <span class="pre">Task,</span> <span class="pre">continuation</span> <span class="pre">:</span> <span class="pre">Task}</span></code>.</p>
<p>To see how I/O works, consider printing hello world: <code class="docutils literal notranslate"><span class="pre">print</span> <span class="pre">&quot;Hi&quot;</span></code>. As a task this looks like <code class="docutils literal notranslate"><span class="pre">Print</span> <span class="pre">&quot;Hi&quot;</span> <span class="pre">exit</span></code>, where <code class="docutils literal notranslate"><span class="pre">exit</span></code> is what happens after (the continuation). The operation is <code class="docutils literal notranslate"><span class="pre">print</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">\cont</span> <span class="pre">-&gt;</span> <span class="pre">Print</span> <span class="pre">a</span> <span class="pre">cont</span></code>. With the continuation as the last argument we can just use the partially-applied function, <code class="docutils literal notranslate"><span class="pre">print</span> <span class="pre">=</span> <span class="pre">Print</span></code>. <code class="docutils literal notranslate"><span class="pre">print</span> <span class="pre">a</span> <span class="pre">&gt;&gt;</span> <span class="pre">print</span> <span class="pre">b</span> <span class="pre">=</span> <span class="pre">\cont</span> <span class="pre">-&gt;</span> <span class="pre">Print</span> <span class="pre">a</span> <span class="pre">(Print</span> <span class="pre">b</span> <span class="pre">cont)</span></code>. Now consider <code class="docutils literal notranslate"><span class="pre">read</span> <span class="pre">ref</span> <span class="pre">&gt;&gt;=</span> <span class="pre">print</span></code>. The operation is <code class="docutils literal notranslate"><span class="pre">Read</span> <span class="pre">ref</span> <span class="pre">&gt;&gt;=</span> <span class="pre">Print</span></code> where <code class="docutils literal notranslate"><span class="pre">&gt;&gt;=</span></code> is the continuation monad’s bind operation, which expands to <code class="docutils literal notranslate"><span class="pre">\cont</span> <span class="pre">-&gt;</span> <span class="pre">Read</span> <span class="pre">ref</span> <span class="pre">(\v</span> <span class="pre">-&gt;</span> <span class="pre">Print</span> <span class="pre">v</span> <span class="pre">cont)</span></code>.</p>
<p>So conceptually the “Hello World” program is simply the value <code class="docutils literal notranslate"><span class="pre">Print</span> <span class="pre">&quot;Hello</span> <span class="pre">World&quot;</span> <span class="pre">(Exit</span> <span class="pre">0)</span></code>. Except print isn’t a primitive operation, it’s more like:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="kt">Data</span><span class="w"> </span><span class="s">&quot;Hello, world!</span><span class="se">\n</span><span class="s">&quot;</span><span class="w"> </span><span class="p">(</span><span class="nf">\</span><span class="n">msg</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"></span>
<span class="w">  </span><span class="kt">Block</span><span class="w"> </span><span class="s">&quot;_start&quot;</span><span class="w"> </span><span class="p">[</span><span class="kt">Sys_write</span><span class="w"> </span><span class="n">stdout</span><span class="w"> </span><span class="p">(</span><span class="n">addr</span><span class="w"> </span><span class="n">msg</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="n">length</span><span class="w"> </span><span class="n">msg</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="kt">Sys_exit</span><span class="w"> </span><span class="mi">0</span><span class="p">)])</span><span class="w"></span>
</pre></div>
</div>
<p>with Stroscot’s internal assembler language.</p>
<p>Task isn’t really a monad, but we can compose operations that return values using the continuation monad’s bind operation, as implemented with do-notation.</p>
<p>The datatype is similar to the “fudgets” mentioned in <span id="id8">[<a class="reference internal" href="../zzreferences.html#id35" title="Levent Erkok. Value Recursion in Monadic Computations. PhD thesis, Oregon Health and Science University, October 2002. URL: http://leventerkok.github.io/papers/erkok-thesis.pdf.">Erk02</a>]</span>, except we don’t have a pure constructor. Or <a class="reference external" href="http://comonad.com/reader/2011/free-monads-for-less-3/">this</a> type <code class="docutils literal notranslate"><span class="pre">FFI</span> <span class="pre">o</span> <span class="pre">i</span></code>, but with control flow represented explicitly instead of using <code class="docutils literal notranslate"><span class="pre">o</span></code> or <code class="docutils literal notranslate"><span class="pre">i</span></code> parameters.</p>
</section>
<section id="continuations">
<h2>Continuations<a class="headerlink" href="#continuations" title="Permalink to this headline"></a></h2>
<p>Stroscot use continuations for its I/O model because continuations are simple and universal. They’re the supercharged typed equivalent of a goto. A continuation is a function that takes as argument “the rest of the program”, or “its future”. Executing a continuation fills in a skeleton program with this future - or it can discard the future if it is not relevant. The implementation can compile continuations to jumps under most circumstances and closures otherwise, so the execution model is also conceptually simple.</p>
<p>Continuations are the basis in formal denotational semantics for all control flow, from goto statements to exception handling, subsuming vanilla call flow, recursion, generators, coroutines,
backtracking, and even loops along the way. This allows a uniform and consistent interface.</p>
<section id="vs-monads">
<h3>vs Monads<a class="headerlink" href="#vs-monads" title="Permalink to this headline"></a></h3>
<p>Continuations are <a class="reference external" href="http://blog.sigfpe.com/2008/12/mother-of-all-monads.html">the mother of all monads</a> as all other monads can be embedded in the continuation type via <code class="docutils literal notranslate"><span class="pre">m</span> <span class="pre">&gt;&gt;=</span></code> and retrieved via <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">return</span></code>. In particular the Codensity monad <code class="docutils literal notranslate"><span class="pre">Codensity</span> <span class="pre">m</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">forall</span> <span class="pre">b.</span> <span class="pre">(a</span> <span class="pre">-&gt;</span> <span class="pre">m</span> <span class="pre">b)</span> <span class="pre">-&gt;</span> <span class="pre">m</span> <span class="pre">b</span></code> is a monad regardless of <code class="docutils literal notranslate"><span class="pre">m</span></code>. (<a class="reference external" href="http://blog.sigfpe.com/2008/12/mother-of-all-monads.html#c3279179532869319461">See comment</a>) Without the forall, callcc is implementable and the type is too large, see <span id="id9">[<a class="reference internal" href="../zzreferences.html#id101" title="Philip Wadler. The essence of functional programming. In Proceedings of the 19th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages - POPL '92, 1–14. Albuquerque, New Mexico, United States, 1992. ACM Press. URL: http://portal.acm.org/citation.cfm?doid=143165.143169 (visited on 2021-11-22), doi:10.1145/143165.143169.">Wad92</a>]</span> section 3.4 for an example.</p>
<p>Using the <code class="docutils literal notranslate"><span class="pre">Codensity</span> <span class="pre">monad</span></code> instead of a monad stack is often faster - the case analysis is pushed to the monad’s operations, and there is no pile-up of binds. It converts the computation to continuation-passing style. In particular free tree-like monads <span id="id10">[<a class="reference internal" href="../zzreferences.html#id99" title="Janis Voigtländer. Asymptotic Improvement of Computations over Free Monads. In Philippe Audebaud and Christine Paulin-Mohring, editors, Mathematics of Program Construction, volume 5133, pages 388–403. Springer Berlin Heidelberg, Berlin, Heidelberg, 2008. URL: https://www.janis-voigtlaender.eu/papers/AsymptoticImprovementOfComputationsOverFreeMonads.pdf (visited on 2021-07-09), doi:10.1007/978-3-540-70594-9_20.">Voi08</a>]</span> and <a class="reference external" href="http://r6.ca/blog/20071028T162529Z.html">MTL monad stacks</a> are much cheaper when implemented via Codensity. As a contrary point, in the <a class="reference external" href="https://www.mail-archive.com/haskell-cafe&#64;haskell.org/msg66512.html">case</a> of the Maybe monad an ADT version seemed to be faster than a Church encoding. Unfortunately hpaste is defunct so the code can’t be analyzed further. It’s not clear if the “CPS” mentioned is similar to Codensity.</p>
</section>
<section id="vs-yoneda">
<h3>vs Yoneda<a class="headerlink" href="#vs-yoneda" title="Permalink to this headline"></a></h3>
<p><a class="reference external" href="http://comonad.com/reader/2011/free-monads-for-less-2/">Kmett</a> says to use <code class="docutils literal notranslate"><span class="pre">Yoneda</span> <span class="pre">(Rec</span> <span class="pre">f)</span></code>, i.e. <code class="docutils literal notranslate"><span class="pre">newtype</span> <span class="pre">F</span> <span class="pre">f</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">F</span> <span class="pre">{</span> <span class="pre">runF</span> <span class="pre">::</span> <span class="pre">forall</span> <span class="pre">r.</span> <span class="pre">(a</span> <span class="pre">-&gt;</span> <span class="pre">r)</span> <span class="pre">-&gt;</span> <span class="pre">(f</span> <span class="pre">r</span> <span class="pre">-&gt;</span> <span class="pre">r)</span> <span class="pre">-&gt;</span> <span class="pre">r</span> <span class="pre">}</span></code>, instead of <code class="docutils literal notranslate"><span class="pre">Codensity</span> <span class="pre">f</span> <span class="pre">a</span></code>. The claim is that this type is “smaller” than Codensity in the sense that the inhabitants of <code class="docutils literal notranslate"><span class="pre">F</span></code> are in a one-to-one correspondence with those of <code class="docutils literal notranslate"><span class="pre">Free</span> <span class="pre">f</span> <span class="pre">a</span></code>. But what we are interested in is <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">a</span></code>; the recursive layering actually adds extra inhabitants as well, and there is also the <code class="docutils literal notranslate"><span class="pre">Pure</span></code> constructor that doesn’t make much sense for I/O. For example <code class="docutils literal notranslate"><span class="pre">F</span> <span class="pre">Identity</span> <span class="pre">()</span></code> is the type of Church numerals, while <code class="docutils literal notranslate"><span class="pre">Codensity</span> <span class="pre">Identity</span> <span class="pre">()</span> <span class="pre">=</span> <span class="pre">forall</span> <span class="pre">r.</span> <span class="pre">r</span> <span class="pre">-&gt;</span> <span class="pre">r</span> <span class="pre">=</span> <span class="pre">()</span> <span class="pre">=</span> <span class="pre">Identity</span> <span class="pre">()</span></code>. So in this case it is actually <code class="docutils literal notranslate"><span class="pre">F</span></code> that is larger.</p>
<p>Just looking at the types, F has more arrows. Similarly compare the instances:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="c1">-- F f</span><span class="w"></span>
<span class="nf">return</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">F</span><span class="w"> </span><span class="p">(</span><span class="nf">\</span><span class="n">kp</span><span class="w"> </span><span class="kr">_</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="n">kp</span><span class="w"> </span><span class="n">a</span><span class="p">)</span><span class="w"></span>
<span class="kt">F</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="o">&gt;&gt;=</span><span class="w"> </span><span class="n">f</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">F</span><span class="w"> </span><span class="p">(</span><span class="nf">\</span><span class="n">kp</span><span class="w"> </span><span class="n">kf</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="p">(</span><span class="nf">\</span><span class="n">a</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="n">runF</span><span class="w"> </span><span class="p">(</span><span class="n">f</span><span class="w"> </span><span class="n">a</span><span class="p">)</span><span class="w"> </span><span class="n">kp</span><span class="w"> </span><span class="n">kf</span><span class="p">)</span><span class="w"> </span><span class="n">kf</span><span class="p">)</span><span class="w"></span>

<span class="c1">-- C f</span><span class="w"></span>
<span class="nf">return</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">C</span><span class="w"> </span><span class="p">(</span><span class="nf">\</span><span class="n">k</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"></span>
<span class="nf">m</span><span class="w"> </span><span class="o">&gt;&gt;=</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">C</span><span class="w"> </span><span class="p">(</span><span class="nf">\</span><span class="n">c</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="n">runC</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="p">(</span><span class="nf">\</span><span class="n">a</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="n">runC</span><span class="w"> </span><span class="p">(</span><span class="n">k</span><span class="w"> </span><span class="n">a</span><span class="p">)</span><span class="w"> </span><span class="n">c</span><span class="p">))</span><span class="w"></span>
</pre></div>
</div>
<p>The instance for <code class="docutils literal notranslate"><span class="pre">C</span></code> is fewer characters.</p>
<p>Finally there is <span id="id11">[<a class="reference internal" href="../zzreferences.html#id82" title="missing journal in rivasNotionsComputationMonoids2014">RJ14</a>]</span> which derives the Codensity monad from the Yoneda lemma and the assumption that <code class="docutils literal notranslate"><span class="pre">f</span></code> is a small functor. Whereas the Yoneda-Rec seems to have no category theory behind it.</p>
<p>Generally it seems that the Yoneda thing solves a problem Stroscot doesn’t have.</p>
</section>
<section id="vs-multi-prompt-delimited-continuations">
<h3>vs multi-prompt delimited continuations<a class="headerlink" href="#vs-multi-prompt-delimited-continuations" title="Permalink to this headline"></a></h3>
<p>Multi-prompt delimited continuations are described in <span id="id12">[<a class="reference internal" href="../zzreferences.html#id31" title="R. Kent Dyvbig, Simon Peyton Jones, and Amr Sabry. A monadic framework for delimited continuations. Journal of Functional Programming, 17(6):687–730, November 2007. URL: https://doi.org/10.1017/S0956796807006259 (visited on 2020-06-19), doi:10.1017/S0956796807006259.">DPJS07</a>]</span> . These might appear more expressive than standard delimited continuations (the <code class="docutils literal notranslate"><span class="pre">(a</span> <span class="pre">-&gt;</span> <span class="pre">b)</span> <span class="pre">-&gt;</span> <span class="pre">b</span></code> type), but as the paper shows multi-prompt continuations can be implemented as a monad and hence as a library to use with the standard continuations. So the simplicity of the standard continuations wins out. With the multi-prompt continuations you have to have a unique supply and a stack. The unique supply complicates multithreading, and the stack can overflow and requires care to handle tail recursion. Whereas standard continuations translate to pure lambdas, and tail recursion is dealt with by the host language’s semantics.</p>
</section>
<section id="vs-world-token">
<h3>vs world token<a class="headerlink" href="#vs-world-token" title="Permalink to this headline"></a></h3>
<p>Haskell uses a state monad <code class="docutils literal notranslate"><span class="pre">IO</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">s</span> <span class="pre">-&gt;</span> <span class="pre">(#</span> <span class="pre">s,</span> <span class="pre">a</span> <span class="pre">#))</span></code> for implementing I/O, where <code class="docutils literal notranslate"><span class="pre">s</span> <span class="pre">=</span> <span class="pre">World</span></code> is a special zero-sized token type. Clean is similar but <code class="docutils literal notranslate"><span class="pre">s</span> <span class="pre">=</span> <span class="pre">*World</span></code> has the uniqueness type annotation so the state tokens cannot be forged. Regardless, this approach seems quite awkward. Programs like <code class="docutils literal notranslate"><span class="pre">(a,_)</span> <span class="pre">=</span> <span class="pre">getChar</span> <span class="pre">s;</span> <span class="pre">(b,s')</span> <span class="pre">=</span> <span class="pre">getChar</span> <span class="pre">s;</span> <span class="pre">putChar</span> <span class="pre">(a,b)</span> <span class="pre">s'</span></code> that reuse the world are broken and have to be forbidden. Ensuring this holds during core-to-core transformations requires many hacks. Also, an I/O operation is an abstract function which makes it quite difficult to inspect IO values or implement simulations of I/O such as <a class="reference external" href="https://hackage.haskell.org/package/pure-io-0.2.1/docs/PureIO.html">PureIO</a>.</p>
<p>With the task+continuation approach an I/O operation is data that can be pattern-matched over. It’s a little harder for the compiler to optimize that readIORef has no observable side effects, as it’s a reordering property (commutativity), but strict languages have been doing this for years.</p>
</section>
<section id="vs-algebraic-effects">
<h3>vs algebraic effects<a class="headerlink" href="#vs-algebraic-effects" title="Permalink to this headline"></a></h3>
<p>The two approaches are quite similar, both using a data type to represent operations. But continuations are much simpler syntactically than the handler functionality. In the effect approach computations are not first-class values.</p>
<p>OTOH effect types are quite useful, because you can define code that is polymorphic over the effect type, hence can be used as both pure and impure code. They use a monadic translation, I think with the lazy identity monad you can recover lazy pure code.</p>
</section>
<section id="vs-call-by-push-value">
<h3>vs Call by push value<a class="headerlink" href="#vs-call-by-push-value" title="Permalink to this headline"></a></h3>
<p>CBPV has “values” and “computations”. The original presentation has these as separate categories, but <span id="id13">[<a class="reference internal" href="../zzreferences.html#id32" title="J. Egger, R. E. Mogelberg, and A. Simpson. The enriched effect calculus: syntax and semantics. Journal of Logic and Computation, 24(3):615–654, June 2014. URL: https://academic.oup.com/logcom/article-lookup/doi/10.1093/logcom/exs025 (visited on 2021-11-09), doi:10.1093/logcom/exs025.">EMS14</a>]</span> presents an alternative calculus EC+ where every computation type is also a value type. There is exactly one primitive that sequences computation, <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">to</span> <span class="pre">x.</span> <span class="pre">N</span></code>, which acts like the monadic bind <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">&gt;&gt;=</span> <span class="pre">\x</span> <span class="pre">-&gt;</span> <span class="pre">N</span></code>, and similarly there is <code class="docutils literal notranslate"><span class="pre">return</span></code>. And the evaluation is CBV. So stripping away the thunk stuff it seems to be a disguised version of monads. And the thunk stuff is a rather fragile way to implement CBN - it doesn’t generalize to call by need. <span id="id14">[<a class="reference internal" href="../zzreferences.html#id70" title="Dylan McDermott and Alan Mycroft. Extended Call-by-Push-Value: Reasoning About Effectful Programs and Evaluation Order. In Luís Caires, editor, Programming Languages and Systems, volume 11423, pages 235–262. Springer International Publishing, Cham, 2019. URL: http://link.springer.com/10.1007/978-3-030-17184-1_9 (visited on 2021-11-09), doi:10.1007/978-3-030-17184-1_9.">MM19</a>]</span> And then there is jump-with-argument (JWA) which uses continuations and is equivalent to CBPV.</p>
</section>
<section id="vs-applicative">
<h3>vs Applicative<a class="headerlink" href="#vs-applicative" title="Permalink to this headline"></a></h3>
<p>Uses of Applicative can always be rewritten using the laws to be of the form <code class="docutils literal notranslate"><span class="pre">pure</span> <span class="pre">f</span> <span class="pre">&lt;*&gt;</span> <span class="pre">a</span> <span class="pre">&lt;*&gt;</span> <span class="pre">b</span> <span class="pre">...</span> <span class="pre">&lt;*&gt;</span> <span class="pre">d</span></code> (<code class="docutils literal notranslate"><span class="pre">&lt;*&gt;</span></code> is left associative). So the idiom bracket behavior is covered by variadic functions, <code class="docutils literal notranslate"><span class="pre">variadic</span> <span class="pre">f</span> <span class="pre">a</span> <span class="pre">b</span> <span class="pre">...</span> <span class="pre">d</span></code>.</p>
<p>The other way is to use the Cayley representation of Applicative, <code class="docutils literal notranslate"><span class="pre">Rep</span> <span class="pre">f</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">forall</span> <span class="pre">a.</span> <span class="pre">f</span> <span class="pre">a</span> <span class="pre">-&gt;</span> <span class="pre">f</span> <span class="pre">(b,a)</span></code>. <span id="id15">[<a class="reference internal" href="../zzreferences.html#id82" title="missing journal in rivasNotionsComputationMonoids2014">RJ14</a>]</span> This still has a Functor constraint so actually we work with <code class="docutils literal notranslate"><span class="pre">Rep</span> <span class="pre">(Yoneda</span> <span class="pre">f)</span> <span class="pre">a</span></code> for a typeclass-free representation. (<code class="docutils literal notranslate"><span class="pre">Yoneda</span> <span class="pre">f</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">forall</span> <span class="pre">b.</span> <span class="pre">(a</span> <span class="pre">-&gt;</span> <span class="pre">b)</span> <span class="pre">-&gt;</span> <span class="pre">f</span> <span class="pre">b</span></code>, see <cite>here &lt;https://fa.haskell.narkive.com/hUgYjfKJ/haskell-cafe-the-mother-of-all-functors-monads-categories#post3&gt;</cite>)</p>
</section>
</section>
<section id="unsafe-i-o">
<h2>“Unsafe” I/O<a class="headerlink" href="#unsafe-i-o" title="Permalink to this headline"></a></h2>
<p>Haskell also has <code class="docutils literal notranslate"><span class="pre">runST</span></code> and <code class="docutils literal notranslate"><span class="pre">unsafePerformIO</span></code> that allow turning impure computation into pure computations. These can still be implemented as special functions. <code class="docutils literal notranslate"><span class="pre">runST</span></code> scrutinizes its computation for impure behavior such as printing or returning allocated references, while <code class="docutils literal notranslate"><span class="pre">unsafePerformIO</span></code> does not and exposes the internal evaluation order.</p>
<p>If one wants to understand the evaluation order or is dealing with commutative operations, these functions are quite useful, e.g. Debug.Trace.trace looks like a non-I/O function but actually outputs something on the console, and allocation can be done in any order.</p>
</section>
<section id="concurrency">
<h2>Concurrency<a class="headerlink" href="#concurrency" title="Permalink to this headline"></a></h2>
<p>The general idea with concurrency is there are multiple threads of execution, each thread composed of (imperative) operations, and the combination of various operations may have various semantics. Normally we run in an OS thread and use a combination of hardware and OS operations. Working in the cloud, we still run in an OS thread, but the operations use the networking stack. In an embedded environment each thread is bound to a core.
We only get the possibility of deadlock when we use blocking operations. With wait-free / atomic operations we never need to block.</p>
<p>The smallest examples runtimewise just have memory access. For example this program SB: <span id="id16">[<a class="reference internal" href="../zzreferences.html#id83" title="Peter Sewell, Susmit Sarkar, Scott Owens, Francesco Zappa Nardelli, and Magnus O. Myreen. X86-TSO: a rigorous and usable programmer's model for x86 multiprocessors. Communications of the ACM, 53(7):89–97, July 2010. URL: https://dl.acm.org/doi/10.1145/1785414.1785443 (visited on 2021-07-09), doi:10.1145/1785414.1785443.">SSO+10</a>]</span></p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">x</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">mem</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>
<span class="nf">u</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">mem</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>
<span class="kt">A</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">mem</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>
<span class="kt">B</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">mem</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>
<span class="nf">t1</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">fork</span><span class="w"> </span><span class="p">{</span><span class="kt">A</span><span class="w"> </span><span class="kt">:=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="kt">:=</span><span class="w"> </span><span class="o">!</span><span class="p">(</span><span class="n">read</span><span class="w"> </span><span class="kt">B</span><span class="p">)</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="nf">t2</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">fork</span><span class="w"> </span><span class="p">{</span><span class="kt">B</span><span class="w"> </span><span class="kt">:=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">u</span><span class="w"> </span><span class="kt">:=</span><span class="w"> </span><span class="o">!</span><span class="p">(</span><span class="n">read</span><span class="w"> </span><span class="kt">A</span><span class="p">)</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="nf">join</span><span class="w"> </span><span class="p">(</span><span class="n">t1</span><span class="p">,</span><span class="w"> </span><span class="n">t2</span><span class="p">)</span><span class="w"></span>
<span class="nf">print</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="p">(</span><span class="n">read</span><span class="w"> </span><span class="n">x</span><span class="p">),</span><span class="w"> </span><span class="o">!</span><span class="p">(</span><span class="n">read</span><span class="w"> </span><span class="n">u</span><span class="p">))</span><span class="w"></span>
</pre></div>
</div>
<p>Here the threads are provided by the C stdlib’s pthreads, and the operations are hardware load/store instructions.
This program has a race condition - the outcome may be <code class="docutils literal notranslate"><span class="pre">(1,1)</span></code>, <code class="docutils literal notranslate"><span class="pre">(1,0)</span></code>, or <code class="docutils literal notranslate"><span class="pre">(0,1)</span></code> under sequential consistency. But under the relaxed memory model used by X86 (Total Store Order or TSO) <code class="docutils literal notranslate"><span class="pre">(0,0)</span></code> is also possible. But under any model values other than 0 or 1 are not possible.</p>
<p>Another example is independent reads of independent writes (IRIW):</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="n">a</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">X</span><span class="p">;</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">Y</span><span class="p">}</span><span class="w"></span>
<span class="p">{</span><span class="kt">X</span><span class="w"> </span><span class="kt">:=</span><span class="w"> </span><span class="mi">1</span><span class="p">}</span><span class="w"></span>
<span class="p">{</span><span class="kt">Y</span><span class="w"> </span><span class="kt">:=</span><span class="w"> </span><span class="mi">1</span><span class="p">}</span><span class="w"></span>
<span class="p">{</span><span class="n">c</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">Y</span><span class="p">;</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">X</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>Here the initial state is <code class="docutils literal notranslate"><span class="pre">(X,Y)=(0,0)</span></code>, and the final state can be <code class="docutils literal notranslate"><span class="pre">(a,b,c,d)=(1,0,1,0)</span></code> under POWER. But both ARMv8 and x86 forbid this outcome.</p>
</section>
<section id="simulation">
<h2>Simulation<a class="headerlink" href="#simulation" title="Permalink to this headline"></a></h2>
<p>On a low level, race conditions are fine and an expected part of concurrent programming. No undefined behavior here. But on a program level Stroscot simulates the program’s (concurrent) execution, and will give a warning if it’s not consistent.
The program is required to have the same result regardless of the order the tasks are run. This is checked by the verification system. Basically the simulation maintains a list of each thread and its top-level Task value. Each loop iteration takes some arbitrary non-zero number of arbitrarily-chosen tasks and runs their operations in parallel. The tasks operate on a shared state, so the semantics of satisfying the requests in parallel must be defined. We want to error when things clearly conflict.</p>
<p>Samples:</p>
<ul class="simple">
<li><p>Variable: Two writes with different values conflict. But if only one task writes the variable or all writes are equal then no conflict.</p></li>
<li><p>Mutex: Two acquires, mutex available, a winner is nondeterministically chosen to be scheduled. The loser is blocked on the mutex or scheduled in a failure branch if it was try_acquire. No mutex available, block.</p></li>
<li><p>Append-style file writing: Conflicts if same file descriptor</p></li>
<li><p>Exiting: conflicts with anything but an identical exit (clean exit requirement), or else no conflicts</p></li>
</ul>
<p>Etc. It’s a bit lengthy to simulate the entire task interface, but operations change infrequently, so it should be maintainable.</p>
<p>Acquiring a lock blocks until the lock is released. This introduces the problems of deadlock and starvation, which can be detected as the absence of progressing execution orders.</p>
<p>All of these generate happens-before relationships on the various operations. We could track this with vector clocks, IDK why - the posets are easier to reason about directly.</p>
<p>The verification system handles the nondeterminism somehow, check out papers on concurrency verification. The behavior of the OS scheduler is complicated and hard to abstract. The Linux scheduler might take an unreasonably long time to schedule you again even if every other thread is sleeping or calls yield(), handling other processes.</p>
<p>the relaxed-consistency model allows implementing private memory that is then mapped back to shared on synchronization</p>
</section>
<section id="parallelism">
<h2>Parallelism<a class="headerlink" href="#parallelism" title="Permalink to this headline"></a></h2>
<p>Parallelism - the root is “parallel” or “happening at the same time”. But with <a class="reference external" href="https://en.wikipedia.org/wiki/Relativity_of_simultaneity">relativity</a>, simultaneity is not absolute. We instead consider <a class="reference external" href="https://en.wikipedia.org/wiki/Causal_structure">causal structure</a> - event separation can be timelike or spacelike. Timelike separation communicates information from past to future, while no dependency is possible with spacelike separation. Hence we define an execution as a directed graph of information flow, where a node is a value and an edge is read “can casually influence” (we could also use the reverse “reads data from”). Assuming no time travel the graph is acyclic and its transitive closure forms a partial order or poset. Then things happen “in parallel” if neither causally influences the other.</p>
<p>For example, <a class="reference external" href="https://en.wikipedia.org/wiki/Matrix_multiplication_algorithm#Parallel_and_distributed_algorithms">multiplying</a> two 2x2 matrices:</p>
<img alt="../_images/matrix-multiply.svg" src="../_images/matrix-multiply.svg" /><p>The multiplications all happen in parallel and the additions in parallel.</p>
<p>There’s no explicit syntax for parallelism - pure computations have inherent parallelism. Writing it out looks like:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">multiply</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="ow">=</span><span class="w"></span>
<span class="w">  </span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">dim</span><span class="w"> </span><span class="n">a</span><span class="w"></span>
<span class="w">  </span><span class="p">(</span><span class="n">n&#39;</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">n&#39;</span><span class="p">,</span><span class="n">o</span><span class="p">)</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">dim</span><span class="w"> </span><span class="n">b</span><span class="w"></span>
<span class="w">  </span><span class="n">for</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="o">..</span><span class="n">m</span><span class="p">]</span><span class="w"> </span><span class="o">$</span><span class="w"> </span><span class="nf">\</span><span class="n">i</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"></span>
<span class="w">    </span><span class="n">for</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="o">..</span><span class="n">o</span><span class="p">]</span><span class="w"> </span><span class="o">$</span><span class="w"> </span><span class="nf">\</span><span class="n">j</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"></span>
<span class="w">      </span><span class="n">sum</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="o">!!</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">b</span><span class="w"> </span><span class="o">!!</span><span class="w"> </span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">j</span><span class="p">))</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">&lt;-</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="w"> </span><span class="o">..</span><span class="w"> </span><span class="n">n</span><span class="p">]</span><span class="w"> </span><span class="p">]</span><span class="w"></span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">for</span></code> and <code class="docutils literal notranslate"><span class="pre">sum</span></code> can evaluate arguments in parallel. More complicated is allowing functions, for example <code class="docutils literal notranslate"><span class="pre">foldMap</span> <span class="pre">f</span> <span class="pre">g</span> <span class="pre">(x:xs)</span> <span class="pre">=</span> <span class="pre">g</span> <span class="pre">(f</span> <span class="pre">x)</span> <span class="pre">(foldMap</span> <span class="pre">f</span> <span class="pre">g</span> <span class="pre">xs)</span></code> generates a DAG of f’s and g’s if the list spine is known. Even with general recursion it should still be possible to identify data dependencies and assign DAG cells to temporary values in some fashion. Conditionals are a little hard to schedule because you have to make sure both sides can be speculated or discard the untaken branch promptly.</p>
<p>Stroscot schedules the instructions to maximize instruction-level parallelism, where appropriate. This takes advantage of the design of modern CPUs, where there are multiple “ports” and each port can execute an instruction simultaneously.</p>
<p>With large (&gt;1000 width) matrices we might want to multiply sub-matrices on multiple threads (cores). That requires concurrency, so is handled by writing the synchronization operations explicitly.  Stroscot doesn’t parallelize on the thread level by default because automatically spawning threads would be surprising, and the choice of thread/scheduler/performance model (OpenMP, OS thread, green thread) influences what granularity to split up the computation at.</p>
<p>But still, for complex data science type computations we might want automatic parallelization. So we can provide a DSL function <code class="docutils literal notranslate"><span class="pre">parallelize</span></code> to automatically rewrite pure computations to concurrent ones, implementing the “small on single thread, big splits into small” operations on top of fork/join model and taking the thread / task queue implementation as a parameter. Doug Lea’s work stealing task queues can be very efficient given the correct task granularity.</p>
<p>Haskell’s “par” is interesting, but too fine-grained to be efficient. You have to manually add in a depth threshold and manually optimize it. It’s just as clear to use explicit fork/join operations, and indeed the <code class="docutils literal notranslate"><span class="pre">rpar/rpar/rseq/rseq</span></code> pattern proposed in <a class="reference external" href="https://www.oreilly.com/library/view/parallel-and-concurrent/9781449335939/ch02.html">the Parallel Haskell book</a> is just fork/join with different naming.</p>
<p>As far as the actual task granularity, Cliff says somewhere around the middle of the microsecond range is the break-even point, thousands of cycles / machine code instructions. Below that the overhead for forking the task exceeds the speedup from parallelism, but above you can make useful progress.</p>
</section>
<section id="os-model">
<h2>OS Model<a class="headerlink" href="#os-model" title="Permalink to this headline"></a></h2>
<p>An application consists of one or more processes. A process, in the simplest terms, is an executing program.</p>
<p>A job object allows groups of processes to be managed as a unit. Job objects are namable, securable, sharable objects that control attributes of the processes associated with them. Operations performed on the job object affect all processes associated with the job object.</p>
<p>One or more threads run in the context of the process. A thread is the basic unit to which the operating system allocates processor time. A thread can execute any part of the process code, including parts currently being executed by another thread.</p>
<p>Windows has a special thread type “UMS thread” which has more application control. An application can switch between UMS threads in user mode without involving the system scheduler and regain control of the processor if a UMS thread blocks in the kernel. Each UMS thread has its own thread context. The ability to switch between threads in user mode makes UMS more efficient than thread pools for short-duration work items that require few system calls.</p>
<p>A fiber / green thread / virtual thread consists of a stack, a small storage space for registers, and fiber local storage. A fiber runs in the context of a thread and shares the thread context with other fibers. Fiber switching is fewer OS calls than a full-on thread context switch. When fibers are integrated into the runtime they can be more memory efficient than threads, otherwise they do not provide many advantages over threads.</p>
<p>async marking makes core library functions more painful to call and requires a special annotation on the whole call chain. Avoid it by making everything async.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Sets.html" class="btn btn-neutral float-left" title="Sets" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Syntax.html" class="btn btn-neutral float-right" title="Syntax" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2020 Mathnerd314.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>