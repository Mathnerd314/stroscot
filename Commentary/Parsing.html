<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Parsing &mdash; Stroscot  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/hexagon_favicon.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Posets" href="Posets.html" />
    <link rel="prev" title="Package manager" href="PackageManager.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html">
            
              <img src="../_static/hexagon_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/index.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../HowTo/index.html">How to</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Reference/index.html">Language Reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Commentary</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Assembly.html">Assembly</a></li>
<li class="toctree-l2"><a class="reference internal" href="BuildSystem.html">Build system</a></li>
<li class="toctree-l2"><a class="reference internal" href="Checklist.html">Checklist</a></li>
<li class="toctree-l2"><a class="reference internal" href="Code-Generation.html">Code generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Compiler.html">Compiler design</a></li>
<li class="toctree-l2"><a class="reference internal" href="Compiler-Library.html">Compiler library</a></li>
<li class="toctree-l2"><a class="reference internal" href="CompilerOutput.html">Compiler output</a></li>
<li class="toctree-l2"><a class="reference internal" href="Concurrency.html">Concurrency</a></li>
<li class="toctree-l2"><a class="reference internal" href="CoreSyntax.html">Core syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="Dispatch.html">Dispatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="Errors.html">Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="Evaluation-Strategy.html">Evaluation strategy</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exceptions.html">Exceptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="Fastest.html">As fast as C</a></li>
<li class="toctree-l2"><a class="reference internal" href="IR.html">Intermediate representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Intrinsics.html">Intrinsics</a></li>
<li class="toctree-l2"><a class="reference internal" href="Learning.html">Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Logic.html">Logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="LogicProgramming.html">Logic programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="Macros.html">Macros</a></li>
<li class="toctree-l2"><a class="reference internal" href="Memory-Management.html">Memory management</a></li>
<li class="toctree-l2"><a class="reference internal" href="Meta.html">Meta</a></li>
<li class="toctree-l2"><a class="reference internal" href="Modules.html">Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="Objects.html">Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="PackageManager.html">Package manager</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Parsing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#scannerless-generalized-parsing">Scannerless generalized parsing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parser-combinators">Parser combinators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#type">Type</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#output">Output</a></li>
<li class="toctree-l3"><a class="reference internal" href="#algorithm">Algorithm</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Posets.html">Posets</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html">Profiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#resources">Resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#metrics">Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#statistics">Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#methods">Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#action">Action</a></li>
<li class="toctree-l2"><a class="reference internal" href="Programs.html">Exemplary programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction.html">Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction-Example.html">Reduction example</a></li>
<li class="toctree-l2"><a class="reference internal" href="Resource-Management.html">Resource management</a></li>
<li class="toctree-l2"><a class="reference internal" href="Sets.html">Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="Standard-Library.html">Standard library</a></li>
<li class="toctree-l2"><a class="reference internal" href="State.html">Stateful programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="Syntax.html">Syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="TermRewriting.html">Term rewriting</a></li>
<li class="toctree-l2"><a class="reference internal" href="Time.html">Time API</a></li>
<li class="toctree-l2"><a class="reference internal" href="Tools.html">Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="Types.html">Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="Units.html">Units</a></li>
<li class="toctree-l2"><a class="reference internal" href="Verification.html">Verification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../zzreferences.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Stroscot</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Commentary</a></li>
      <li class="breadcrumb-item active">Parsing</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/Mathnerd314/stroscot/edit/master/docs/Commentary/Parsing.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="parsing">
<h1>Parsing<a class="headerlink" href="#parsing" title="Permalink to this heading"></a></h1>
<p>Source code by itself is rather difficult to work with. To do anything useful, one would prefer to work with the AST or IR. Extensible syntax complicates the issue because there is no fixed grammar for the language. So we need a parser that can take arbitrary rules. And of course once we have a good parser, there is no harm in exposing it in the language, similar to Raku’s inline <a class="reference external" href="https://docs.raku.org/language/grammars.html">grammars</a>.</p>
<section id="scannerless-generalized-parsing">
<h2>Scannerless generalized parsing<a class="headerlink" href="#scannerless-generalized-parsing" title="Permalink to this heading"></a></h2>
<p>The conventional structure of a parser has two levels, the lexer (a regular language) and the grammar (a context-free language). The lexer “tokenises” the input into a stream/sequence of tokens, for example whitespace, keywords, or identifiers. This tokenization uses implicit disambiguation rules such as longest match. Then whitespace tokens are ignored and the rest of the tokens are processed by the parser into a single tree, deterministically. But there is an alternative: scannerless parsing. Per <span id="id1">[]</span>, in scannerless parsing, the grammar may still be conceptually divided into a lexical part and grammar part. However, these are processed into a single character-level grammar, that is mostly context-free. Lexical rules are converted from regular to context-free, while the context-free syntax’s rules have optional layout tokens inserted into every concatenation (<code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">b</span> <span class="pre">-&gt;</span> <span class="pre">a</span> <span class="pre">layout?</span> <span class="pre">b</span></code>). Since lexical rules and context-free rules may overlap they are renamed for clarity, <code class="docutils literal notranslate"><span class="pre">X-LEX</span></code> and <code class="docutils literal notranslate"><span class="pre">X-CF</span></code>.</p>
<p>Scannerless parsing avoids the need for a streaming interface between scanner and parser. It allows using much more flexible rules for lexical syntax, such as defining nested comments. Furthermore the unified grammar handles some situations that are tricky for conventional parsers. For example, in Pascal, there is an ambiguity between a subrange type <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">..</span> <span class="pre">2</span></code> and a list of floating point number constants <code class="docutils literal notranslate"><span class="pre">[</span> <span class="pre">1.</span> <span class="pre">.2</span> <span class="pre">]</span></code> (spaces for clarity). A conventional parser will have to do some lexer hack, while a scannerless parser can disambiguate based on whether a list is being parsed. As another example, with whitespace-sensitive syntax, whitespace is significant in some places, but it is still desirable to be able to ignore it for most rules and centralize its handling in one place. The lack of “tokens” as a layer in the AST makes identifying line numbers and columns easy and doesn’t throw away whitespace information, making reformatting and documentation generation easier. It also allows handling constructs like file path literals that are conceptually a single nonterminal but have internal lexical structure.</p>
<p>The main problem with scannerless parsing is it requires effectively handling ambiguity. Character-level grammars have a large number of states because a literal splits into a state for each character. Most character-level grammars are not LR(k) (i.e., not deterministic) due to lookahead needed for lexical elements - arbitrary amounts of whitespace must be consumed to identify the next rule. Also, lexical disambiguation rules such as longest match are not context-free. The most natural way to formulate them is as ad-hoc disambiguation filters that filters potential parse trees in post-processing, as in <span id="id2">[]</span> 4.4.1. Of course, for efficiency, such disambiguation should be “local” and “incremental” (4.4.5-4.4.6) and done on the fly. Fortunately, <span id="id3">[]</span> says scannerless GLR parsers with post-processed disambugation are fast enough in practice that they can be used for real programming language tasks.</p>
<p>Overall, scannerless seems to be a tradeoff of correct and simple to use but tricky to implement fast. That could be said for programming languages in general: easy to use but hard to write. Given that we are writing the ultimate programming language, it seems worth the effort to also write the ultimate parser.</p>
</section>
<section id="parser-combinators">
<h2>Parser combinators<a class="headerlink" href="#parser-combinators" title="Permalink to this heading"></a></h2>
<p>Per <a class="reference external" href="http://www.semdesigns.com/products/DMS/DMSParsers.html?Home=DMSLexers">this</a>, Ira Baxter says he did EBNF for 30 years, then he “got smart” and switched to BNF, and found he didn’t miss the EBNFisms at all. But from a functional programming perspective, it is kind of restrictive that we can’t abstract out common BNF patterns; everything must be expressed as an explicit, named rule. IMO the extra complexity is worth it if we can add a few definitions and halve the size of our grammar. But with this line of reasoning, even EBNF isn’t sufficient, because it can’t define new patterns. Parser combinators allow arbitrary higher-order abstractions, using FP to abstract patterns. And they allow “nameless” grammar expressions, useful when writing simple regex-like parsers for scripting and the like.</p>
<p>Per <span id="id4">[]</span>, a parser combinator consumes a string and produces the set of all (partial) parses of the string, where a partial parse is a parse tree and the remaining unconsumed input. A “full” parse consumes all of the input, meaning a parse where the remaining unconsumed input is empty - we obtain the traditional parse set by considering only the full parsers. But this only describes first-order parser combinators. Operationally, parser combinators are higher-order, and are whatever is defined as such in papers and libraries. I went and found as many combinators as I could, then classified them into primitive and derived combinators. So, the primitive parser combinators:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">failure</span></code>, <code class="docutils literal notranslate"><span class="pre">mzero</span></code>, <code class="docutils literal notranslate"><span class="pre">empty</span></code>, <code class="docutils literal notranslate"><span class="pre">parseError</span> <span class="pre">(msg</span> <span class="pre">:</span> <span class="pre">ParseError)</span></code>, <code class="docutils literal notranslate"><span class="pre">fail</span> <span class="pre">(msg</span> <span class="pre">:</span> <span class="pre">String)</span></code>, <code class="docutils literal notranslate"><span class="pre">unexpected</span> <span class="pre">(msg</span> <span class="pre">:</span> <span class="pre">String)</span></code> - unsuccessful parse (empty set of parses). always fails with the given error message msg, at the current location. <code class="docutils literal notranslate"><span class="pre">failure</span></code> uses a fixed uninformative message.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">unit</span> <span class="pre">=</span> <span class="pre">return</span> <span class="pre">()</span></code> - no-op parser, matches empty string. consumes no input and always succeeds.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">anyToken</span></code>, <code class="docutils literal notranslate"><span class="pre">anyByte</span></code>, <code class="docutils literal notranslate"><span class="pre">item</span></code> - consumes the next token, fails at eof. Although seemingly simple, it has non-trivial behavior, like suspending the parser on incomplete input and tracking line/column numbers.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">&lt;|&gt;</span> <span class="pre">q</span></code>, <code class="docutils literal notranslate"><span class="pre">mplus</span> <span class="pre">p</span> <span class="pre">q</span></code>, <code class="docutils literal notranslate"><span class="pre">alt</span> <span class="pre">p</span> <span class="pre">q</span></code> - Choice (disjunction), specifically unbiased (nondeterministic) choice - both p and q are tried at the same time.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">&lt;&gt;</span> <span class="pre">q</span></code>, <code class="docutils literal notranslate"><span class="pre">seq</span> <span class="pre">p</span> <span class="pre">q</span></code>, <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">&gt;&gt;=</span> <span class="pre">q</span></code>, <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">&lt;*</span> <span class="pre">q</span></code>, <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">&lt;*&gt;</span> <span class="pre">q</span></code>, <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">*&gt;</span> <span class="pre">q</span></code> - Concatenation. parses p followed by q</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">not</span> <span class="pre">p</span></code> - (absolute) set complement of p, succeeds iff p would fail. For example <code class="docutils literal notranslate"><span class="pre">[^abc]</span></code> is <code class="docutils literal notranslate"><span class="pre">not</span> <span class="pre">(oneOf</span> <span class="pre">&quot;abc&quot;)</span> <span class="pre">&lt;&amp;&amp;&gt;</span> <span class="pre">anyChar</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">try</span></code> / <code class="docutils literal notranslate"><span class="pre">attempt</span></code> - This is a primitive in backtracking parsers, but in a nondeterministic parser, it is simply a no-op: all combinators behave as though they are wrapped in <code class="docutils literal notranslate"><span class="pre">try</span></code>, and failure with consumed input is not observable.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lookAhead</span> <span class="pre">p</span></code> - parses p. If p succeeds, consumes no input and succeeds. If p fails, so does lookAhead. It is possible to rewrite lookAhead into intersection, via <code class="docutils literal notranslate"><span class="pre">lookAhead</span> <span class="pre">a</span> <span class="pre">&lt;&gt;</span> <span class="pre">b</span> <span class="pre">=</span> <span class="pre">(a</span> <span class="pre">&lt;&gt;</span> <span class="pre">many</span> <span class="pre">any)</span> <span class="pre">&lt;&amp;&amp;&gt;</span> <span class="pre">b</span></code>, but it is a global CPS-like transformation, whereas the reverse <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">&lt;&amp;&amp;&gt;</span> <span class="pre">y</span> <span class="pre">=</span> <span class="pre">lookAhead</span> <span class="pre">x</span> <span class="pre">&lt;&gt;</span> <span class="pre">y</span></code> is direct, so <code class="docutils literal notranslate"><span class="pre">lookAhead</span></code> is a more useful choice of primitive.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">disambiguateFilter</span> <span class="pre">(test</span> <span class="pre">:</span> <span class="pre">ParseForest</span> <span class="pre">-&gt;</span> <span class="pre">ParseTree</span> <span class="pre">-&gt;</span> <span class="pre">Bool)</span> <span class="pre">p</span></code> - disambiguation filter (<span id="id5">[]</span> 4.4.1). First <code class="docutils literal notranslate"><span class="pre">p</span></code> is run, identifying all partial parses. These partial parses are grouped into parse forests by amount of input consumed. A filter <code class="docutils literal notranslate"><span class="pre">test</span></code> identifies, for each parse tree within each parse forest, whether that parse is “correct” or “wrong”. The wrong parses are removed from the forest and only the correct parses are further considered. Not commonly used in this form, but this formulation is the most powerful.</p></li>
<li><p>recursion - in our notation it’s built into the ambient language, but formally we should use a construct like <code class="docutils literal notranslate"><span class="pre">let</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">a</span> <span class="pre">&lt;|&gt;</span> <span class="pre">b</span> <span class="pre">in</span> <span class="pre">a</span></code>, where the bound appearances of the identifier <code class="docutils literal notranslate"><span class="pre">a</span></code> are pseudo-combinators. It is also possible to use a graph with cycles, or just unroll it to an infinite tree, but the <code class="docutils literal notranslate"><span class="pre">let</span></code> is more human-readable. There is also parameterized parsing, e.g. <code class="docutils literal notranslate"><span class="pre">flip</span> <span class="pre">count</span> <span class="pre">p</span></code> is technically an infinite family of productions indexed by integers, which needs some accomodation as well for data-dependent parsing (but is of course very useful).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">&lt;?&gt;</span> <span class="pre">(msg</span> <span class="pre">:</span> <span class="pre">String)</span></code>, <code class="docutils literal notranslate"><span class="pre">label</span> <span class="pre">p</span> <span class="pre">msg</span></code> - Capture group / label. behaves as parser p, but labels the output tree / parse error message with msg. Usually the label is the type of production expected (expression, number, end quote, etc.)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hidden</span> <span class="pre">p</span></code> - like p, but suppresses any labels in error messages</p></li>
</ul>
<p>Then we have derived combinators:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">-</span> <span class="pre">q</span> <span class="pre">=</span> <span class="pre">p</span> <span class="pre">&lt;&amp;&amp;&gt;</span> <span class="pre">not</span> <span class="pre">q</span></code>, <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">{reject}</span> <span class="pre">q</span></code> - set subtraction, relative complement, reject production. Acts as p but fails if q would succeed. <span id="id6">[]</span> has <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">&lt;|&gt;</span> <span class="pre">not</span> <span class="pre">(p</span> <span class="pre">&lt;&gt;</span> <span class="pre">always)</span> <span class="pre">&lt;&amp;&amp;&gt;</span> <span class="pre">q</span></code>. This maps 1-1 to the “prefer literals” implicit lexer rule, via the transform in <span id="id7">[]</span> section 3.6.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">{prefer}</span> <span class="pre">q</span> <span class="pre">=</span> <span class="pre">p</span> <span class="pre">&lt;|&gt;</span> <span class="pre">(q</span> <span class="pre">-</span> <span class="pre">p)</span></code>, <code class="docutils literal notranslate"><span class="pre">q</span> <span class="pre">{avoid}</span> <span class="pre">p</span></code> - Biased (preferential) choice, similar to that used in PEG’s or backtracking parsers. If <code class="docutils literal notranslate"><span class="pre">p</span></code> matches, returns only the parses from <code class="docutils literal notranslate"><span class="pre">p</span></code>. Otherwise, acts as <code class="docutils literal notranslate"><span class="pre">q</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">always</span> <span class="pre">=</span> <span class="pre">not</span> <span class="pre">mzero</span></code> - always succeeds, consumes an arbitrary amount of input</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">&lt;&amp;&amp;&gt;</span> <span class="pre">y</span> <span class="pre">=</span> <span class="pre">lookAhead</span> <span class="pre">x</span> <span class="pre">&lt;&gt;</span> <span class="pre">y,</span> <span class="pre">and</span> <span class="pre">x</span> <span class="pre">y</span></code> - conjunction / set intersection. must match both x and y, returns parse tree of <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">notFollowedBy</span> <span class="pre">p</span> <span class="pre">=</span> <span class="pre">lookAhead</span> <span class="pre">(not</span> <span class="pre">p)</span></code> - succeeds iff parser <code class="docutils literal notranslate"><span class="pre">p</span></code> fails, consuming no input.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eof</span> <span class="pre">=</span> <span class="pre">notFollowedBy</span> <span class="pre">anyToken</span></code> - succeeds at the end of the input.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">more</span> <span class="pre">=</span> <span class="pre">lookAhead</span> <span class="pre">anyToken</span></code> - succeeds if there is more input.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">-/-</span> <span class="pre">B</span> <span class="pre">=</span> <span class="pre">A</span> <span class="pre">&lt;&gt;</span> <span class="pre">notFollowedBy</span> <span class="pre">B</span></code> - follow restriction, consumes <code class="docutils literal notranslate"><span class="pre">A</span></code> but does not match if <code class="docutils literal notranslate"><span class="pre">B</span></code> can be parsed afterwards. For example <code class="docutils literal notranslate"><span class="pre">[a-z]+</span> <span class="pre">-/-</span> <span class="pre">[a-z]</span></code> specifies an identifier not followed by another identifier character. <span id="id8">[]</span> section 3.6 explains that, although follow restrictions work to identify the longest match in all practical cases, in contrived cases the follow restriction is too strict and gives no parse even when some longest-match parse exists.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">filter</span> <span class="pre">f</span> <span class="pre">p,</span> <span class="pre">satisfy</span> <span class="pre">f</span> <span class="pre">p,</span> <span class="pre">p</span> <span class="pre">{with}</span> <span class="pre">test</span></code> - semantic predicate / property filter. Restricts parses of <code class="docutils literal notranslate"><span class="pre">p</span></code> to those for which <code class="docutils literal notranslate"><span class="pre">f</span></code> returns true.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">filterMin</span> <span class="pre">r</span> <span class="pre">p,</span> <span class="pre">filterMax</span> <span class="pre">r</span> <span class="pre">p</span></code> - comparison filters, which selects the maximal/minimal parses according to some strict partial order <code class="docutils literal notranslate"><span class="pre">r</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">longestMatch</span></code>: A comparison filter. Each parse tree is converted to a token stream (list) by depth-first left-to-right traversal of the parse tree, stopping at lexical rules / literal rules. Then a token stream <code class="docutils literal notranslate"><span class="pre">xs</span></code> is a longer match than <code class="docutils literal notranslate"><span class="pre">ys</span></code> if  <code class="docutils literal notranslate"><span class="pre">map</span> <span class="pre">length</span> <span class="pre">xs</span> <span class="pre">&gt;</span> <span class="pre">map</span> <span class="pre">length</span> <span class="pre">ys</span></code>, where <code class="docutils literal notranslate"><span class="pre">(&gt;)</span></code> is lexicographical ordering and <code class="docutils literal notranslate"><span class="pre">length</span></code> counts the number of matched characters in the subtree.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">between</span> <span class="pre">open</span> <span class="pre">close</span> <span class="pre">p</span> <span class="pre">=</span> <span class="pre">open</span> <span class="pre">&lt;&gt;</span> <span class="pre">p</span> <span class="pre">&lt;&gt;</span> <span class="pre">close</span></code> - just a convenience</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">done</span> <span class="pre">p</span> <span class="pre">=</span> <span class="pre">p</span> <span class="pre">&lt;&amp;&amp;&gt;</span> <span class="pre">unit</span></code> - nullability parser. Simplifies to <code class="docutils literal notranslate"><span class="pre">unit</span></code> if <code class="docutils literal notranslate"><span class="pre">p</span></code> is nullable and <code class="docutils literal notranslate"><span class="pre">failure</span></code> otherwise.</p></li>
</ul>
<p>There are also derived repetition combinators:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">many</span> <span class="pre">p</span> <span class="pre">=</span> <span class="pre">return</span> <span class="pre">()</span> <span class="pre">&lt;|&gt;</span> <span class="pre">p</span> <span class="pre">*&gt;</span> <span class="pre">many</span> <span class="pre">p</span></code> - Kleene closure/star. applies the parser p zero or more times.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">some</span> <span class="pre">p</span> <span class="pre">=</span> <span class="pre">many1</span> <span class="pre">p</span> <span class="pre">=</span> <span class="pre">p</span> <span class="pre">&lt;|&gt;</span> <span class="pre">(p</span> <span class="pre">*&gt;</span> <span class="pre">many</span> <span class="pre">p)</span></code> - Kleene plus. applies the parser p one or more times.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">manyTill</span> <span class="pre">p</span> <span class="pre">end</span> <span class="pre">=</span> <span class="pre">end</span> <span class="pre">&lt;|&gt;</span> <span class="pre">(p</span> <span class="pre">&gt;*&lt;</span> <span class="pre">manyTill</span> <span class="pre">p</span> <span class="pre">end)</span></code>, <code class="docutils literal notranslate"><span class="pre">manyUntil</span></code> - applies parser p zero or more times until parser end succeeds.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">someUntil</span> <span class="pre">p</span> <span class="pre">end</span></code> - applies parser p one or more times until parser end succeeds.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">count</span> <span class="pre">n</span> <span class="pre">p</span> <span class="pre">=</span> <span class="pre">p</span> <span class="pre">&lt;&gt;</span> <span class="pre">count</span> <span class="pre">(n-1)</span> <span class="pre">p;</span> <span class="pre">count</span> <span class="pre">0</span> <span class="pre">p</span> <span class="pre">=</span> <span class="pre">unit</span></code>, <code class="docutils literal notranslate"><span class="pre">exactly</span> <span class="pre">n</span> <span class="pre">p</span></code> - applies the parser p exactly n times. n must be nonnegative.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">manyN</span> <span class="pre">n</span> <span class="pre">p</span> <span class="pre">=</span> <span class="pre">count</span> <span class="pre">n</span> <span class="pre">p</span> <span class="pre">&lt;&gt;</span> <span class="pre">many</span> <span class="pre">p</span></code> - applies the parser p n or more times.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">count'</span> <span class="pre">m</span> <span class="pre">n</span> <span class="pre">p</span></code> - applies the parser p between m and n times. 0 &lt;= m &lt; n.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">option</span> <span class="pre">p</span></code>, <code class="docutils literal notranslate"><span class="pre">optional</span> <span class="pre">p</span></code> - applies p zero or one times</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">choice</span> <span class="pre">ps</span></code> - apply the parsers in the list ps in order, until one of them succeeds.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sepBy</span> <span class="pre">p</span> <span class="pre">sep</span></code> parses zero or more occurrences of p, separated by sep.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sepBy1</span> <span class="pre">p</span> <span class="pre">sep</span></code> parses one or more occurrences of p, separated by sep.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">endBy</span> <span class="pre">p</span> <span class="pre">sep</span></code> parses zero or more occurrences of p, separated and ended by sep.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">endBy1</span> <span class="pre">p</span> <span class="pre">sep</span></code> parses one or more occurrences of p, separated and ended by sep.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sepEndBy</span> <span class="pre">p</span> <span class="pre">sep</span></code> parses zero or more occurrences of p, separated and optionally ended by sep.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sepEndBy1</span> <span class="pre">p</span> <span class="pre">sep</span></code> parses one or more occurrences of p, separated and optionally ended by sep.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">chainl</span> <span class="pre">p</span> <span class="pre">op</span> <span class="pre">=</span> <span class="pre">unit</span> <span class="pre">&lt;|&gt;</span> <span class="pre">chainl1</span> <span class="pre">p</span> <span class="pre">op</span></code> parses zero or more occurrences of p, separated by op. (left-associative)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">chainl1</span> <span class="pre">p</span> <span class="pre">op</span> <span class="pre">=</span> <span class="pre">p</span> <span class="pre">&lt;|&gt;</span> <span class="pre">((chainl1</span> <span class="pre">p</span> <span class="pre">op)</span> <span class="pre">&lt;&gt;</span> <span class="pre">op</span> <span class="pre">&lt;&gt;</span> <span class="pre">p)</span></code> - parses one or more occurrences of p, separated by op (left-associative).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">chainr</span> <span class="pre">p</span> <span class="pre">op</span> <span class="pre">=</span> <span class="pre">unit</span> <span class="pre">&lt;|&gt;</span> <span class="pre">chainr1</span> <span class="pre">p</span> <span class="pre">op</span></code> parses zero or more occurrences of p, separated by op. (right-associative)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">chainr1</span> <span class="pre">p</span> <span class="pre">op</span> <span class="pre">=</span> <span class="pre">p</span> <span class="pre">&lt;|&gt;</span> <span class="pre">(p</span> <span class="pre">&lt;&gt;</span> <span class="pre">op</span> <span class="pre">&lt;&gt;</span> <span class="pre">(chainr1</span> <span class="pre">p</span> <span class="pre">op))</span></code> - parses one or more occurrences of p, separated by op (right-associative).</p></li>
</ul>
<p>Character/byte/token combinators:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">space</span> <span class="pre">=</span> <span class="pre">oneOf</span> <span class="pre">&quot;\t</span> <span class="pre">&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">space_unicode</span></code>, <code class="docutils literal notranslate"><span class="pre">spaces</span> <span class="pre">=</span> <span class="pre">many</span> <span class="pre">space</span></code>, <code class="docutils literal notranslate"><span class="pre">space1</span> <span class="pre">=</span> <span class="pre">some</span> <span class="pre">space</span></code>, <code class="docutils literal notranslate"><span class="pre">tab</span></code>, <code class="docutils literal notranslate"><span class="pre">newline</span></code>, <code class="docutils literal notranslate"><span class="pre">crlf</span></code>, <code class="docutils literal notranslate"><span class="pre">endOfLine</span> <span class="pre">=</span> <span class="pre">newline</span> <span class="pre">&lt;|&gt;</span> <span class="pre">crlf</span></code>, <code class="docutils literal notranslate"><span class="pre">whitspace</span> <span class="pre">=</span> <span class="pre">space</span> <span class="pre">&lt;|&gt;</span> <span class="pre">oneOf</span> <span class="pre">&quot;\n\r\f\u000B&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">upper</span></code>, <code class="docutils literal notranslate"><span class="pre">lower</span></code>, <code class="docutils literal notranslate"><span class="pre">alphaNum</span></code>, <code class="docutils literal notranslate"><span class="pre">letter</span></code>, <code class="docutils literal notranslate"><span class="pre">letter_iso8859_15</span></code>, <code class="docutils literal notranslate"><span class="pre">digit</span></code>, <code class="docutils literal notranslate"><span class="pre">hexDigit</span></code>, <code class="docutils literal notranslate"><span class="pre">octDigit</span></code>, <code class="docutils literal notranslate"><span class="pre">control</span></code>, <code class="docutils literal notranslate"><span class="pre">comma</span></code>, <code class="docutils literal notranslate"><span class="pre">colon</span></code>, <code class="docutils literal notranslate"><span class="pre">dot</span></code>- obvious (unqualified definitions based on ASCII)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">anyUTF8Char</span> <span class="pre">=</span> <span class="pre">b1</span> <span class="pre">&lt;|&gt;</span> <span class="pre">b2</span> <span class="pre">&lt;&gt;</span> <span class="pre">bx</span> <span class="pre">&lt;|&gt;</span> <span class="pre">b3</span> <span class="pre">&lt;&gt;</span> <span class="pre">(count</span> <span class="pre">2</span> <span class="pre">bx)</span> <span class="pre">&lt;|&gt;</span> <span class="pre">b4</span> <span class="pre">&lt;&gt;</span> <span class="pre">(count</span> <span class="pre">3</span> <span class="pre">bx)</span> <span class="pre">where</span> <span class="pre">b1</span> <span class="pre">=</span> <span class="pre">[\x00-\x7F];</span> <span class="pre">b2</span> <span class="pre">=</span> <span class="pre">[\xC2-\xDF];</span> <span class="pre">b3</span> <span class="pre">=</span> <span class="pre">[\xE0-\xEF];</span> <span class="pre">b4</span> <span class="pre">=</span> <span class="pre">[\xF0-\xF4];</span> <span class="pre">bx</span> <span class="pre">=</span> <span class="pre">[\x80-\xBF]</span></code> - byte-based UTF8 parsing</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">charCategory</span> <span class="pre">cat</span></code>, <code class="docutils literal notranslate"><span class="pre">combining</span></code>, <code class="docutils literal notranslate"><span class="pre">numeric</span></code>, <code class="docutils literal notranslate"><span class="pre">punctuation</span></code>, <code class="docutils literal notranslate"><span class="pre">symbol</span></code>, <code class="docutils literal notranslate"><span class="pre">ascii</span></code>, <code class="docutils literal notranslate"><span class="pre">latin1</span></code> - parses a Unicode character in the given Unicode general category.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">semiSep</span></code>, <code class="docutils literal notranslate"><span class="pre">semiSep1</span></code>, <code class="docutils literal notranslate"><span class="pre">commaSep</span></code>, <code class="docutils literal notranslate"><span class="pre">commaSep1</span></code> - sepBy/sepBy1 with the given separator</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">oneOf</span> <span class="pre">cs</span></code>, <code class="docutils literal notranslate"><span class="pre">inClass</span> <span class="pre">cs</span></code> - succeeds if the current character is in the supplied list/class/range of characters cs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">noneOf</span> <span class="pre">cs</span></code>, <code class="docutils literal notranslate"><span class="pre">notInClass</span> <span class="pre">cs</span></code> - dual of oneOf, succeeds if the current character is not in the supplied list/class/range of characters cs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">satisfyC</span> <span class="pre">f</span></code>- succeeds for any character for which the supplied function f returns True.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">string</span> <span class="pre">s</span> <span class="pre">=</span> <span class="pre">filter</span> <span class="pre">(==</span> <span class="pre">s)</span> <span class="pre">(count</span> <span class="pre">(length</span> <span class="pre">s)</span> <span class="pre">anyToken)</span></code> - matches a sequence of characters identical to s.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">char</span> <span class="pre">c</span> <span class="pre">=</span> <span class="pre">string</span> <span class="pre">[c]</span></code>, <code class="docutils literal notranslate"><span class="pre">single</span> <span class="pre">s</span></code> - parses a single character c / token s.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">notChar</span> <span class="pre">c</span> <span class="pre">=</span> <span class="pre">anyChar</span> <span class="pre">&lt;&amp;&amp;&gt;</span> <span class="pre">not</span> <span class="pre">(char</span> <span class="pre">c)</span></code> - parses any single character besides c.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">take</span> <span class="pre">n</span> <span class="pre">=</span> <span class="pre">count</span> <span class="pre">n</span> <span class="pre">anyChar</span></code> - consumes exactly n characters of input</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">takeWhile</span> <span class="pre">p</span> <span class="pre">=</span> <span class="pre">many</span> <span class="pre">(satisfy</span> <span class="pre">p)</span></code> - matches input as long as the predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is true. Always succeeds, at worst it will simply match nothing.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">takeTill</span> <span class="pre">p</span></code> - matches input as long as the predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is false. Always succeeds, at worst it will simply match nothing.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">takeWhile1</span> <span class="pre">p</span> <span class="pre">=</span> <span class="pre">some</span> <span class="pre">(satisfy</span> <span class="pre">p)</span></code> - matches input as long as the predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is true. Fails if no input is consumed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">takeWhileIncluding</span> <span class="pre">p</span> <span class="pre">=</span> <span class="pre">many</span> <span class="pre">(satisfy</span> <span class="pre">p)</span> <span class="pre">&gt;*&lt;</span> <span class="pre">anyChar</span></code> - matches input as long as the predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is true, and the following character. Fails if no input is consumed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scan</span> <span class="pre">s_0</span> <span class="pre">p</span></code> - stateful version of <code class="docutils literal notranslate"><span class="pre">takeWhile</span></code>. As long as <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">s_i</span> <span class="pre">c_i</span></code> return <code class="docutils literal notranslate"><span class="pre">Just</span> <span class="pre">s_(i+1)</span></code>, the parser will continue matching input.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">identifier</span></code>, <code class="docutils literal notranslate"><span class="pre">reserved</span></code>, <code class="docutils literal notranslate"><span class="pre">operator</span></code>, <code class="docutils literal notranslate"><span class="pre">reservedOperator</span></code> - a legal identifier is one of the form <code class="docutils literal notranslate"><span class="pre">start</span> <span class="pre">letter*</span></code> that does not match a reserved word. Similarly operators are <code class="docutils literal notranslate"><span class="pre">opStart</span> <span class="pre">opLetter*</span></code> and also some operators are reserved.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">charLiteral</span></code>, <code class="docutils literal notranslate"><span class="pre">stringLiteral</span></code>, <code class="docutils literal notranslate"><span class="pre">natural</span></code>, <code class="docutils literal notranslate"><span class="pre">integer</span></code>, <code class="docutils literal notranslate"><span class="pre">rational</span></code>, <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">naturalOrFloat</span></code>, <code class="docutils literal notranslate"><span class="pre">decimal</span></code>, <code class="docutils literal notranslate"><span class="pre">hexadecimal</span></code>, <code class="docutils literal notranslate"><span class="pre">octal</span></code> - parses as in the Haskell report</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">buildExpressionParser</span> <span class="pre">table</span> <span class="pre">term</span></code> builds a (mixfix) expression parser. The expressions use <code class="docutils literal notranslate"><span class="pre">term</span></code> as the lowest building block of an expression, commonly an (atomic) identifier or a parenthesised expression. The table is a lists of lists; the outer list is ordered in ascending precedence (least tight to most tight), while all operators in one inner list have the same precedence. Each operator is specified as a list of productions and holes, and also has an associativity (none, left, or right - “both” or “assoc” is ambiguous and parsed as left in a “don’t-care” manner), taken into account when an identifier starts or ends with holes. <span id="id9">[]</span> defines priority and associativity for SDF using disambiguation filters, essentially priority specifies that a use of <code class="docutils literal notranslate"><span class="pre">E_i</span></code> in a production <code class="docutils literal notranslate"><span class="pre">E_j</span></code> must have <code class="docutils literal notranslate"><span class="pre">i&gt;j</span></code>. The associativity filters out trees with the same production in the first/last position, like <code class="docutils literal notranslate"><span class="pre">func</span> <span class="pre">=</span> <span class="pre">(E</span> <span class="pre">-</span> <span class="pre">func)</span> <span class="pre">&quot;→&quot;</span> <span class="pre">E</span></code>. Definition 3.4.1 defines it formally, these are disallowed:</p>
<ul class="simple">
<li><p>a parse <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">=</span> <span class="pre">...</span> <span class="pre">B</span> <span class="pre">...</span></code> where <code class="docutils literal notranslate"><span class="pre">B</span></code> is a direct child and has lower precedence than <code class="docutils literal notranslate"><span class="pre">A</span></code></p></li>
<li><p>a parse <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">=</span> <span class="pre">B</span> <span class="pre">...</span> <span class="pre">A</span> <span class="pre">...</span></code> where <code class="docutils literal notranslate"><span class="pre">B</span></code> is right-associative or non-associative w.r.t. A</p></li>
<li><p>a parse <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">=</span> <span class="pre">...</span> <span class="pre">A</span> <span class="pre">...</span> <span class="pre">B</span></code> where <code class="docutils literal notranslate"><span class="pre">B</span></code> is left-associative or non-associative w.r.t. A</p></li>
</ul>
<p>The precedence rule should be clear. For the associativity, consider a binary operator <code class="docutils literal notranslate"><span class="pre">_+_</span></code> left-associative w.r.t. <code class="docutils literal notranslate"><span class="pre">Term</span></code>. Parsing <code class="docutils literal notranslate"><span class="pre">(1+(2+3))</span></code> will give a tree like <code class="docutils literal notranslate"><span class="pre">Add</span> <span class="pre">Term</span> <span class="pre">(Add</span> <span class="pre">Term</span> <span class="pre">Term)</span></code> - <code class="docutils literal notranslate"><span class="pre">Term</span></code> appears before <code class="docutils literal notranslate"><span class="pre">Add</span></code>.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">whiteSpace</span></code> - zero or more occurrences of a space, a line comment or a block (multi line) comment. Block comments may be nested. The only point where the whiteSpace parser should be called explicitly is the start of the main parser in order to skip any leading white space.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lexeme</span> <span class="pre">p</span> <span class="pre">=</span> <span class="pre">p</span> <span class="pre">&gt;*&lt;</span> <span class="pre">whiteSpace</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">symbol</span> <span class="pre">s</span> <span class="pre">=</span> <span class="pre">lexeme</span> <span class="pre">(string</span> <span class="pre">s)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">parens</span> <span class="pre">p,</span> <span class="pre">braces</span> <span class="pre">p,</span> <span class="pre">angles</span> <span class="pre">p,</span> <span class="pre">brackets</span> <span class="pre">p</span></code> - respectively <code class="docutils literal notranslate"><span class="pre">(p),</span> <span class="pre">{p},</span> <span class="pre">&lt;p&gt;,</span> <span class="pre">[p]</span></code>.</p></li>
</ul>
<p>“Selective” combinators  (Mokhov et al. 2019) decide which branch to take based on the result of another parser, somewhere between monads and applicatives. For example <code class="docutils literal notranslate"><span class="pre">branch</span> <span class="pre">either</span> <span class="pre">left</span> <span class="pre">right</span></code> parses <code class="docutils literal notranslate"><span class="pre">either</span></code>, then, if successful and <code class="docutils literal notranslate"><span class="pre">Left</span></code> is returned, tries <code class="docutils literal notranslate"><span class="pre">left`,</span> <span class="pre">otherwise,</span> <span class="pre">if</span> <span class="pre">``Right</span></code> is produced, the parser <code class="docutils literal notranslate"><span class="pre">right</span></code> is executed. This can be mimicked without the dependent behavior by narrowing the productions, <code class="docutils literal notranslate"><span class="pre">eitherL</span> <span class="pre">left</span> <span class="pre">&lt;|&gt;</span> <span class="pre">eitherR</span> <span class="pre">right</span></code> where <code class="docutils literal notranslate"><span class="pre">eitherL</span></code> is the language of <code class="docutils literal notranslate"><span class="pre">either</span></code> that returns <code class="docutils literal notranslate"><span class="pre">Left</span></code> and similarly for <code class="docutils literal notranslate"><span class="pre">eitherR</span></code>. I don’t really like having to compute the set of all strings for which a function returns a given value, so it seems good to avoid this. But maybe it can be implemented easily.</p>
<p>Per <span id="id10">[]</span> it is worth exposing the derivative function as a parser combinator <code class="docutils literal notranslate"><span class="pre">feed</span> <span class="pre">p</span> <span class="pre">c</span> <span class="pre">=</span> <span class="pre">p</span> <span class="pre">&lt;&lt;</span> <span class="pre">c</span></code>. It’s not clear though if this functionality is useful without being able to do monadic bind and write something like <code class="docutils literal notranslate"><span class="pre">char</span> <span class="pre">&gt;&gt;=</span> <span class="pre">\c</span> <span class="pre">-&gt;</span> <span class="pre">feed</span> <span class="pre">p</span> <span class="pre">c</span></code>.</p>
<p>Layout: per <span id="id11">[<a class="reference internal" href="../zzreferences.html#id56" title="Sebastian Erdweg, Tillmann Rendel, Christian Kästner, and Klaus Ostermann. Layout-sensitive generalized parsing. In David Hutchison, Takeo Kanade, Josef Kittler, Jon M. Kleinberg, Friedemann Mattern, John C. Mitchell, Moni Naor, Oscar Nierstrasz, C. Pandu Rangan, Bernhard Steffen, Madhu Sudan, Demetri Terzopoulos, Doug Tygar, Moshe Y. Vardi, Gerhard Weikum, Krzysztof Czarnecki, and Görel Hedin, editors, Software Language Engineering, volume 7745, pages 244–263. Springer Berlin Heidelberg, Berlin, Heidelberg, 2013. URL: http://link.springer.com/10.1007/978-3-642-36089-3_14 (visited on 2020-06-15), doi:10.1007/978-3-642-36089-3_14.">ERKO13</a>]</span>, can be implemented with “layout constraints”, specialized semantic predicates. The constraints examine the starting/ending line and column of the first/last/leftmost of middle lines/rightmost of middle lines characters of each direct sub-tree of the parse. Then they can express boolean formulas of comparison constraints (equal, less than, greater than), e.g. the offside rule is <code class="docutils literal notranslate"><span class="pre">1.first.startCol</span> <span class="pre">&lt;</span> <span class="pre">1.left.startCol</span></code>. <span id="id12">[]</span> says it can be done in a more principled manner by annotating each production with its column and using constraints that the sub-production must be at column 0 or must be equal, greater than, or greater than or each to to the column of the start of of the production. <span id="id13">[<a class="reference internal" href="../zzreferences.html#id7" title="Luís Eduardo de Souza Amorim, Michael J. Steindorfer, Sebastian Erdweg, and Eelco Visser. Declarative specification of indentation rules: a tooling perspective on parsing and pretty-printing layout-sensitive languages. In Proceedings of the 11th ACM SIGPLAN International Conference on Software Language Engineering - SLE 2018, 3–15. Boston, MA, USA, 2018. ACM Press. URL: http://udesou.info/wp-content/uploads/2018/10/layout-pp.pdf (visited on 2020-06-15), doi:10.1145/3276604.3276607.">ASEV18</a>]</span> specifies some higher-level constaints like <code class="docutils literal notranslate"><span class="pre">align</span></code> that can be used for both parsing (translating to column-based layout constraints) and for pretty-printing, and gives the full algorithm for incrementally constructing parse trees with column information.</p>
<section id="type">
<h3>Type<a class="headerlink" href="#type" title="Permalink to this heading"></a></h3>
<p>Per <span id="id14">[]</span>, the nominal type of a parser combinator is <span class="math notranslate nohighlight">\(A^* \to P(T \times A^*)\)</span>, where <code class="docutils literal notranslate"><span class="pre">T</span></code> is the type of parse trees and <code class="docutils literal notranslate"><span class="pre">A</span></code> the type of tokens. Similarly <span id="id15">[]</span> uses the Haskell type <code class="docutils literal notranslate"><span class="pre">Parser</span> <span class="pre">s</span> <span class="pre">t</span> <span class="pre">=</span> <span class="pre">[s]</span> <span class="pre">-&gt;</span> <span class="pre">[(t,[s])]</span></code>. Let’s compare this simple nominal type with the definitions in actual libraries, namely <a class="reference external" href="https://hackage.haskell.org/package/parsec-3.1.16.1/docs/Text-Parsec-Prim.html">parsec</a>, <a class="reference external" href="https://hackage.haskell.org/package/trifecta-2.1.2/docs/Text-Trifecta-Parser.html">Trifecta</a>, <a class="reference external" href="https://hackage.haskell.org/package/attoparsec-0.14.4/docs/Data-Attoparsec-Internal-Types.html#t:Parser">Attoparsec</a>, and <a class="reference external" href="https://hackage.haskell.org/package/megaparsec-9.3.0/docs/Text-Megaparsec-Internal.html#t:ParsecT">Megaparsec</a>. These are collected in Parser.hs. First note that most definitions (implicitly) use <code class="docutils literal notranslate"><span class="pre">CodensityT</span> <span class="pre">m</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">forall</span> <span class="pre">b.</span> <span class="pre">(a</span> <span class="pre">-&gt;</span> <span class="pre">m</span> <span class="pre">b)</span> <span class="pre">-&gt;</span> <span class="pre">m</span> <span class="pre">b</span></code>, because <code class="docutils literal notranslate"><span class="pre">(a</span> <span class="pre">-&gt;</span> <span class="pre">r)</span> <span class="pre">-&gt;</span> <span class="pre">(b</span> <span class="pre">-&gt;</span> <span class="pre">r)</span> <span class="pre">-&gt;</span> <span class="pre">r</span> <span class="pre">=</span> <span class="pre">(Either</span> <span class="pre">a</span> <span class="pre">b</span> <span class="pre">-&gt;</span> <span class="pre">r)</span> <span class="pre">-&gt;</span> <span class="pre">r</span></code>. The codensity monad’s sole purpose is to right-associate the monad bind to increase performance, so we can simplify the type by removing it, replacing <code class="docutils literal notranslate"><span class="pre">CodensityT</span> <span class="pre">m</span> <span class="pre">a</span></code> with <code class="docutils literal notranslate"><span class="pre">m</span> <span class="pre">a</span></code>. Also, some parser types act as monad transformers; this is not really relevant either so we can assume pure parsing <code class="docutils literal notranslate"><span class="pre">m=Identity</span></code>. The type of the parse result is a parameter; it simplifies things to just assume the parser builds up the AST as a fixed type <code class="docutils literal notranslate"><span class="pre">ParseTree</span></code>. Similarly we can standardize <code class="docutils literal notranslate"><span class="pre">[Byte]</span></code> as the input type, at least while we’re designing.  Regarding trifecta’s rope, kmett <a class="reference external" href="https://github.com/ekmett/trifecta/issues/49#issuecomment-322073854">says</a> he’s exploring removing the rope machinery entirely, so it can be simplified to <code class="docutils literal notranslate"><span class="pre">[Byte]</span></code> as well. Considering parsec’s <code class="docutils literal notranslate"><span class="pre">State</span></code> type, it seems <cite>u = ()`</cite> in almost all cases, but maintaining a separate <code class="docutils literal notranslate"><span class="pre">State</span></code> type as an extension point is reasonable, so we replace <code class="docutils literal notranslate"><span class="pre">([Byte],Pos,...)</span></code> with <code class="docutils literal notranslate"><span class="pre">State</span></code> in the other parsers. At this point, all the parsers are of the form <code class="docutils literal notranslate"><span class="pre">Parser</span> <span class="pre">=</span> <span class="pre">State</span> <span class="pre">-&gt;</span> <span class="pre">...</span> <span class="pre">|</span> <span class="pre">Ok</span> <span class="pre">ParseTree</span> <span class="pre">State</span></code>, differing only in the handling of errors and incomplete input. So yes, the nominal type is pretty close to actual behavior. The main differences are tracking position in the <code class="docutils literal notranslate"><span class="pre">State</span></code> type,  and also that these libraries use PEG-style backtracking, hence only return a single parse tree and have to handle errors specially, whereas derivatives and other non-deterministic parsers return a set of parses, modelling multiple or zero parses more naturally.</p>
</section>
</section>
<section id="output">
<h2>Output<a class="headerlink" href="#output" title="Permalink to this heading"></a></h2>
<p>The main output of the parser is an AST. DMS extols automatic AST construction - the grammar is the documentation for the AST, and it allows rapid development of complex grammars. I tend to agree; parsec’s profusion of tuple-returning concatenation operators shows that people want to be lazy and work with an untyped tree. It’s just Haskell’s distaste for heterogeneous lists that forces an ADT, and the lack of any standard parse result type that leads to the typed AST result parameter. DMS can apparently drop nodes and contract unary nodes, but I think this goes against the spirit of automation. The result should be completely automatic, with no annotations allowed - any further efforts should be post-processing. This ensures a uniform representation of the parse tree, and enables reformatting.</p>
<p>The use of combinators instead of BNF does complicate the definition of AST a bit. We need some concept that merges callstacks with AST trees.</p>
<p>Per <span id="id16">[]</span> section 2.4 pages 17-20, it is desirable to produce all possible parses and disambiguate them afterwards. However, the number of parses of a grammar <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">=</span> <span class="pre">A</span> <span class="pre">A</span> <span class="pre">|</span> <span class="pre">anyChar</span></code> grows as the Catalan numbers, which tends to <span class="math notranslate nohighlight">\(O(4^n / n^{3/2})\)</span>, basically exponential, and cyclic grammars may have an infinite number of parses. A compact representation is needed. Tomita describes a “shared packed parse forest”. Sharing deduplicates identical sub-trees - each node is identified by a pointer and the sub-tree relation is represented by a points-to, so that a node may have multiple parents. Packing localizes ambiguity - it creates “packed nodes” that represent a certain non-terminal symbol and parse span, with each subnode of the packed node representing a different parse. However, per <span id="id17">[]</span>, a grammar like <code class="docutils literal notranslate"><span class="pre">S</span> <span class="pre">=</span> <span class="pre">a</span> <span class="pre">|</span> <span class="pre">S</span> <span class="pre">S</span> <span class="pre">|</span> <span class="pre">S^{m+2}</span></code> and string of “a”s of length <span class="math notranslate nohighlight">\(n\)</span> requires constructing at least <span class="math notranslate nohighlight">\(O(n^m)\)</span> nodes, due to having to represent all the positions. The solution per <span id="id18">[]</span> is binarization: splitting a node with n child trees into a right-biased sequence of nodes where each node has two children. More specifically, binarization converts a production <code class="docutils literal notranslate"><span class="pre">S</span> <span class="pre">=</span> <span class="pre">A</span> <span class="pre">B</span> <span class="pre">C</span></code> to productions <code class="docutils literal notranslate"><span class="pre">S1</span> <span class="pre">=</span> <span class="pre">A</span> <span class="pre">S2;</span> <span class="pre">S2</span> <span class="pre">=</span> <span class="pre">B</span> <span class="pre">C</span></code>, where the new non-terminals are unique. Then one obtains cubic parsing <span class="math notranslate nohighlight">\(O(n^3 G)\)</span> where <span class="math notranslate nohighlight">\(n\)</span> is the length and <span class="math notranslate nohighlight">\(G`\)</span> is the size of the (normalized) grammar.</p>
<p>to ensure that the RNGLR algorithm recognises sentences in cubic time. However,
we would need to use different non-terminals for each replacement to be sure that
the language remains unchanged. For example, we cannot rewrite the grammar
S ′</p>
<blockquote>
<div><p>::=
S</p>
</div></blockquote>
<p>as</p>
<dl class="simple">
<dt>X</dt><dd><p>::=
SS | cS</p>
</dd>
</dl>
<p>because the latter grammar generates the string bcb while the first grammar
contains only sentences with an even number of c’s.
Introducing new non-terminals to factorise the grammar can substantially
increase both the number of rows and the number of columns in the parse table.</p>
<p><span id="id19">[]</span> there is a grammar</p>
<p>BRNGLR [17] builds a modified form of SPPF and is worst case cubic order.
<span id="id20">[]</span> gives two Earley parsers, both of which are worst case cubic space and time.</p>
<p>all classical parsing algorithms are based on the (non-deterministic) pushdown automaton (PDA) model (it is not always very visible, but it is always there). LR(k) are just deterministic PDAs built in some systematic way (when possible), that correspond to a technique using the grammar to walk the (unique) parse-tree as efficiently as possible. These techniques are limited to subclasses of CF grammars and languages.</p>
<p>The general context-free parsing algorithms can handle all CF grammars and languages. They are usually built using the very same techniques, but the consruction accepts that there may be conflicts in the the steps to be applied. These conflicts are simply non-deterministic choices. But the construction is basically the same as in the deterministic case. That means that the resulting non-deterministic PDA can walk all possible parse-trees, sometimes having to walk parse-tree fragments that do not belong to a full parse-tree (for example in unambiguous CF languages that are not deterministic).</p>
<p>So these algorithms walk all parse-trees, independently of whether they actually produce these parse-trees as output. There may be exponentially many (even sometimes infinitely many) such parse trees. The General CF parsers use a tabular (dynamic programming / memoization) technique to share computation, in order to do the work a bit faster. They all use the same tabular technique (from an abstract point of view) and get all the same worst case complexity O(n3)
. They may however differ on some example, for example if a grammar falls in the domain wherhe one PDA construction gives a dterministic PDA, while another does not. But they all have O(n3)</p>
<p>time complexity when there are exponentially many parse trees as in your example.</p>
<p>I do not believe I ever encountered a parsing algorithm that does not fall in this schematic description (up to some bells and whistles). This is essentially the basis of the work in the Billot &amp; Lang paper cited above.</p>
<p>Now, as I said, if you are not interested in parse-tree, you can always modify one of these algorithms to do better in some cases. For example, as I said, the rules S→SS∣a
could be noticed by the recognizer (no longer parser) construction technique, and replaced by the simpler rules S→aS∣a</p>
<p>. But then it is no longer the same “parsing” algorithm.</p>
<p>For an analysis of tree sharing into forests and the effect on parsing complexity, you may want to read “Observations on Context Free Parsing” by Beau Sheil In Statistical Methods in Linguistics, 1976:71-109. The point is that all general CF parsing algorithms walk this shared forest completely. And it has size O(n3)</p>
<p>for your example grammar.
Share
Cite
Improve this answer
Follow
edited Apr 13, 2017 at 12:32
Community’s user avatar
CommunityBot
1
answered May 21, 2014 at 0:26
babou’s user avatar
babou
1,5321010 silver badges1717 bronze badges</p>
<blockquote>
<div><p>Let me clarify things, so maybe you can give a concrete answer. The worst case grammars look like something S ::= SSS | SS | a, which were introduced by Mark Johnson in the paper “the complexity of glr parsing” to show the worst case O(n^k). I don’t question the general case, but just this simple grammar. It may indeed be the worst case, but I need proof, using any algorithm is fine. I tried this grammar using a GLL parser and to me it looks like the number of steps is bounded by O(n^2). However, because of left-recursion termination in GLL is pretty hard for me to analyse it. –
Wickoo
May 21, 2014 at 0:57</p>
</div></blockquote>
<p>I suggested GLR because I thought maybe it’s easier as left-recursion is encoded in the parse table and search space is not affected by that. So I can reformulate this question: can someone theoretically, regardless of any algorithm and using some combinatorial formulas and taking sharing into account tell me what’s the upper bound of parsing this grammar? Can you give me reasons in terms of any particular parsing algorithm. –
Wickoo
May 21, 2014 at 1:02
I still don’t see a concrete answer or a sketch of proof here. You are just giving general facts that I’m aware of. You are right about S ::= S S S that it is used to show o(n^k), as i already said myself. My point was that that grammar is much more ambiguous compared to E ::= E + E. So, you’re saying that any ambiguous grammar triggers worst case complexity? My question os that this example seems simpler that worst case and my experiments also show that. Can someone prove it? Or show that it is not the case. –
Wickoo
May 21, 2014 at 10:19
The sketch of a proof is: all general CF algorithms walk the whole forest, because that is what they are built for. Whatever computation sharing they do is forest sharing. Shared forest representation is cubic in general, and always so for exponential ambiguity (which is your case). Hence all those parsers will be cubic on your grammar example. As I said, this is only a sketch, on which an actual proof can be built by checking all the claims. Johnson’s example is not much more ambiguous than your: both are exponential and that is all that matters. The fact you ignore parse trees is irrelevant. –
babou
May 21, 2014 at 11:01
You may be right, but I’m not convinced yet by your argument. How do you define exponential ambiguity? I suggest you run the grammar to see that in practice it doesn’t trigger the worst case, but SSS does. –
Wickoo
May 21, 2014 at 11:35
Exponential ambiguity = exponential number of parse trees. What difference do you see with SSS, compared to SS. - - - - - - - - - - - - - - - One way to get a better bound, while retaining the general approach of these parsing algorithms, would be to find a more compact shared representation of parse-forests that can be walked as well to simulate all parse-tree walks. But even then, this would no longer be one of the classical general CF algorithms. It would be a very interesting result, though … but I doubt there is anything to be found. –
babou
May 21, 2014 at 11:43
&#64;Ali I do not have the software (and time) to run examples. but there are some figures in the Billot-Lang paper, though probably not enough to actually show that the parsing is cubic. Look at the appendix C. –
babou
May 21, 2014 at 11:52
Thanks! Appendix C shows a similar grammar A ::= AA | x named UBDA. I saw a proof in the original Early paper that that this grammar has O(n^3) bound. I redid my experiments, and for very large inputs, 800 a’s, I’ll get the cubic growth rate. I guess the reason I concluded that it may not be cubic was that its growth was much smaller than SSS, and I ran the experiments for inputs of size 200 which shows the cubic behaviour for SSS but not for E+E, but still they are both worst case cubic. –
Wickoo
May 21, 2014 at 13:17
&#64;Ali Good you succeeded. How did you do your measurements? If you measure execution time, you always have to be careful with small values as they may hide behind system overhead. On the other hand, large values sometimes trigger garbage collection. There are more formal ways of measuring that avoid these pitfalls, but it is sometimes more work, or delicate to set up accurately. –
babou
May 21, 2014 at 13:34
I do it in the pretty standard way of measuring the performance of Java programs. Warm up and then average result with throwing out the outliers. I also take the System time instead of nano time to take GC and other noise out (as much as possible). The problem with E + E was it was reaching the n^3 quite late. I basically was doubling the input and measuring if the time was was 8 times bigger, it was much less than 8. The first time I observed 8 was increasing from 400 a’s to 800 a’s. For the other grammar it is much easier to observe the cubic behaviour and that misleaded me. –
Wickoo
May 21, 2014 at 17:30
&#64;Ali This is a bit strange. Maybe there is heavy initialization cost. Would you mind sending me the times you got for various values of n, especially those below the 400. Here or at babou(at)inbox.com –
babou
May 21, 2014 at 17:58
Sure, the numbers are on my workstation at work. I will send them to you tomorrow. –
Wickoo
May 21, 2014 at 18:48</p>
<p>However,</p>
<blockquote>
<div><p>shared packed parse forests (SPPFs), which allows efficiently representing parses using only cubic space.</p>
</div></blockquote>
<p>SPPF
BSRs</p>
<p>If we compile a scannerless parser, we should be able to get the regular portion of the grammar to be a finite  state automaton, and the context-free to use at most memory proportional to the maximum expression depth. There is also some amount of state explosion in the conversion from nondeterministic to deterministic, so the compiled code may be large and we can trade-off compiled states and runtime memory usage. But many standard techniques of optimizing programs apply, so getting scannerless parsers to have performance competitive with hand-rolled recursive descent parsers is a possibility. Comparing with conventional two-level parsers is possible as well but is not really fair since two-level parsers are not very expressive grammar-wise and are generally table-based rather than directly generating machine code. Looking at <span id="id21">[]</span> which does LLVM compilation and parses directly from UTF-8 encoded bytes, we should expect about a 3x speedup for properly compiling the grammar, vs. using a decent table-based implementation (re2 vs redgrep, second non-trivial regex example).</p>
<p>The EBNF formalisms complicate building an AST automatically, and can be encoded in straight BNF.</p>
</section>
<section id="algorithm">
<h2>Algorithm<a class="headerlink" href="#algorithm" title="Permalink to this heading"></a></h2>
<p>PEG is popular, but uses backtracking, which is not efficient enough on highly ambiguous grammars. The original Packrat paper proposed to use memoization to get linear time, but this uses memory proportional to the size of the input file, so is not really a good option compared to other methods. There is also the issue that PEG doesn’t natively support left recursion, but per some paper’s trick, this can be worked around in a parse-preserving manner by splitting each production into definitely-null, possibly-null, and not-null productions, e.g. for <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">=</span> <span class="pre">A</span> <span class="pre">B</span> <span class="pre">|</span> <span class="pre">C</span></code>:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="kt">A</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">Anull</span><span class="w"> </span><span class="kt">B</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="kt">Anotnull</span><span class="w"> </span><span class="kt">B</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="kt">C</span>
<span class="kt">Anull</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="o">&lt;</span><span class="n">empty</span><span class="o">&gt;</span>
<span class="kt">Anotnull</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">Anull</span><span class="w"> </span><span class="kt">Bnotnull</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="kt">Cnotnull</span>
</pre></div>
</div>
<p>This does collapse trivial parses, but they are after all trivial and the possible parses of the empty string can simply be grafted onto the parse forest after-the-fact. But it makes life even simpler if trivial parses have trivial parse trees, since then there isn’t even a grafting step.</p>
<p>There are many algorithms: GLR, GLL, CYK, Earley, and derivatives. We want a single algorithm that combines the advantages of all. Derivatives are the newest, so that’s the place to start.</p>
<p>Also error recovery. Treesitter implements incremental LR parsing with error recovery.</p>
<blockquote>
<div><p><a class="reference external" href="https://github.com/attresearch/yakker">Yakker</a> is the most developed parser I’ve seen feature-wise. It’s only missing incremental parsing.</p>
</div></blockquote>
<p>to have a disambiguating pass on the set of parse tree generated by a nondeterministic automaton. The alternatives involve restricting parsers to be deterministic, for example PEGs. But PEGs have big issues with error detection and reporting, not to mention correct parsing. There’s just no information on what possible parses are available or what token is expected. Whereas with Earley you can do “Ruby slippers”: scan the sets for what they want next, output “warning: expected ‘;’ at end of statement”, and then add that to the parse forest and continue parsing with almost no overhead.</p>
<p>Revisiting this, the goal is to use partial evaluation to generate the parser, by speeding up a naive brute-force algorithm applied to the grammar. There is already a paper on LR parsing by partial evaluation <span id="id22">[<a class="reference internal" href="../zzreferences.html#id149" title="Michael Sperber and Peter Thiemann. Generation of LR parsers by partial evaluation. ACM Transactions on Programming Languages and Systems (TOPLAS), 22(2):224–264, March 2000. URL: http://dl.acm.org/doi/10.1145/349214.349219 (visited on 2020-06-15), doi:10.1145/349214.349219.">ST00</a>]</span> and also on specializing Earley, so with sufficiently powerful compiler optimization handling general grammars should be possible.</p>
<p>In particular the parser should be written as a nondeterministic finite state transducer that builds up trees (outputs a list in the style of start-children-end or S-expressions or something).</p>
<p>Formally:</p>
<ul class="simple">
<li><p>Q is a finite set, the set of states;</p></li>
<li><p>I is a subset of Q, the set of initial states;</p></li>
<li><p>F is a subset of Q, the set of final states; and</p></li>
<li><p>Σ is a finite set, called the input alphabet;</p></li>
<li><p>Γ is a finite set, called the output alphabet;</p></li>
<li><p>The transition function is of type <span class="math notranslate nohighlight">\(Q \times (\Sigma \cup \{\epsilon \})\to P(Q \times (\Gamma \cup \{\epsilon \}))\)</span>, where ε is the empty string and P(Q) denotes the power set of Q.</p></li>
</ul>
<p>// “Derivatives of Regular Expressions”
// Janusz Brzozowski
// Journal of the ACM, vol. 11 iss. 4, pp. 481-494, October 1964
// <a class="reference external" href="http://dl.acm.org/citation.cfm?id=321249">http://dl.acm.org/citation.cfm?id=321249</a>
//
// “Regular-expression derivatives re-examined”
// Scott Owens, John Reppy, Aaron Turon
// Journal of Functional Programming, vol. 19 iss. 2, pp. 173-190, March 2009
// <a class="reference external" href="http://dl.acm.org/citation.cfm?id=1520288">http://dl.acm.org/citation.cfm?id=1520288</a>
//
// “Partial Derivatives of Regular Expressions and Finite Automaton Constructions”
// Valentin Antimirov
// Theoretical Computer Science, vol. 155 iss. 2, pp. 291-319, March 1996
// <a class="reference external" href="http://dl.acm.org/citation.cfm?id=231848">http://dl.acm.org/citation.cfm?id=231848</a>
//
// “Partial Derivatives of an Extended Regular Expression”
// Pascal Caron, Jean-Marc Champarnaud, Ludovic Mignot
// Language and Automata Theory and Applications 2011, pp. 179-191, May 2011
// <a class="reference external" href="http://dl.acm.org/citation.cfm?id=2022911">http://dl.acm.org/citation.cfm?id=2022911</a>
//
// “A Flexible and Efficient ML Lexer Tool Based on Extended Regular Expression Submatching”
// Martin Sulzmann, Pippijn van Steenhoven
// Compiler Construction 2014, pp. 174-191, April 2014
// <a class="reference external" href="http://dx.doi.org/10.1007/978-3-642-54807-9_10">http://dx.doi.org/10.1007/978-3-642-54807-9_10</a>
//
// “Efficient submatch addressing for regular expressions”
// Ville Laurikari
// Master’s Thesis, November 2001
// <a class="reference external" href="http://laurikari.net/ville/regex-submatch.pdf">http://laurikari.net/ville/regex-submatch.pdf</a></p>
<p>Regular expression search algorithm Ken Thompson June 1968
<a class="reference external" href="http://dl.acm.org/citation.cfm?id=3363387">http://dl.acm.org/citation.cfm?id=3363387</a></p>
<p>regular expression derivatives to llvm
capturing groups are really kind of complicated
An grammar expression E matches a language S, namely a set of strings.</p>
<p>There are various problems. Their complexity:
Membership problem: Given a grammar G and string w, is w ∈ L(G)? - decidable for recursive grammars (includes context sensitive). Cubic time (actually matrix-mult time) for context-free grammars, by Earley or CYK.
Nullability: Given a grammar G, is ε ∈ L(G)? Decidable for context-free grammars, by normalizing (Chomsky normal form and removing useless productions) and inspecting the result (determining nullability of each rule)
Emptiness problem: is the language empty, i.e. given a grammar G, is L(G) = ∅? - solveable similar to nullability
Finiteness problem: is the language L(G) finite? - again solveable similar to nullability
Completeness problem: Does a grammar G match every string, i.e. L(G) = Σ*? - decidable for deterministic context-free gramars (LR(k) parseable)
Regularity problem: Does a grammar G describe a regular language, i.e. L(G) = L(R) for some regular grammar R? - decidable for deterministic context-free gramars (LR(k) parseable)
Equality problem: Given grammars G1, G2, is L(G1) = L(G2)? - decidable for deterministic context-free gramars.
Minimizing problem: Find smallest grammar G’ with L(G) = L(G’). - decidable for deterministic context-free gramars.
Subset problem: Is L1 subset of L2? - decidable for regular languages
Overlap problem: Is L1 intersection of L2 = null? - decidable for regular languages
Complement: closed for recursive languages but not recurisvely enumerable languages
Intersection: closed for recursively enumerable languages</p>
<p>it’s easier and faster to match in a byte oriented way than to decode utf-8 in a preprocessing step. It works because there is only one representation of each character as a UTF-8 byte sequence.</p>
<p>Normalizing/compacting grammars is important for equality comparison and efficiency:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span>(r∗)∗ ≈ r∗
∅∗ ≈ ε
ε∗ ≈ ε
\C∗ ≈ ¬∅
(r · s) · t ≈ r · (s · t)
∅ · r ≈ ∅
r · ∅ ≈ ∅
ε · r ≈ r
r · ε ≈ r
¬(¬r) ≈ r
∅ &amp; r ≈ ∅
r &amp; ∅ ≈ ∅
(r &amp; s) &amp; t ≈ r &amp; (s &amp; t)
r &amp; s ≈ s &amp; r
r &amp; r ≈ r
¬∅ &amp; r ≈ r
r &amp; ¬∅ ≈ r
¬∅ + r ≈ ¬∅
r + ¬∅ ≈ ¬∅
(r + s) + t ≈ r + (s + t)
r + s ≈ s + r
r + r ≈ r
∅ + r ≈ r
r + ∅ ≈ r
</pre></div>
</div>
<p>A nullable expression is one that matches the empty string. Nullability is important to know, as the derivative of a concatenation (defined next) depends on whether the first expression is nullable. Recursion is handled via the least fixed point of the equations (e.g., <code class="docutils literal notranslate"><span class="pre">L</span> <span class="pre">=</span> <span class="pre">L</span> <span class="pre">&amp;</span> <span class="pre">L</span></code> is not nullable).</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span>ν(∅) = F
ν(ε) = T
ν(\C) = F
ν(&#39;a&#39;) = F
ν(S) = F
ν(r∗) = T
ν(r · s) = ν(r) &amp;&amp; ν(s)
ν(¬r) = not ν(r)
ν(r &amp; s) = ν(r) &amp;&amp; ν(s)
ν(r + s) = ν(r) || ν(s)
</pre></div>
</div>
<p>The derivative of an grammar expression E with respect to a character (or set of strings) C is a grammar expression d_C E such that its language is { s : exists c in C. c s in L(E) }. I.e., you take the strings in L(E) that begin with C, and then you chop off the C. For example the derivative of <code class="docutils literal notranslate"><span class="pre">ab|ac|de</span></code> w.r.t. <code class="docutils literal notranslate"><span class="pre">a</span></code> is <code class="docutils literal notranslate"><span class="pre">b|c</span></code>. Some derivatives are as follows:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span>∂a ∅ = ∅
∂a ε = ∅
∂a \C = ε
∂a a = ε
∂a b = ∅ for b ≠ a
∂a S = ε if a ∈ S
       ∅ if a ∉ S
∂a (r∗) = ∂ar · r∗
∂a (r · s) = ∂ar · s + (ν(r) ? ε : ∅) · ∂as
∂a (¬r) = ¬(∂ar)
∂a (r &amp; s) = ∂ar &amp; ∂as
∂a (r + s) = ∂ar + ∂as
</pre></div>
</div>
<p>With this we can already implement an interpreter-style recognizer, by computing the derivative on the fly. The loop is read next char, compute derivative, normalize, repeat. Then at EOF the input string matched if the final grammar expression is nullable.</p>
<p>To compile a derivative parser to a DFA, we do a traversal of the state graph of grammar expressions, e.g. depth-first. Starting at the original expression <code class="docutils literal notranslate"><span class="pre">E</span></code>, we compute successive derivatives with respect to all possible characters, normalize the resulting expressions, and minimize the resulting DFA state graph by interning equivalent grammar expressions. The nullable expressions are accepting states. The textbook approach to compiling regular expressions constructs an NFA, constructs the DFA from that, and then minimizes the DFA. But derivative parsing allows you to avoid the NFA entirely, and produces a result much closer to the minimal DFA right off the bat, saving a lot of work.</p>
<p>An important speedup of minimization is identifying partitions of state transitions w.r.t. byte values. Basically, rather than computing the derivatives w.r.t. 0, 1, 2, up to 255 individually and checking for equality afterwards, you can determine from the structure of the expression that it can transition to up to n other states and that each of some set of byte values will transition to a given state. This can be represented by n bitsets of length 256 for n possible next states, with the AND of any two bitsets 0 and the OR of all of them the bitset of all 1’s (basically redgrep’s representation, although it specifically inverts the first one to model it as a “default” case), or as a packed array-table with ceil(log_2(n)) bits for each byte value, or maybe with ranges if the states are generally clustered in contiguous ranges. The rules for partitions are as follows:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span>C(∅) = {Σ}
C(ε) = {Σ}
C(\C) = {Σ}
C(a) = {Σ \ a, a}
C(S) = {Σ \ S, S}
C(r∗) = C(r)
C(r · s) = C(r) ∧ C(s) if ν(r) = ε
           C(r)        if ν(r) = ∅
C(¬r) = C(r)
C(r &amp; s) = C(r) ∧ C(s)
C(r + s) = C(r) ∧ C(s)
</pre></div>
</div>
<p>With the DFA in hand, we can implement a table-based recognizer: just read the character, look up the state, and at EOF check if the state’s corresponding grammar is nullable. But LLVM is more interesting. The overall function takes a pointer and length, and jumps to state 0’s initial block. Then, for each DFA state, we create two basic blocks. The first (entry) one checks if we’ve hit the end of the string, and branches to return true or return false depending on whether the state was accepting. Otherwise it branches to the second basic block. The second basic block increments the pointer, decrements the length, and then enters a C-style switch on the current byte. Each case is simply a jump to the basic block corresponding to the next state. We need two main optimizations, register allocation and loop removal. Also LLVM optimizes the switch.</p>
<p>An important speed-up is vectorization - examine a glob of memory at once, use vector operations to compare all of them at once, and then reduce the result. Byte-at-a-time is 1.1 GB/s, vectorized is 12 GB/s and memory-constrained. For example look at memchr from libc.</p>
<p>Going from a recognizer to a parser, we must produce a parse tree. So rather than looking at the language (set of strings), we consider the set of pairs <code class="docutils literal notranslate"><span class="pre">(string,tree)</span></code>.</p>
<blockquote>
<div><blockquote>
<div><dl>
<dt>if (IsNullable(exp)) {</dt><dd><blockquote>
<div><p>fa-&gt;accepting_[curr] = true;
if (tagged) {</p>
<blockquote>
<div><p>TNFA* tnfa = reinterpret_cast&lt;TNFA*&gt;(fa);
EpsilonBindings(exp, &amp;tnfa-&gt;final_[curr]);</p>
</div></blockquote>
<p>}</p>
<dl>
<dt>if (tagged) {</dt><dd><p>TNFA* tnfa = reinterpret_cast&lt;TNFA*&gt;(fa);
Outer outer = Partial(exp, byte);
std::set&lt;std::pair&lt;int, Bindings&gt;&gt; seen;
for (const auto&amp; j : <a href="#id23"><span class="problematic" id="id24">*</span></a>outer) {</p>
<blockquote>
<div><p>Exp par = Normalised(j.first);
int next = LookupOrInsert(par);
if (seen.count(std::make_pair(next, j.second)) == 0) {</p>
<blockquote>
<div><p>seen.insert(std::make_pair(next, j.second));
if (i == partitions-&gt;begin()) {</p>
<blockquote>
<div><p>// Set the “default” transition.
tnfa-&gt;transition_.insert(std::make_pair(</p>
<blockquote>
<div><p>std::make_pair(curr, byte), std::make_pair(next, j.second)));</p>
</div></blockquote>
</div></blockquote>
<dl>
<dt>} else {</dt><dd><dl>
<dt>for (int byte = 0; byte &lt; 256; ++byte) {</dt><dd><dl class="simple">
<dt>if (i-&gt;test(byte)) {</dt><dd><dl class="simple">
<dt>tnfa-&gt;transition_.insert(std::make_pair(</dt><dd><p>std::make_pair(curr, byte), std::make_pair(next, j.second)));</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>}</p>
</dd>
<dt>} else {</dt><dd><p>DFA* dfa = reinterpret_cast&lt;DFA*&gt;(fa);
Exp der = Derivative(exp, byte);
der = Normalised(der);
int next = LookupOrInsert(der);
if (i == partitions-&gt;begin()) {</p>
<blockquote>
<div><p>// Set the “default” transition.
dfa-&gt;transition_[std::make_pair(curr, byte)] = next;</p>
</div></blockquote>
<dl>
<dt>} else {</dt><dd><dl>
<dt>for (int byte = 0; byte &lt; 256; ++byte) {</dt><dd><dl class="simple">
<dt>if (i-&gt;test(byte)) {</dt><dd><p>dfa-&gt;transition_[std::make_pair(curr, byte)] = next;</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
</div></blockquote>
<p>}
return states.size();</p>
</div></blockquote>
<p>}</p>
<dl class="simple">
<dt>size_t Compile(Exp exp, TNFA* tnfa) {</dt><dd><p>return CompileImpl(exp, true, tnfa);</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>bool Match(const DFA&amp; dfa, llvm::StringRef str) {</dt><dd><p>int curr = 0;
while (!str.empty()) {</p>
<blockquote>
<div><p>int byte = str[0];
str = str.drop_front(1);
auto transition = <a href="#id43"><span class="problematic" id="id44">dfa.transition_</span></a>.find(std::make_pair(curr, byte));
if (transition == <a href="#id45"><span class="problematic" id="id46">dfa.transition_</span></a>.end()) {</p>
<blockquote>
<div><p>// Get the “default” transition.
transition = <a href="#id47"><span class="problematic" id="id48">dfa.transition_</span></a>.find(std::make_pair(curr, -1));</p>
</div></blockquote>
<p>}
int next = transition-&gt;second;
curr = next;</p>
</div></blockquote>
<p>}
return dfa.IsAccepting(curr);</p>
</dd>
</dl>
<p>}</p>
<p>// Applies the Bindings to offsets using pos.
static void ApplyBindings(const Bindings&amp; bindings,</p>
<blockquote>
<div><blockquote>
<div><p>int pos,
std::vector&lt;int&gt;* offsets) {</p>
</div></blockquote>
<dl>
<dt>for (const auto&amp; i<span class="classifier">bindings) {</span></dt><dd><p>int l = 2 * i.first + 0;
int r = 2 * i.first + 1;
switch (i.second) {</p>
<blockquote>
<div><dl>
<dt>case kCancel:</dt><dd><dl class="simple">
<dt>if ((<a href="#id25"><span class="problematic" id="id26">*</span></a>offsets)[l] != -1) {</dt><dd><p>(<a href="#id27"><span class="problematic" id="id28">*</span></a>offsets)[l] = -1;
(<a href="#id29"><span class="problematic" id="id30">*</span></a>offsets)[r] = -1;</p>
</dd>
</dl>
<p>}
continue;</p>
</dd>
</dl>
<p>case kEpsilon:
case kAppend:</p>
<blockquote>
<div><dl class="simple">
<dt>if ((<a href="#id31"><span class="problematic" id="id32">*</span></a>offsets)[l] == -1) {</dt><dd><p>(<a href="#id33"><span class="problematic" id="id34">*</span></a>offsets)[l] = pos;
(<a href="#id35"><span class="problematic" id="id36">*</span></a>offsets)[r] = pos;</p>
</dd>
</dl>
<p>}
if (i.second == kAppend) {</p>
<blockquote>
<div><p>++(<a href="#id37"><span class="problematic" id="id38">*</span></a>offsets)[r];</p>
</div></blockquote>
<p>}
continue;</p>
</div></blockquote>
</div></blockquote>
<p>}
abort();</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
<dl>
<dt>bool Match(const TNFA&amp; tnfa, llvm::StringRef str,</dt><dd><blockquote>
<div><p>std::vector&lt;int&gt;* offsets) {</p>
</div></blockquote>
<p>std::list&lt;std::pair&lt;int, std::vector&lt;int&gt;&gt;&gt; curr_states;
curr_states.push_back(std::make_pair(0, std::vector&lt;int&gt;(2 * <a href="#id49"><span class="problematic" id="id50">tnfa.modes_</span></a>.size(), -1)));
int pos = 0;
while (!str.empty()) {</p>
<blockquote>
<div><p>int byte = str[0];
str = str.drop_front(1);
// For each current state, determine the next states - applying Bindings -
// and then sort them by comparing offsets. Doing this repeatedly from the
// initial state and discarding next states that have been seen already in
// the current round is intended to simulate a VM implementation.
std::list&lt;std::pair&lt;int, std::vector&lt;int&gt;&gt;&gt; next_states;
std::set&lt;int&gt; seen;
for (const auto&amp; i : curr_states) {</p>
<blockquote>
<div><p>int curr = i.first;
std::pair&lt;int, int&gt; key = std::make_pair(curr, byte);
auto transition = <a href="#id51"><span class="problematic" id="id52">tnfa.transition_</span></a>.lower_bound(key);
if (transition == <a href="#id53"><span class="problematic" id="id54">tnfa.transition_</span></a>.upper_bound(key)) {</p>
<blockquote>
<div><p>// Get the “default” transition.
key = std::make_pair(curr, -1);
transition = <a href="#id55"><span class="problematic" id="id56">tnfa.transition_</span></a>.lower_bound(key);</p>
</div></blockquote>
<p>}
std::list&lt;std::pair&lt;int, std::vector&lt;int&gt;&gt;&gt; tmp;
while (transition != <a href="#id57"><span class="problematic" id="id58">tnfa.transition_</span></a>.upper_bound(key)) {</p>
<blockquote>
<div><p>int next = transition-&gt;second.first;
if (seen.count(next) == 0 &amp;&amp;</p>
<blockquote>
<div><blockquote>
<div><p>!tnfa.IsError(next)) {</p>
</div></blockquote>
<p>seen.insert(next);
std::vector&lt;int&gt; copy = i.second;
ApplyBindings(transition-&gt;second.second, pos, &amp;copy);
tmp.push_back(std::make_pair(next, copy));</p>
</div></blockquote>
<p>}
++transition;</p>
</div></blockquote>
<p>}
tmp.sort(CompareOffsets);
next_states.insert(next_states.end(), tmp.begin(), tmp.end());</p>
</div></blockquote>
<p>}
curr_states.swap(next_states);
++pos;</p>
</div></blockquote>
<p>}
for (const auto&amp; i : curr_states) {</p>
<blockquote>
<div><p>int curr = i.first;
if (tnfa.IsAccepting(curr)) {</p>
<blockquote>
<div><p>std::vector&lt;int&gt; copy = i.second;
ApplyBindings(<a href="#id59"><span class="problematic" id="id60">tnfa.final_</span></a>.find(curr)-&gt;second, pos, &amp;copy);
offsets-&gt;resize(2 * <a href="#id61"><span class="problematic" id="id62">tnfa.captures_</span></a>.size());
for (size_t j = 0; j &lt; <a href="#id63"><span class="problematic" id="id64">tnfa.captures_</span></a>.size(); ++j) {</p>
<blockquote>
<div><p>(<a href="#id39"><span class="problematic" id="id40">*</span></a>offsets)[2 * j + 0] = copy[2 * tnfa.captures_[j] + 0];
(<a href="#id41"><span class="problematic" id="id42">*</span></a>offsets)[2 * j + 1] = copy[2 * tnfa.captures_[j] + 1];</p>
</div></blockquote>
<p>}
return true;</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>}
return false;</p>
</dd>
</dl>
<p>}</p>
<p>Valentin Antimirov of came up with Antimirov partial derivatives these are used to construct an NFA and the only real difference between them is that when you have a disjunction in an in your DFA you split that into two separate NFA States.
French scientists I think came up with some set set of set-based techniques to essentially allow you to bubble up or surface disjunctions from inside conjunctions and complements using again using like de Morgan’s laws and distributions on the sets of the conjunctions.
using Antimirov partial derivatives, I construct an NFA that I can apply the parentheses as tagged epsilon transitions, then use Laura carry tagged transitions to convert the tagged NFA to a tagged DFA and assuming that works that I can try translating into machine code.</p>
<ol class="arabic simple" start="3">
<li><p>Complexity Analysis</p></li>
</ol>
<p>Might et al. (2011) report an exponential bound for their
algorithm, but they never show it is a tight bound. On the
contrary, it turns out that PWD can, in fact, be implemented
in cubic time.
As mentioned before, at its core, PWD involves four re-
cursive functions: nullable?, derive, parse-null, and
parse. The nullable? and derive functions implement
δ (L) and D c (L), respectively; the parse-null function
extracts the final AST; and parse implements the outer loop
over input tokens. In Section 3.1, we observe that the running
times of these functions are bounded by the number of gram-
mar nodes in the initial grammar plus the number of gram-
mar nodes constructed during parsing. Next, in Section 3.2
we discover that the total</p>
<blockquote>
<div><p>number of nodes constructed dur-</p>
</div></blockquote>
<dl class="simple">
<dt>grammar ing parsing and isn O isGn3 the  length , where of G theis input. the size How of to the structure</dt><dd><p>initial</p>
</dd>
</dl>
<p>this part of the proof is the essential insight in our analy-
sis and is based on counting unique names that we assign
to nodes. When combined with the results from Section 3.1,
this then leads to a cubic bound on the total runtime.
Throughout this section, let G be the number of grammar
nodes in the initial grammar, let g be the number of nodes
created during parsing, and let n be the length of the input.
Also, when analyzing a memoized function, we consider the
cost of the check to see if a memoized result exists for a
particular input to be part of the running time of the caller
instead of the callee.
3.1 Total Running Time in Terms of Grammar Nodes
First, consider nullable?, which computes a boolean value
for each parse node in terms of a least fixed point. The im-
plementation by Might et al. (2011) iteratively re-traverses
the grammar until no new nodes can be proven nullable?.
Such an algorithm is quadratic in the number of nodes over
which nullable? is being computed because each traver-
sal might update only one node. However, a more intelligent
algorithm that tracks dependencies between nodes and oper-
ates over the boolean lattice can implement this function in
linear time, as shown in the following lemma.
Lemma 1. The sum of the running times of all invocations
of nullable? is O(G + g).
Proof. The fixed point to calculate nullable? can be im-
plemented by a data-flow style algorithm (Kildall 1973) that
tracks which nodes need their nullability reconsidered when
a given node is discovered to be nullable. Such an algorithm
is linear in the product of the height of the lattice for the
value stored at each node and the number of direct dependen-
cies between nodes. In this case, the lattice is over booleans
and is of constant height. Since each node directly depends
227
on at most two children, the number of dependencies is
bounded by twice the number of nodes ever created.
Next, we have derive. Since derive is memoized, it
is tempting to analyze it in terms of the nodes passed to
it. However, each node may have its derivative taken with
multiple different input tokens. The work done by derive
thus depends on the number of tokens by which each node
is derived, so we can instead simplify things by analyzing
derive in terms of the nodes that it constructs.
Lemma 2. The sum of the running times of all invocations
of derive is O(G + g).
Proof. Every call to derive that is not cached by memoiza-
tion creates at least one new node and, excluding the cost of
recursive calls, does O(1) work. As a result, the number of
nodes created, g, is at least as great as the amount of work
done. Thus, the work done by all calls to derive is O(g)
plus the work done by nullable?. By Lemma 1, this totals
to O(G + g).
Next, we have parse-null. For this part of the proof,
we assume that ASTs use ambiguity nodes and a potentially
cyclic graph representation. This is a common and widely
used assumption when analyzing parsing algorithms. For ex-
ample, algorithms like GLR (Lang 1974) and Earley (Ear-
ley 1968, 1970) are considered cubic, but only when making
such assumptions. Without ambiguity nodes, the grammar
S -&gt; S S | a | b has an exponential number of unique
parses for strings of length n that have no repeated substrings
of length greater than log2 n. Many of those parses share
common sub-trees, so it does not take exponential space
when represented with ambiguity nodes. Our implementa-
tion is capable of operating either with or without such a
representation, but the complexity result holds only with the
assumption.
Under these assumptions, parse-null is a simple mem-
oized function over grammar nodes and thus is linear.
Lemma 3. The sum of the running times of all invocations
of parse-null is O(G + g).
Proof. Every call to parse-null that is not cached by mem-
oization does O (1) work, excluding the cost of recursive
calls. There are at most G + g such non-cached calls.
Finally, we have the total running time of parse.
Theorem 4. The total running time of parse is O(G + g).
Proof. The parse function calls derive for each input to-
ken and, at the end, calls parse-null once. By Lemma 2
and Lemma 3, these together total O(G + g).
3.2 Grammar Nodes in Terms of Input Length
All of the results in Section 3.1 depend on g, the number
of grammar nodes created during parsing. If we look at
the definition of Dc (L) (i.e., derive) in Figure 2, most
of the clauses construct only a single node and use the
children of the input node only once each. When combined
with memoization, for a given input token, these clauses
create at most the same number of nodes as there are in the
grammar for the result of the derivative just before parsing
that input token. On their own, these clauses thus lead to the
construction of only Gn nodes.
However, the clause for a sequence node L1 ◦ L2 , when
L1 is nullable, uses L2 twice. This duplication is what led
many to believe PWD was exponential; and indeed, without
memoization, it would be. In order to examine this more
closely, we assign unique names to each node. We choose
these names such that each name is unique to the derivative
of a particular node with respect to a particular token. Thus,
the naming scheme matches the memoization strategy, and
the memoization of derive ensures that two nodes with the
same name are always actually the same node.
Definition 5. We give each node a unique name that is a
string of symbols determined by the following rules.
Rule 5a: Nodes in the initial grammar are given a name
consisting of a single unique symbol distinct from that
of any other node in the grammar.
Rule 5b: When the node passed to derive has the name
w and is a ◦ node containing a nullable left child,
the ∪ node created by derive is given the name w•c
where • is a distinguished symbol that we use for this
purpose and c is the token passed to derive.
Rule 5c: Any other node created by derive is given a
name of the form wc, where w and c are respectively
the name of the node passed to derive and the token
passed to derive.
A ◦ node with a nullable left child has the special case of
Rule 5b because it is the only case where derive produces
more than one node, and we need to give these nodes distinct
names. These resultant nodes are a ∪ node and a ◦ node
that is the left child of the ∪ node. The introduction of the •
symbol in the name of the ∪ node keeps this name distinct
from the name of the ◦ node.
As an example of these rules, Figure 5 shows the nodes
and corresponding names for the nodes created when parsing
the following grammar.
L = (L ◦ L) ∪ c
In this example, c accepts any token; the initial names
are L, M , and N ; and the input is c1 c2 c3 c4 . Each node in
Figure 5 is labeled with its name in a subscript, and children
that point to already existing nodes are represented with
a box containing the name of that node. For example, the
root of the first grammar contains the node named L as
228
its root, and the node named M in that tree has L as both
its children. The dotted arrows in this diagram show where
concatenation causes duplication. The node M produces
M c1 , M c1 produces M c 1 •c2 and M c1 c2, and so on.
A nice property of these rules can be seen if we consider
node names with their initial unique symbol and any • sym-
bols removed. The remaining symbols are all tokens from
the input. Furthermore, these symbols are added by succes-
sive calls to derive and thus are substrings of the input. This
lets us prove the following lemma.
Lemma 6. The number of strings of symbols consisting
of node names with their initial unique symbols and any •
Proof. symbols These removed strings is O are n2 all  substrings .</p>
<blockquote>
<div><p>of the input. Flaxman</p>
</div></blockquote>
<p>et al. (2004) count the number of such substrings and show
because that, unsurprisingly, the number it of is positions O n2 . At where an intuitive these substrings level, this can</p>
<blockquote>
<div><p>is</p>
</div></blockquote>
<p>start and end in the input are both linear in n.
In Figure 5, this can be seen by the fact that the c1, c2 ,
c3, and c4 occurring in node names are always in increasing,
consecutive ranges such as c 1 c2c3 in M c1c2 •c3 or c2c3 in
N c2c3 .
Another nice property of names is that they all contain at
most one occurrence of •. This turns out to be critical. At
an intuitive level, this implies that the ∪ node involved in a
duplication caused by a ◦ node is never involved in another
duplication.
Lemma 7. Each node name contains at most one occur-
rence of the • symbol.
Proof. According to Rule 5b, a • symbol is put in the name
of only those ∪ nodes that come from taking the derivative
of a ◦ node. Further derivatives of these ∪ nodes can produce
only more ∪ nodes, so Rule 5b, which applies only to ◦
nodes, cannot apply to any further derivatives of those ∪
nodes. Thus, once a • symbol is added to a name, another
one cannot be added to the name.
This property can be seen in Figure 5 where no name
contains more than one •, and every node that does contain
• is a ∪ node.
This then implies that every name is either of the form
N w or N u•v, where N is the name of an initial grammar
node and both w and uv are substrings of the input. As a
result, we can bound the number of possible names with the
following theorem.
Theorem 8. The total</p>
<blockquote>
<div><p>number of nodes constructed during</p>
</div></blockquote>
<p>Proof. parsing In isa O name Gn3 of 
.</p>
<blockquote>
<div><p>the form N w or N u•v, the number of</p>
</div></blockquote>
<p>possible symbols for N is the size of the initial grammar, G.
Also, the number of possible words for w or uv is bounded
by the number of unique subwords in the input, which is
O occur n2</p>
<blockquote>
<div><p>within . Finally, those the subwords number is of O(n). positions The number at which of unique
• may</p>
</div></blockquote>
<dl class="simple">
<dt>names, and consequently the number of nodes</dt><dd><p>created during</p>
</dd>
</dl>
<p>parsing, is the product of these: O Gn3
.
3.3 Running Time in Terms of Input Length
Finally, we can conclude that the running time of parsing is
cubic in the length of the input.
Theorem 9. The running time of parse is O Gn3
.
Proof. Use O Gn3</p>
<blockquote>
<div><p>in Theorem 8 for g in Theorem 4.</p>
</div></blockquote>
<p>Note that this analysis does not assume the use of the pro-
cess that Might et al. (2011) call compaction. Nevertheless,
it does hold, in that case, if compaction rules are applied only
when a node is constructed and only locally at the node being
constructed. The extra cost of compaction is thus bounded
by the number of nodes constructed, and compaction only
ever reduces the number of nodes constructed by other parts
of the parser.
4.</p>
<blockquote>
<div><p>Improving Performance in Practice</p>
</div></blockquote>
<p>Given that PWD has a cubic running time instead of the ex-
ponential conjectured in Might et al. (2011), the question re-
mains of why their implementation performed so poorly and
whether it can be implemented more efficiently. To inves-
tigate this, we reimplemented PWD from scratch and built
up the implementation one part at a time. We measured the
running time as each part was added and adjusted our imple-
mentation whenever a newly added part significantly slowed
down the implementation. Section 4.1 reports the final per-
formance of the resulting parser. Aside from low-level needs
to choose efficient data structures, we found three major al-
gorithmic improvements, which are discussed in Section 4.2,
Section 4.3, and Section 4.4.
The resulting parser implementation remains rather sim-
ple and easily read. The optimization of the fixed-point
computation for nullable? (Section 4.2) takes 24 lines of
Racket code, including all helpers. Compaction (Section 4.3)
is implemented using smart constructors for each form that
test if they are constructing a form that can be reduced. This
takes 50 lines of code due to each constructor needing to
have a clause for each child constructor with which it could
reduce. Finally, single-entry memoization (Section 4.4) re-
quires changing only the helpers that implement memoiza-
tion, which does not increase the complexity or size of the
resulting code. With all of these optimizations implemented,
the core code is 62 lines of Racket code with an additional
76 lines of code for helpers.
The complete implementation can be downloaded from:
<a class="reference external" href="http://www.bitbucket.com/ucombinator/derp-3">http://www.bitbucket.com/ucombinator/derp-3</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="PackageManager.html" class="btn btn-neutral float-left" title="Package manager" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Posets.html" class="btn btn-neutral float-right" title="Posets" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2022 Mathnerd314.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>