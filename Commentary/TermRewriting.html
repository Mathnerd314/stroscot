<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Term rewriting &mdash; Stroscot  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/hexagon_favicon.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Verification" href="Verification.html" />
    <link rel="prev" title="Syntax" href="Syntax.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html">
            <img src="../_static/hexagon_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/index.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../HowTo/index.html">How to</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Reference/index.html">Language Reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Commentary</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Assembly.html">Assembly</a></li>
<li class="toctree-l2"><a class="reference internal" href="BuildSystem.html">Build system</a></li>
<li class="toctree-l2"><a class="reference internal" href="Code-Generation.html">Code generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Compiler.html">Compiler design</a></li>
<li class="toctree-l2"><a class="reference internal" href="CoreSyntax.html">Core syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="Evaluation-Strategy.html">Evaluation strategy</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exceptions.html">Exceptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="F2G2_example.html">F2 G2</a></li>
<li class="toctree-l2"><a class="reference internal" href="Fastest.html">As fast as C</a></li>
<li class="toctree-l2"><a class="reference internal" href="Fexprs.html">Macros</a></li>
<li class="toctree-l2"><a class="reference internal" href="Library.html">Library</a></li>
<li class="toctree-l2"><a class="reference internal" href="Logic.html">Logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="Memory-Management.html">Memory management</a></li>
<li class="toctree-l2"><a class="reference internal" href="Meta.html">About</a></li>
<li class="toctree-l2"><a class="reference internal" href="Modules.html">Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="Objects.html">Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="PackageManager.html">Package manager</a></li>
<li class="toctree-l2"><a class="reference internal" href="Programs.html">Exemplary programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction.html">Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction-Example.html">Reduction example</a></li>
<li class="toctree-l2"><a class="reference internal" href="Sets.html">Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="State.html">Imperative programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="Syntax.html">Syntax</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Term rewriting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#down-with-functions">Down with functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rewrite-rules">Rewrite rules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#higher-order-matching">Higher-order matching</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#normal-forms">Normal forms</a></li>
<li class="toctree-l3"><a class="reference internal" href="#classification">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="#determinism">Determinism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#confluence">Confluence</a></li>
<li class="toctree-l4"><a class="reference internal" href="#normalization">Normalization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#equality-and-left-linearity">Equality and left-linearity</a></li>
<li class="toctree-l3"><a class="reference internal" href="#modularity">Modularity</a></li>
<li class="toctree-l3"><a class="reference internal" href="#higher-order-rewriting-system">Higher-order rewriting system</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concrete-strategies">Concrete strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dispatch">Dispatch</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Verification.html">Verification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../zzreferences.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Stroscot</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Commentary</a> &raquo;</li>
      <li>Term rewriting</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/Mathnerd314/stroscot/edit/master/docs/Commentary/TermRewriting.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="term-rewriting">
<h1>Term rewriting<a class="headerlink" href="#term-rewriting" title="Permalink to this headline"></a></h1>
<section id="down-with-functions">
<h2>Down with functions<a class="headerlink" href="#down-with-functions" title="Permalink to this headline"></a></h2>
<p>Haskell and other functional programming languages have had great success. But there’s a dirty secret: the programs you can write with these languages are restricted. In particular the evaluation of clauses is fixed to top-to-bottom order.</p>
<p>For example see the program from <cite>this old Usenet post &lt;https://groups.google.com/g/comp.lang.functional/c/sb76j3UE5Zg/m/h1ps0wEaTckJ&gt;</cite>):</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">myand</span><span class="w"> </span><span class="kt">False</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">False</span><span class="w"></span>
<span class="nf">myand</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="kt">False</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">False</span><span class="w"></span>
<span class="nf">myand</span><span class="w"> </span><span class="kt">True</span><span class="w"> </span><span class="kt">True</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">True</span><span class="w"></span>
</pre></div>
</div>
<p>Ideally <code class="docutils literal notranslate"><span class="pre">myand</span></code> should be defined with parallel semantics, so that <code class="docutils literal notranslate"><span class="pre">myand</span> <span class="pre">undefined</span> <span class="pre">False</span> <span class="pre">=</span> <span class="pre">False</span></code>. But Haskell defines evaluation as trying the rules in order, so the first equation evaluates <code class="docutils literal notranslate"><span class="pre">undefined</span></code> and evaluation results in an error.</p>
<p>In Stroscot we have both parallel and sequential matching. The sequential matching is straightforward to implement and mimics the implementation from Haskell. The parallel matching is more difficult - for a proper explanation of the semantics we have to shift the paradigm from functions to term rewrites.</p>
</section>
<section id="rewrite-rules">
<h2>Rewrite rules<a class="headerlink" href="#rewrite-rules" title="Permalink to this headline"></a></h2>
<p>A rewrite rule or clause is applied by matching the left hand side to the term or one of its subterms and applying the resulting substitution to the right hand side. Rewrite rules also have conditions - the rewrite rule can only be applied if its condition holds. For example, with the rules <code class="docutils literal notranslate"><span class="pre">fact</span> <span class="pre">n</span> <span class="pre">|</span> <span class="pre">n</span> <span class="pre">&gt;</span> <span class="pre">0</span> <span class="pre">=</span> <span class="pre">n</span> <span class="pre">*</span> <span class="pre">fact</span> <span class="pre">(n-1)</span></code> and <code class="docutils literal notranslate"><span class="pre">fact</span> <span class="pre">0</span> <span class="pre">=</span> <span class="pre">1</span></code>, we get the reduction sequence</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">fact</span><span class="w"> </span><span class="mi">3</span><span class="w"></span>
<span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fact</span><span class="w"> </span><span class="p">(</span><span class="mi">3</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>
<span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fact</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fact</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="w"></span>
<span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fact</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"></span>
<span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fact</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span><span class="w"></span>
<span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fact</span><span class="w"> </span><span class="mi">0</span><span class="p">))</span><span class="w"></span>
<span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1</span><span class="p">))</span><span class="w"></span>
<span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"></span>
<span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="mi">6</span><span class="w"></span>
</pre></div>
</div>
<p>We say that <code class="docutils literal notranslate"><span class="pre">fact</span> <span class="pre">3</span></code> reduces to <code class="docutils literal notranslate"><span class="pre">6</span></code>, written more concisely as the rewrite rule <code class="docutils literal notranslate"><span class="pre">fact</span> <span class="pre">3</span> <span class="pre">=</span> <span class="pre">6</span></code>.</p>
<p>Note that a reduction sequence is not necessarily unique, e.g. we could have used an associative law <code class="docutils literal notranslate"><span class="pre">3</span> <span class="pre">*</span> <span class="pre">(2</span> <span class="pre">*</span> <span class="pre">fact</span> <span class="pre">1)</span> <span class="pre">=</span> <span class="pre">(3</span> <span class="pre">*</span> <span class="pre">2)</span> <span class="pre">*</span> <span class="pre">fact</span> <span class="pre">1</span></code> and reduced from there to <code class="docutils literal notranslate"><span class="pre">6</span> <span class="pre">*</span> <span class="pre">fact</span> <span class="pre">1</span></code>. Different reduction sequences can be more efficient; this can optimize stack usage.</p>
<section id="higher-order-matching">
<h3>Higher-order matching<a class="headerlink" href="#higher-order-matching" title="Permalink to this headline"></a></h3>
<p>Handling lambdas in RHSs is fairly straightforward, just reduce them away when they are encountered. But in higher-order term rewriting systems the lambdas can show up on the left hand side, in the pattern. The rewriting system is then defined modulo lambda reduction. Executing a rule <code class="docutils literal notranslate"><span class="pre">l</span> <span class="pre">-&gt;</span> <span class="pre">r</span></code> on a term <code class="docutils literal notranslate"><span class="pre">t</span></code> solves the equation <code class="docutils literal notranslate"><span class="pre">t</span> <span class="pre">=</span> <span class="pre">C[lθ]</span></code> and replaces it with <code class="docutils literal notranslate"><span class="pre">C[rθ]</span></code>.</p>
<p>Finding the contexts <code class="docutils literal notranslate"><span class="pre">C</span></code> is fairly straightforward, just enumerate all the subterms of <code class="docutils literal notranslate"><span class="pre">t</span></code>. But solving the equation <code class="docutils literal notranslate"><span class="pre">s</span> <span class="pre">=</span> <span class="pre">lθ</span></code> is an instance of higher-order unification (specifically higher-order matching).  The λ-superposition calculus relies on complete sets of unifiers (CSUs). The
CSU for s and t, with respect to a set of variables V , denoted by CSUV (s, t), is a
set of unifiers such that for any unifier % of s and t, there exists a σ ∈ CSUV (s, t)
and θ such that %(X) = (σ◦θ)(X) for all X ∈ V . The set X is used to distinguish
between important and auxiliary variables. We can normally leave it implicit</p>
<p>Higher order matching is decidable for the simply typed lambda calculus. But the proof is of the form “the minimal solution is of size at most 2^2^2^2…, the number of 2’s proportional to the size of the problem”. There are 3 transformations presented in the proof which reduce a larger solution to a smaller solution. These might be usable to prune the search tree. But at the end of the day it’s mostly brute-force.</p>
<p>The proof relies on some properties of the STLC, namely normalization and that terms have a defined eta long form (canonical form).</p>
<p>It is not clear if there is a way to do untyped higher order matching for general lambda patterns.</p>
</section>
</section>
<section id="normal-forms">
<h2>Normal forms<a class="headerlink" href="#normal-forms" title="Permalink to this headline"></a></h2>
<p>The execution of a Stroscot program is modeled as applying rewrite rules successively until no more can be applied.</p>
<p>A “value” in a TRS refers to a normal form, a term that cannot be reduced further.
We model the program as generating an infinite normal form for I/O, so we extend values to infinite normal forms. Then a term’s values are the set of infinite normal forms produced as the limits of reduction sequences. If there are multiple such normal forms then the term is nondeterministic and has multiple values, or we could say it’s undefined.</p>
<p>To find the value the normal form must be computable - if the head normal form can’t be found in a reasonable amount of time then the value is uncomputable.</p>
</section>
<section id="classification">
<h2>Classification<a class="headerlink" href="#classification" title="Permalink to this headline"></a></h2>
<p>There are various behaviors which show up in a TRS, which require different handling.</p>
<ul class="simple">
<li><p>convergent (confluent and terminating) - These include typed systems such as the simply typed lambda calculus. For these, the result is the same no matter how they are reduced. So the focus is on do the reduction efficiently, compiling to fast assembly via a state machine and data format analysis and/or doing optimal reduction to reduce in the smallest number of steps.</p></li>
<li><p>cycles - The untyped lambda calculus has cycles, e.g. <code class="docutils literal notranslate"><span class="pre">Omega</span> <span class="pre">=</span> <span class="pre">let</span> <span class="pre">w=\x.x</span> <span class="pre">x</span> <span class="pre">in</span> <span class="pre">w</span> <span class="pre">w</span></code> reduces to itself and <span id="id1">[<a class="reference internal" href="../zzreferences.html#id98" title="missing journal in venturiniReductionGraphsLambda1983">Ven83</a>]</span> shows a 6-cycle <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">M</span> <span class="pre">I</span></code>. Similarly commutativity <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">+</span> <span class="pre">b</span> <span class="pre">=</span> <span class="pre">b</span> <span class="pre">+</span> <span class="pre">a</span></code> generates cycles. If we are able to detect these then the solution is to collapse the SCC into a single term. <span id="id2">[<a class="reference internal" href="../zzreferences.html#id23" title="Nachum Dershowitz and Jean-Pierre Jouannaud. Rewrite systems. In Handbook of Theoretical Computer Science (Vol. B): Formal Models and Semantics, pages 243–320. MIT Press, Cambridge, MA, USA, January 1991.">DJ91</a>]</span>’s notion of a (congruence-)class-rewriting system is helpful - the rewrite rules are split into rules R and (reversible) equations S, and we consider the system R/S (R mod S). A term where only S rules apply (no R rules apply) is considered a normal form in the class-rewriting system. So similarly terms with no reductions in the <a class="reference external" href="https://en.wikipedia.org/wiki/Strongly_connected_component#Definitions">condensation</a> of the rewrite graph are normal forms. Hence <code class="docutils literal notranslate"><span class="pre">&lt;Omega&gt;</span></code>,  <code class="docutils literal notranslate"><span class="pre">&lt;M</span> <span class="pre">M</span> <span class="pre">I&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;a</span> <span class="pre">+</span> <span class="pre">b&gt;</span></code> would be SCC normal forms since they do not reduce out of the SCC. In  The way we handle this in the rewrite engine is something like “detect cyclic term via cycle detection or presence of AC operator -&gt; wrap in scc node to prevent normal reduction -&gt; use specialized matching (eg AC matching or Tarjan SCC + memo hash table) to reduce to a term not in the SCC -&gt; end with SCC normal form if no reduction”</p></li>
<li><p>infinitely expanding terms - for example <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">::</span> <span class="pre">x</span></code> or <code class="docutils literal notranslate"><span class="pre">fib</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">::</span> <span class="pre">2</span> <span class="pre">::</span> <span class="pre">zipWith</span> <span class="pre">(+)</span> <span class="pre">fib</span> <span class="pre">(head</span> <span class="pre">fib)</span></code> or <code class="docutils literal notranslate"><span class="pre">foo</span> <span class="pre">=</span> <span class="pre">let</span> <span class="pre">t</span> <span class="pre">=</span> <span class="pre">\x.</span> <span class="pre">x</span> <span class="pre">x</span> <span class="pre">x</span> <span class="pre">in</span> <span class="pre">t</span> <span class="pre">t</span></code>. If reduction does not end in a SCC normal form, then the sequence of terms must be expanding in the sense that for every size s there is a point in the reduction where terms are always at least size s (otherwise since there are only finitely many terms of size &lt; s, there would be a cycle and it would be a SCC normal form). Here the idea is to find the limit of the computation, if it exists - an infinite normal form defined as a solution to a recurrence equation. So <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">::</span> <span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">fib</span></code> are already in a (head) normal form. Then this infinite term is computed in chunks and fed to the surrounding context on demand (laziness), ensuring that a normal form is reached if possible and otherwise implementing an infinite stream of commands. <code class="docutils literal notranslate"><span class="pre">foo</span></code> might resolve to <code class="docutils literal notranslate"><span class="pre">foo</span> <span class="pre">=</span> <span class="pre">foo</span> <span class="pre">t</span></code>, but this isn’t necessarily a normal form, so hard to say if it’s useful.</p></li>
<li><p>nondeterminism - if a term reduces to two normal forms, it’s hard to say immediately if this is an error - the program might ignore the term or give the same behavior on the different values. Errors/exceptions are by design non-deterministic. In a parsing context the desired behavior is to collect all possible parses and use a disambiguating handler to choose among them. But if at the top-level a program is reducing to two distinct non-error terms, this is probably an error. But this is a global property and at the local level we have to handle nondeterminism.</p></li>
<li><p>diverging - if a term infinitely expands and doesn’t converge even to a head-normal limit, i.e. it has no head normal form, then there’s not much semantic meaning in it. It perpetually has a redex in the head position, i.e. is root-active, so it can’t even be safely pattern matched on. So since its value is unobservable it can be replaced with an error term, just like Bohm reduction <span id="id3">[<a class="reference internal" href="../zzreferences.html#id59" title="J. R. Kennaway, J. W. Klop, M. R. Sleep, and F. J. de Vries. Transfinite reductions in orthogonal term rewriting systems. In Ronald V. Book, editor, Rewriting Techniques and Applications, Lecture Notes in Computer Science, 1–12. Berlin, Heidelberg, 1991. Springer. doi:10.1007/3-540-53904-2_81.">KKSdeVries91</a>]</span>.</p></li>
</ul>
</section>
<section id="determinism">
<h2>Determinism<a class="headerlink" href="#determinism" title="Permalink to this headline"></a></h2>
<p>In general the precise guarantees of determinism are undecidable, so there is no simple and precise condition. The most precise property is “unique normal forms with respect to reduction” (UN→), but this hasn’t been well-studied. Researchers have mostly focused on stronger properties, i.e. conditions sufficient for the properties to hold, as opposed to equivalent or weaker conditions. The simplest guarantee of determinism is for there to only be one matching rule (orthogonality). Confluence has gotten a lot of attention as well and has automated provers.</p>
<section id="confluence">
<h3>Confluence<a class="headerlink" href="#confluence" title="Permalink to this headline"></a></h3>
<p>Confluence implies UN→; it is equivalent if the TRS is weakly normalizing. And there is an extension theorem: every TRS with unique normal forms (UN=) can be extended to a confluent TRS with the same set of normal forms by adding bottom terms and reductions to normal forms and bottoms that preserve the equivalence classes of terms. <span id="id4">[<a class="reference internal" href="../zzreferences.html#id71" title="Aart Middeldorp. Modular aspects of properties of term rewriting systems related to normal forms. In G. Goos, J. Hartmanis, D. Barstow, W. Brauer, P. Brinch Hansen, D. Gries, D. Luckham, C. Moler, A. Pnueli, G. Seegmüller, J. Stoer, N. Wirth, and Nachum Dershowitz, editors, Rewriting Techniques and Applications, volume 355, pages 263–277. Springer Berlin Heidelberg, Berlin, Heidelberg, 1989. URL: http://link.springer.com/10.1007/3-540-51081-8_113 (visited on 2021-09-14), doi:10.1007/3-540-51081-8_113.">Mid89</a>]</span> Similarly a system can be shown to be UN= by presenting an extension of it that is confluent. <span id="id5">[<a class="reference internal" href="../zzreferences.html#id61" title="Jan Willem Klop and Roel de Vrijer. Extended term rewriting systems. In S. Kaplan and M. Okada, editors, Conditional and Typed Rewriting Systems, Lecture Notes in Computer Science, 26–50. Berlin, Heidelberg, 1991. Springer. doi:10.1007/3-540-54317-1_79.">KdeVrijer91</a>]</span> So a UN= program is just a partially specified system. UN→ is a little more complex though. And the equivalence classes of terms are uncomputable in general so the extension is as well.</p>
<p>Confluence avoids situations where a system may branch into two distinct diverging states. It makes finding a normalizing strategy much easier as the strategy only has to avoid getting stuck evaluating a term infinitely (using the same rule infinitely often), as opposed to UN→ where the strategy must avoid using the wrong reduction rule at every step.</p>
<p>The Knuth-Bendix algorithm produces a confluent system from a set of non-oriented equations, but the rules in programs are oriented, so using this would be confusing. Not to mention that the algorithm fails often. So that’s out.</p>
<p>A necessary condition for confluence is weak/local confluence, i.e. each critical pair is convergent. But this is not sufficient. Newman’s lemma is that a terminating locally confluent TRS is confluent. But termination is quite strong. A generalization is a critical pair system <span id="id6">[<a class="reference internal" href="../zzreferences.html#id45" title="Nao Hirokawa and Aart Middeldorp. Decreasing Diagrams and Relative Termination. arXiv:0910.2853 [cs], October 2009. URL: http://arxiv.org/abs/0910.2853 (visited on 2021-09-14), arXiv:0910.2853.">HM09</a>]</span> (also called decreasingly confluent): the system must be left-linear, locally confluent, and its critical pair steps must be <em>relatively terminating</em>, i.e. the relation ‘arbitrary steps followed by a critical pair step followed by arbitrary steps’ is terminating. Trivial critical pair steps can be excluded, hence this includes weakly orthogonal TRSs. For a terminating TRS the TRS syntactic equality notion is equivalent to strict equality, hence the system is left linear in the CTRS sense, hence why this includes Newman’s lemma.</p>
<p>We say → has random descent (RD), if for each R:a ↔∗b with b in normal form, all maximal reductions from a have length d(R) and end in b. Systems with random descent are confluent.</p>
</section>
<section id="normalization">
<h3>Normalization<a class="headerlink" href="#normalization" title="Permalink to this headline"></a></h3>
<p>Normalizing strategies find the normal form if it exists, i.e. if any reduction sequence/strategy produces a normal form, a normalizing strategy does too. A normalizing strategy avoids getting stuck infinitely evaluating nonterminating arguments (time efficient in the large). Basically, a normalizing strategy provides all the benefits of “lazy evaluation”:
* One can reason unconditionally about the termination behavior of program fragments (substituting expression for value, removing unused expressions)
* The semantics of nontermination are cleaner - a normalizing strategy handles if-then-else and short-circuit functions gracefully.
* Infinite data structures can be used without allocating infinite memory</p>
<p>A hypernormalizing strategy is a strategy that is normalizing even if arbitrary reduction steps are taken before and after steps of the strategy. This allows the compiler to make optimizations without changing the behavior of the program. A hypernormalizing strategy allows aggressive optimizations and program transforms.</p>
<p>Leftmost outermost reduction is the basis of lazy evaluation and is hypernormalizing for the lambda calculus. But for TRSs LO is only normalizing for left-normal TRSs, where variables do not precede function symbols in the left-hand sides of the rewrite rule. A better strategy is outermost fair (ensuring each outermost redex will eventually be evaluated - the simplest example is parallel outermost) - it’s hypernormalizing for critical pair TRSs (decreasingly confluent TRSs), in particular weakly orthogonal TRSs. <span id="id7">[<a class="reference internal" href="../zzreferences.html#id46" title="Nao Hirokawa and Aart Middeldorp. Strategies for Decreasingly Confluent Rewrite Systems. Reduction Strategies in Rewriting and Programming, pages 23, 2011.">HM11</a>]</span></p>
<p>There are also stronger properties than normalization. A Church-Rosser strategy is one with common reducts, i.e. there exist m and n, such that <span class="math notranslate nohighlight">\(F^m(t)=F^n(u)\)</span> for every t and u equal via forward/backward evaluation. A normalizing strategy is Church-Rosser if the system is confluent and weakly normalizing (i.e. all objects have a normal form). In general a many-step CR strategy exists for effective ARS’s, i.e. countable (in a computable fashion) and with a computable reduction relation. But the strategy is quite hard to compute, as it has to synchronize reducing subterms so that all components are reduced the same amount. And it’s not clear that this synchronization offers anything to the programmer.</p>
<p>Cofinal strategies are weaker than Church-Rosser but stronger than normalizing: for every term a, if a reduces in a finite number of steps to b, then there is an object c obtained by applying the strategy some number of times to a such that b reduces to c. For critical pair TRSs any “fair” strategy that ensures every redex is eventually contracted is cofinal. The cofinal property provides slick proofs - it ensures every redex not part of a cycle is contracted. But at runtime non-normalizing terms have indistinguishable behavior (infinite loop), hence this means the cofinal strategy is doing unnecessary work.</p>
<p>There are also termination properties like strong convergence that ensure that for every term, there exists some number of reduction steps after which the head cannot be rewritten.
To ensure that term rewriting halts we probably also want a property like strong convergence, but this is a property of the rewriting strategy, not the TRS proper.</p>
<p>A perpetual strategy is the opposite of normalizing - if any strategy diverges, then perpetual strategy diverges. Leftmost-innermost is close to the strategies commonly used in strict languages and is perpetual. With a perpetual strategy inlining etc. hold only if reduction of the expression terminates, i.e. one must keep track of termination properties. A perpetual strategy gives the wrong behavior for if-then-else and short-circuit functions, so strict languages special-case these to ensure they don’t cause nontermination. Perpetual strategies are antagonistic, “I’ll crash your program if I can”.</p>
</section>
</section>
<section id="equality-and-left-linearity">
<h2>Equality and left-linearity<a class="headerlink" href="#equality-and-left-linearity" title="Permalink to this headline"></a></h2>
<p>The TRS notion of equality <code class="docutils literal notranslate"><span class="pre">eq_t</span> <span class="pre">x</span> <span class="pre">x</span> <span class="pre">-&gt;</span> <span class="pre">True</span></code> is different from strict equality <code class="docutils literal notranslate"><span class="pre">eq_s</span> <span class="pre">x</span> <span class="pre">y</span> <span class="pre">|</span> <span class="pre">x</span> <span class="pre">==</span> <span class="pre">y</span></code> in a CTRS (conditional term rewriting system). Strict equality compares equality of normal forms (fully reduced terms). But <code class="docutils literal notranslate"><span class="pre">eq_t</span> <span class="pre">c</span> <span class="pre">c</span></code> matches even if <code class="docutils literal notranslate"><span class="pre">c</span></code> doesn’t have a normal form. A broader CTRS equality is semi-equational equality which equates all terms that can be rewritten to each other via rewrites and inverse rewrites. In general strict equality is weaker than TRS equality (<code class="docutils literal notranslate"><span class="pre">x==x</span></code> can’t be simplified to true), TRS equality is weaker than semi-equational equality (because of the inverse rewrites). In general all 3 may be uncomputable, but strict equality is computable if there is a computable normalizing strategy, semi-equational equality is computable depending on the complexity of the system, while normalizing reduction in a system with TRS equality is undecidable.</p>
<p>For the CTRS to be confluent if the unconditional TRS is, the conditions in the rules have to be stable, i.e. if the terms involved are reduced the truth value of the condition doesn’t change. Non-left-linear rules aren’t stable, in general, while strict equality and equational equality are. So left-linearity essentially fixes a specification problem. There are non-left-linear systems that have unique normal forms or are confluent but it’s arguable if they’re useful or if they’re just CTRSs with complex conditions in disguise.</p>
<p>If you aren’t convinced of the bad behavior of left non-linearity consider some systems:</p>
<ul class="simple">
<li><p>In the system <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">x</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">a,</span> <span class="pre">f</span> <span class="pre">x</span> <span class="pre">(g</span> <span class="pre">x)</span> <span class="pre">=</span> <span class="pre">b,</span> <span class="pre">c</span> <span class="pre">=</span> <span class="pre">g</span> <span class="pre">c</span></code> the first rule is non-linear. There are no critical pairs, so the system is locally confluent, but <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">c</span> <span class="pre">c</span></code> reduces to both <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> hence the system is not confluent. With strict equality <code class="docutils literal notranslate"><span class="pre">c</span></code> has no normal form, hence <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">c</span> <span class="pre">c</span></code> does not reduce with an <code class="docutils literal notranslate"><span class="pre">f</span></code>-rule (it gets stuck evaluating a reduction of the form <code class="docutils literal notranslate"><span class="pre">c</span> <span class="pre">-&gt;</span> <span class="pre">g</span> <span class="pre">c</span> <span class="pre">-&gt;</span> <span class="pre">g</span> <span class="pre">(g</span> <span class="pre">c)</span> <span class="pre">-&gt;</span> <span class="pre">...</span></code>). With equational equality <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">c</span> <span class="pre">c</span></code> reduces to both <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> in one step hence the system is not locally confluent.</p></li>
<li><p>In the system <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">x</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">X,</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">b,</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">c,</span> <span class="pre">c</span> <span class="pre">=</span> <span class="pre">c,</span> <span class="pre">d</span> <span class="pre">=</span> <span class="pre">c,</span> <span class="pre">d</span> <span class="pre">=</span> <span class="pre">e</span></code>, the term <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">a</span> <span class="pre">d</span></code> reduces to both <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">b</span> <span class="pre">e</span></code>, hence the system does not have unique normal forms. With strict equality <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">a</span> <span class="pre">d</span></code> does not reduce to <code class="docutils literal notranslate"><span class="pre">X</span></code> and with equational equality <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">b</span> <span class="pre">e</span></code> reduces to <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p></li>
</ul>
</section>
<section id="modularity">
<h2>Modularity<a class="headerlink" href="#modularity" title="Permalink to this headline"></a></h2>
<p>A property is modular if the disjoint union of two systems with the property has the property.</p>
<p>Left linearity, confluence, weak normalization, unique normal forms (w.r.t. equivalence), and consistency (w.r.t. equivalence) are modular for first-order systems. Modularity of left linearity, confluence, and unique normal forms extend to semi-equational CTRSs. Confluence also extends to join CTRSs. In fact if the disjoint union is confluent then the component systems must be confluent. Confluence is not modular for higher-order TRSs but confluence plus left linearity is.</p>
<p>Weak termination, weak innermost termination, and strong innermost termination are modular for CTRSs in combination with confluence or the property that there are no extra variables in the conditions.</p>
<p>NF, unique normal forms with respect to reduction, and consistency with respect to reduction are modular in combination with left linearity. Consistency w.r.t. reduction means that there is no term reducing to two distinct variables; it is implied by the unique normal form property w.r.t. reduction as variables are normal forms.</p>
<p>Strong normalization plus consistency w.r.t. reduction plus left linearity is modular. This likely holds for CTRSs without extra variables as well.</p>
</section>
<section id="higher-order-rewriting-system">
<h2>Higher-order rewriting system<a class="headerlink" href="#higher-order-rewriting-system" title="Permalink to this headline"></a></h2>
<p>A HORS consists of a substitution calculus, an alphabet, and a set of rewrite rules.</p>
<p>A substitution calculus is an ARS on a set of prestructures. A structure is a prestructure that is a normal form with respect to the substitution calculus ARS.</p>
<p>Types are sets of prestructures. We assume every type is inhabited by an infinite number of atomic prestructures called variables. Among the variables a countable set called the alphabet is distinguished whose elements are called symbols. Holes are distinguished variables indexed by an integer.</p>
<p>A rewrite rule is a LHS and RHS, both closed structures of the same type, closed meaning containing no free variables that are not symbols. The TRS on structures is defined by M -&gt; N if M &lt;-&gt;* C[l] and C[r] &lt;-&gt;* N for some rewrite rule l -&gt; r and context C containing a hole of type matching the rewrite rule.</p>
<p>As a consequence of confluence each rewrite step is composed of an expansion in the substitution calculus, a replacement by applying some rule, and a reduction in the substitution calculus, so it is M &lt;&lt;- C[l] and C[r] -&gt;&gt; N</p>
<p>A m-ary precontext is a preterm with holes 1 through m. It is linear if every hole occurs exactly once.
The set of term is the set of representatives of preterms when considering equivalence classes under the substitution calculus.</p>
<blockquote>
<div><p>and a signature of operator symbols or constants.</p>
</div></blockquote>
<p>An example is the lambda calculus. The set of raw preterms on a set of bound variables is built in the following way: A bound variable is a raw preterm iff it is in the set of bound variables. All other nullary symbols are raw preterms regardless. The application of two raw preterms is a raw preterm. Abstraction is a raw preterm where the first raw preterm is a bound variable symbol and the second is a raw preterm over the set of bound variables extended with the newly bound variable. The rewrite alphabet consists of operators and term variables (a.k.a. free variables), also nullary.</p>
<p>A preterm is a raw preterm over the empty set, i.e. all bound variables are bound. If it contains free variables it is called open, otherwise closed.</p>
<p>A HORS is orthogonal if:</p>
<p>A1 the substitution calculus is complete
A2 the substitution calculus is only needed for gluing
A4 the substitution calculus is a descendant rewriting system
A5 the substitution calculus is parametric and rules are head-defined
A7 the substitution calculus is naturally closed under substitution</p>
<p>A3 parallel rewrite steps can be serialised
A6 left-hand sides of rules are linear
A8 every set of redexes is pairwise simultaneous</p>
</section>
<section id="concrete-strategies">
<h2>Concrete strategies<a class="headerlink" href="#concrete-strategies" title="Permalink to this headline"></a></h2>
<p>So: strategy must normalizing. Now, which strategy?</p>
<p>For terminating programs, all strategies are normalizing. Hence we want to infer termination and use this to optimize the strategy - leftmost innermost ensures “complete development”, i.e. a subterm is reduced completely before the outer term, hence we can store the subterm using an optimized representation of the normal form.
But strongly normalizing implies not Turing complete, hence the typechecker that ensures termination will cause problems for complex programs. We need a fallback for non-terminating programs.</p>
<p>The simplest fallback is outermost-fair, it’s a reasonable default and terminates on critical pair TRSs. But there are hand-written examples where it fails.</p>
<p>We could do user-specified strategies like Stratego, but then how would we know that they’re normalizing.</p>
<p>The optimal reduction stuff is defined for match sequential TRSs.</p>
<p>non-strict strategies:
* Lenient evaluation - computation rule [Traub, FPCA 89], where all redexes are evaluated in parallel except inside the arms of conditionals and inside lambdas.
* extra memory overhead for parameter passing (inefficient)
* strictness analysis to optimize to eager (which has identical semantics to lazy 99% of the time)</p>
<p>Now, one can argue about which computational strategy is better (time, space, parallelism, …)
Stroscot: be accepting of programs, ensure a normalizing strategy. But after that aim for most efficient in time/space for strict programs.</p>
<p>Q: can normalizing be as efficient as strict
profiling, other optimization tricks</p>
<p>A list List[Nat]. In a strict language ADTs are finite. In lazy, we might accept infinite lists (generators). We want precise types: the finite data structure and its infinite counterpart ARE DIFFERENT DATATYPES. Only discardable (weakenable) boxes can contain infinite structures, so uList. (Nat + !w List) is an infinite list, while uList. (Nat + List) is a strict list. Extends to more complicated data structures. With subtyping you can use a finite list with an infinite list transformer.</p>
<p>UNIX pipes. “yes fred | less” works fine, but “yes fred | sort | less” is an infinite loop, because yes fred is infinite and sort is strict. For finite streams the simple semantics of pipes, namely
1) First program generates output
2) This output is sent to next program
….
n) This output is sent to next program
n+1) This output is sent to terminal
suffices.
Most programs have finite output on finite input and block gracefully. Thus for MOST programs you need not worry about whether the execution of pipes is interleaved or not. The interleaving matters for long outputs because it saves memory (=time w/gc) and improves performance dramatically.
That interleaving works with certain infinite streams is just a natural generalization. The slow behavior of sort is also visible with long lists.
Laziness means you can implement interleaving once in the language (as the evaluation strategy) as opposed to piecemeal for each program.</p>
<p>Tree structure of terms (n⋅(n+1))/2 and n⋅((n+1)/2)</p>
<p>Given a set V of variable symbols, a set C of constant symbols and sets Fn of n-ary function symbols, also called operator symbols, for each natural number n ≥ 1, the set of (unsorted first-order) terms T is recursively defined to be the smallest set with the following properties:[1]</p>
<blockquote>
<div><p>every variable symbol is a term: V ⊆ T,
every constant symbol is a term: C ⊆ T,
from every n terms t1,…,tn, and every n-ary function symbol f ∈ Fn, a larger term f(t1, …, tn) can be built.</p>
</div></blockquote>
<p>Using an intuitive, pseudo-grammatical notation, this is sometimes written as: t ::= x | c | f(t1, …, tn). Usually, only the first few function symbol sets Fn are inhabited. Well-known examples are the unary function symbols sin, cos ∈ F1, and the binary function symbols +, −, ⋅, / ∈ F2, while ternary operations are less known, let alone higher-arity functions. Many authors consider constant symbols as 0-ary function symbols F0, thus needing no special syntactic class for them.</p>
<p>A term denotes a mathematical object from the domain of discourse. A constant c denotes a named object from that domain, a variable x ranges over the objects in that domain, and an n-ary function f maps n-tuples of objects to objects. For example, if n ∈ V is a variable symbol, 1 ∈ C is a constant symbol, and add ∈ F2 is a binary function symbol, then n ∈ T, 1 ∈ T, and (hence) add(n, 1) ∈ T by the first, second, and third term building rule, respectively. The latter term is usually written as n+1, using infix notation and the more common operator symbol + for convenience.</p>
</section>
<section id="dispatch">
<h2>Dispatch<a class="headerlink" href="#dispatch" title="Permalink to this headline"></a></h2>
<p>The standard vtable implementation of Java/C++ is out. TODO: check out pattern dispatch paper</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Syntax.html" class="btn btn-neutral float-left" title="Syntax" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Verification.html" class="btn btn-neutral float-right" title="Verification" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2020 Mathnerd314.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>