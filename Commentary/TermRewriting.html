<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Term rewriting &mdash; Stroscot  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/hexagon_favicon.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Time API" href="Time.html" />
    <link rel="prev" title="Syntax" href="Syntax.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html">
            
              <img src="../_static/hexagon_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/index.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../HowTo/index.html">How to</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Reference/index.html">Language Reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Commentary</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Assembly.html">Assembly</a></li>
<li class="toctree-l2"><a class="reference internal" href="BuildSystem.html">Build system</a></li>
<li class="toctree-l2"><a class="reference internal" href="Checklist.html">Checklist</a></li>
<li class="toctree-l2"><a class="reference internal" href="Code-Generation.html">Code generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Compiler.html">Compiler design</a></li>
<li class="toctree-l2"><a class="reference internal" href="Compiler-Library.html">Compiler library</a></li>
<li class="toctree-l2"><a class="reference internal" href="CompilerOutput.html">Compiler output</a></li>
<li class="toctree-l2"><a class="reference internal" href="Concurrency.html">Concurrency</a></li>
<li class="toctree-l2"><a class="reference internal" href="CoreSyntax.html">Core syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="Dispatch.html">Dispatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="Errors.html">Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="Evaluation-Strategy.html">Evaluation strategy</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exceptions.html">Exceptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="Fastest.html">As fast as C</a></li>
<li class="toctree-l2"><a class="reference internal" href="IR.html">Intermediate representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Intrinsics.html">Intrinsics</a></li>
<li class="toctree-l2"><a class="reference internal" href="Learning.html">Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Logic.html">Logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="LogicProgramming.html">Logic programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="Macros.html">Macros</a></li>
<li class="toctree-l2"><a class="reference internal" href="Memory-Management.html">Memory management</a></li>
<li class="toctree-l2"><a class="reference internal" href="Meta.html">Meta</a></li>
<li class="toctree-l2"><a class="reference internal" href="Modules.html">Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="Objects.html">Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="PackageManager.html">Package manager</a></li>
<li class="toctree-l2"><a class="reference internal" href="Parsing.html">Parsing</a></li>
<li class="toctree-l2"><a class="reference internal" href="Posets.html">Posets</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html">Profiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#resources">Resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#metrics">Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#statistics">Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#methods">Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#action">Action</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#caches">Caches</a></li>
<li class="toctree-l2"><a class="reference internal" href="Programs.html">Exemplary programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction.html">Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction-Example.html">Reduction example</a></li>
<li class="toctree-l2"><a class="reference internal" href="Resource-Management.html">Resource management</a></li>
<li class="toctree-l2"><a class="reference internal" href="Sets.html">Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="Standard-Library.html">Standard library</a></li>
<li class="toctree-l2"><a class="reference internal" href="State.html">Stateful programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="Syntax.html">Syntax</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Term rewriting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#higher-order-rewriting">Higher-order rewriting</a></li>
<li class="toctree-l3"><a class="reference internal" href="#currying">Currying</a></li>
<li class="toctree-l3"><a class="reference internal" href="#conditional-rewriting">Conditional rewriting</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cycles">Cycles</a></li>
<li class="toctree-l3"><a class="reference internal" href="#nondeterminism">Nondeterminism</a></li>
<li class="toctree-l3"><a class="reference internal" href="#infinite-reduction">Infinite reduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#meaningless-terms">Meaningless terms</a></li>
<li class="toctree-l3"><a class="reference internal" href="#left-nonlinearity">Left-nonlinearity</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#confluence">Confluence</a></li>
<li class="toctree-l4"><a class="reference internal" href="#normalization">Normalization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#evaluation-strategy">Evaluation strategy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#higher-order-matching">Higher-order matching</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#verifying-confluence">Verifying confluence</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Time.html">Time API</a></li>
<li class="toctree-l2"><a class="reference internal" href="Tools.html">Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="Types.html">Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="Units.html">Units</a></li>
<li class="toctree-l2"><a class="reference internal" href="Verification.html">Verification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../zzreferences.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Stroscot</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Commentary</a></li>
      <li class="breadcrumb-item active">Term rewriting</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/Mathnerd314/stroscot/edit/master/docs/Commentary/TermRewriting.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="term-rewriting">
<h1>Term rewriting<a class="headerlink" href="#term-rewriting" title="Permalink to this heading"></a></h1>
<section id="higher-order-rewriting">
<h2>Higher-order rewriting<a class="headerlink" href="#higher-order-rewriting" title="Permalink to this heading"></a></h2>
<p>The definition is vaguely based on <span id="id1">[]</span>. But Ooostrom’s HORS definition, like Terese, uses closed terms and no separate substitution, avoiding free variables by adding additional binders, e.g. he writes the rule <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">1</span></code> as <code class="docutils literal notranslate"><span class="pre">\x.</span> <span class="pre">f</span> <span class="pre">x</span> <span class="pre">-&gt;</span> <span class="pre">\x.</span> <span class="pre">1</span></code>. I don’t like this because it’s unclear how it interacts with currying, eta reduction, and conditional rewriting, so I added the substitution back.</p>
<p>There is some question of whether context substitution is capture-avoiding, i.e. does <code class="docutils literal notranslate"><span class="pre">(\x.</span> <span class="pre">□)[□</span> <span class="pre">:=</span> <span class="pre">x]</span></code> not resolve to <code class="docutils literal notranslate"><span class="pre">(\x.</span> <span class="pre">x)</span></code>. Terese says it captures. With Oostrom this substitution is forbidden since <code class="docutils literal notranslate"><span class="pre">x</span></code> is not a closed term. In our more liberal definition this resolves to <code class="docutils literal notranslate"><span class="pre">(\y.</span> <span class="pre">x)</span></code> by alpha-renaming the variable.</p>
<p>An example substitution calculus is the lambda calculus. The set of preterms is built from nullary symbols (variables, holes, symbols, and constants), applications of two preterms, and abstractions of a variable and a preterm. The substitution calculus rewriting rules are beta reduction and alpha renaming. Eta reduction can be added but makes the system only weakly orthogonal. <span id="id2">[<a class="reference internal" href="../zzreferences.html#id55" title="Jörg Endrullis, Dimitri Hendriks, and Jan Willem Klop. Highlights in infinitary rewriting and lambda calculus. Theoretical Computer Science, 464:48–71, December 2012. URL: https://www.sciencedirect.com/science/article/pii/S030439751200792X (visited on 2022-07-02), doi:10.1016/j.tcs.2012.08.018.">EHK12</a>]</span></p>
</section>
<section id="currying">
<h2>Currying<a class="headerlink" href="#currying" title="Permalink to this heading"></a></h2>
<p>Per <span id="id3">[<a class="reference internal" href="../zzreferences.html#id90">KKSV95</a>]</span> there are three related TRSs:</p>
<ul class="simple">
<li><p>The standard uncurried system where a function application <code class="docutils literal notranslate"><span class="pre">f(t1,</span> <span class="pre">...</span> <span class="pre">,</span> <span class="pre">tn)</span></code> is formed from an n-ary function symbol <code class="docutils literal notranslate"><span class="pre">f</span></code> and n terms t1,…,tn.</p></li>
<li><p>A curried system where a function application <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">t1</span> <span class="pre">...</span> <span class="pre">tn</span></code> is formed from a nullary constant <code class="docutils literal notranslate"><span class="pre">f</span></code> and many application of the binary “application” operator, written as left-associative juxtaposition or more verbosely <code class="docutils literal notranslate"><span class="pre">App(f,x)</span></code>.</p></li>
<li><p>A “partially parameterized” (PP) system containing <code class="docutils literal notranslate"><span class="pre">App</span></code> and, for each n-ary function symbol in the uncurried system, n-1 partial application symbols and “uncurrying” rules <code class="docutils literal notranslate"><span class="pre">App(f_i(...),</span> <span class="pre">x)</span> <span class="pre">=</span> <span class="pre">f_i+1</span> <span class="pre">(...,</span> <span class="pre">x)</span></code>. GHC does something similar with a <code class="docutils literal notranslate"><span class="pre">PAP</span></code> constructor, so it is <code class="docutils literal notranslate"><span class="pre">PAP</span> <span class="pre">1</span> <span class="pre">f_2</span> <span class="pre">a</span></code> instead of <code class="docutils literal notranslate"><span class="pre">f_1(a)</span></code>. This allows combining all the partial-application rules into one handler, but forces a uniform representation for partial applications.</p></li>
</ul>
<p>The uncurried system embeds in the curried system, i.e. for every uncurried term t there is a unique corresponding curried term t’, and every reduct of t corresponds to a reduct of t’ and vice-versa. Hence we lose no expressiveness by currying, and gain some expressiveness because only the curried system can express partially applied terms.</p>
<p>The PP system is an extension of the uncurried system, and is isomorphic to the curried system. The normal forms of PP and curried are in a bijection, and each curried reduction step corresponds to one or more PP steps. The curried system is simpler than the PP system, so we use the curried definition for the language syntax and semantics. But the PP system may be useful for compilation. It’s easy to break the isomorphism though, e.g. <code class="docutils literal notranslate"><span class="pre">printf</span> <span class="pre">&quot;%i&quot;</span> <span class="pre">1</span></code> can be defined in the curried system but not in the PP system because the arity is variable.</p>
</section>
<section id="conditional-rewriting">
<h2>Conditional rewriting<a class="headerlink" href="#conditional-rewriting" title="Permalink to this heading"></a></h2>
<p>In a general CTRS the reduction rules are of the form <code class="docutils literal notranslate"><span class="pre">t</span> <span class="pre">|</span> <span class="pre">P</span> <span class="pre">-&gt;</span> <span class="pre">s</span></code>, where <code class="docutils literal notranslate"><span class="pre">P</span></code> is a predicate. The allowed rewrites of a conditional rule are the unconditional rewrites <code class="docutils literal notranslate"><span class="pre">t</span> <span class="pre">-&gt;</span> <span class="pre">s</span></code> that satisfy the condition <code class="docutils literal notranslate"><span class="pre">P</span></code>. We can add a form of logic programming by allowing conditions to use variables not in the LHS, e.g. <code class="docutils literal notranslate"><span class="pre">precedes</span> <span class="pre">x</span> <span class="pre">z</span> <span class="pre">|</span> <span class="pre">exists</span> <span class="pre">y.</span> <span class="pre">precedes</span> <span class="pre">x</span> <span class="pre">y</span> <span class="pre">&amp;&amp;</span> <span class="pre">precedes</span> <span class="pre">y</span> <span class="pre">z</span> <span class="pre">=</span> <span class="pre">true</span></code>. This further extends to allowing variables on the RHS not present on the LHS. A further extension allows LHSs that are a single variable but have a condition - some authors disallows variables LHSs. Some syntax like <code class="docutils literal notranslate"><span class="pre">l</span> <span class="pre">|</span> <span class="pre">exists</span> <span class="pre">x.</span> <span class="pre">C</span> <span class="pre">=</span> <span class="pre">r</span></code> and <code class="docutils literal notranslate"><span class="pre">l</span> <span class="pre">=</span> <span class="pre">exists</span> <span class="pre">x.</span> <span class="pre">r</span></code> might make this easier to follow.</p>
<p>The definition of a CTRS is complicated by allowing predicates to refer to the rewrite relation <code class="docutils literal notranslate"><span class="pre">-&gt;</span></code>. Ideally the rewrite relation would be defined as a fixed point of the rewrite rules. I.e. letting <code class="docutils literal notranslate"><span class="pre">S</span></code> be the system as a function of the rewrite relation <code class="docutils literal notranslate"><span class="pre">-&gt;</span></code>, we would define <code class="docutils literal notranslate"><span class="pre">-&gt;</span></code> to be a relation <code class="docutils literal notranslate"><span class="pre">R</span></code> such that <code class="docutils literal notranslate"><span class="pre">R</span> <span class="pre">=</span> <span class="pre">S(R)</span></code>. Terese presents the least fixed point. However, with badly-behaved conditions, no fixed point may exist, so instead we use the “optimal prefixedpoint”, the intersection of the maximal prefixedpoints. I.e. we find the sets <code class="docutils literal notranslate"><span class="pre">Pre</span> <span class="pre">=</span> <span class="pre">{</span> <span class="pre">R</span> <span class="pre">:</span> <span class="pre">R</span> <span class="pre">subseteq</span> <span class="pre">S(R)</span> <span class="pre">},</span> <span class="pre">PreMax</span> <span class="pre">=</span> <span class="pre">{</span> <span class="pre">R</span> <span class="pre">in</span> <span class="pre">Pre</span> <span class="pre">:</span> <span class="pre">forall</span> <span class="pre">R'</span> <span class="pre">in</span> <span class="pre">Pre,</span> <span class="pre">R</span> <span class="pre">subseteq</span> <span class="pre">R'</span> <span class="pre">implies</span> <span class="pre">R=</span> <span class="pre">R'</span> <span class="pre">},</span> <span class="pre">R</span> <span class="pre">=</span> <span class="pre">intersection</span> <span class="pre">PreMax</span></code>. We warn on all the reductions in <code class="docutils literal notranslate"><span class="pre">S(R)</span> <span class="pre">\</span> <span class="pre">R</span></code> that make it not a fixed point.</p>
<p>For example, with a system with the single rule <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">-&gt;</span> <span class="pre">a</span> <span class="pre">|</span> <span class="pre">a</span> <span class="pre">is</span> <span class="pre">a</span> <span class="pre">normal</span> <span class="pre">form</span></code>, <code class="docutils literal notranslate"><span class="pre">S({})</span> <span class="pre">=</span> <span class="pre">{(a,a)}</span></code> and <code class="docutils literal notranslate"><span class="pre">S({a,a})</span> <span class="pre">=</span> <span class="pre">{}</span></code>. There is no fixed point, so the naive definition doesn’t work. The optimal prefixedpoint is <code class="docutils literal notranslate"><span class="pre">{}</span></code> so <code class="docutils literal notranslate"><span class="pre">R</span> <span class="pre">=</span> <span class="pre">{}</span></code>. But we warn that the reduction <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">-&gt;</span> <span class="pre">a</span></code> is not included. As another example, take <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">-&gt;</span> <span class="pre">b</span> <span class="pre">if</span> <span class="pre">not(c</span> <span class="pre">-&gt;</span> <span class="pre">d);</span> <span class="pre">c</span> <span class="pre">-&gt;</span> <span class="pre">d</span> <span class="pre">if</span> <span class="pre">not(a</span> <span class="pre">-&gt;</span> <span class="pre">b)</span></code>. The maximal (pre)fixedpoints are <code class="docutils literal notranslate"><span class="pre">{(a,b)}</span></code> and <code class="docutils literal notranslate"><span class="pre">{(c,d)}</span></code>, but their intersection is <code class="docutils literal notranslate"><span class="pre">{}</span></code> so the optimal prefixedpoint is <code class="docutils literal notranslate"><span class="pre">R</span> <span class="pre">=</span> <span class="pre">{}</span></code>. We warn that <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">-&gt;</span> <span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span> <span class="pre">-&gt;</span> <span class="pre">d</span></code> are not included (extra diagnostics could show they are mutually exclusive). Lastly, <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">-&gt;</span> <span class="pre">b</span> <span class="pre">if</span> <span class="pre">a</span> <span class="pre">-&gt;</span> <span class="pre">b</span></code> allows the reduction <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">-&gt;</span> <span class="pre">b</span></code> as it is the maximal (pre)fixedpoint.</p>
<p>The optimal prefixedpoint is correct in that reductions must satisfy conditions, conservative in that systems which have multiple differing interpretations do not reduce, but also a bit generous since it is maximal instead of least, and robust because independent rules are processed independently.</p>
<p>As far as terminology, the literature uses “term rewriting” to refer to unconditional term rewriting and “conditional term rewriting” otherwise. But many popular programming languages such as Haskell have conditional dispatch (guards, patterns, etc.), so we instead use “term rewriting” to refer to conditional and unconditional systems, and we refer to “unconditional TRSs” when necessary.</p>
</section>
<section id="cycles">
<h2>Cycles<a class="headerlink" href="#cycles" title="Permalink to this heading"></a></h2>
<p>The untyped lambda calculus has cycles, e.g. <code class="docutils literal notranslate"><span class="pre">Omega</span> <span class="pre">=</span> <span class="pre">let</span> <span class="pre">w=\x.x</span> <span class="pre">x</span> <span class="pre">in</span> <span class="pre">w</span> <span class="pre">w</span></code> reduces to itself and <span id="id4">[<a class="reference internal" href="../zzreferences.html#id162" title="Marissa Venturini Zilli. Reduction graphs in the lambda calculus. Theoretical Computer Science, 29(3):251–275, January 1984. URL: https://www.sciencedirect.com/science/article/pii/0304397584900021 (visited on 2022-06-08), doi:10.1016/0304-3975(84)90002-1.">VZ84</a>]</span> shows a 6-cycle <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">M</span> <span class="pre">I</span></code>. Similarly commutativity <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">+</span> <span class="pre">b</span> <span class="pre">=</span> <span class="pre">b</span> <span class="pre">+</span> <span class="pre">a</span></code> generates cycles.</p>
<p><span id="id5">[<a class="reference internal" href="../zzreferences.html#id42" title="Nachum Dershowitz and Jean-Pierre Jouannaud. Rewrite systems. In Handbook of Theoretical Computer Science (Vol. B): Formal Models and Semantics, pages 243–320. MIT Press, Cambridge, MA, USA, January 1991. URL: https://www.cs.tau.ac.il/~nachum/papers/survey-draft.pdf (visited on 2022-02-25).">DJ91</a>]</span>’s notion of a congruence-class rewriting system is helpful - the rewrite rules are split into rules R and reversible equations S, and we consider the system R/S (R mod S). A term where only S rules apply (no R rules apply) is considered a normal form. So similarly we consider the <a class="reference external" href="https://en.wikipedia.org/wiki/Strongly_connected_component#Definitions">condensation</a> of the rewrite graph, condensing each SCC to a single term. This does away with the “rewriting modulo equations” formalism while still maintaining its power.</p>
<p>A term is a “condensed normal form” if it has no reduction out of its SCC. Hence <code class="docutils literal notranslate"><span class="pre">Omega</span></code>,  <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">M</span> <span class="pre">I</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">+</span> <span class="pre">b</span></code> would be condensed normal forms since their SCC contains themselves and they have no further reductions. We could further specify the normal form to be a canonical representative of the SCC, e.g. taking the smallest and lexicographically first element of the SCC, but leaving input unchanged seems better.</p>
<p>Orthogonal higher-order TRSs that are weakly head normalizing are acyclic, per <span id="id6">[<a class="reference internal" href="../zzreferences.html#id93" title="Jeroen Ketema, Jan Willem Klop, and Vincent van Oostrom. Vicious Circles in Rewriting Systems. In 5th International Workshop on Reduction Strategies in Rewriting and Programming, 20. Nara, Japan, April 2005. URL: https://www.dicosmo.org/WRS05/proceedings/jeroen.pdf.">KKvanOostrom05</a>]</span>, so the cycle condensation doesn’t affect standard functional programming because condensing acyclic rewriting systems gives back the same system. So the cycle detector doesn’t have to be that great, even supporting associativity/commutativity is going into PhD territory.</p>
</section>
<section id="nondeterminism">
<h2>Nondeterminism<a class="headerlink" href="#nondeterminism" title="Permalink to this heading"></a></h2>
<p>A reduction sequence is not necessarily unique, e.g. in reducing <code class="docutils literal notranslate"><span class="pre">3</span> <span class="pre">*</span> <span class="pre">(2</span> <span class="pre">*</span> <span class="pre">fact</span> <span class="pre">1)</span></code> to <code class="docutils literal notranslate"><span class="pre">6</span></code> we could compute <code class="docutils literal notranslate"><span class="pre">fact</span> <span class="pre">1</span> <span class="pre">=</span> <span class="pre">1</span></code> or we could first use an associative law <code class="docutils literal notranslate"><span class="pre">3</span> <span class="pre">*</span> <span class="pre">(2</span> <span class="pre">*</span> <span class="pre">fact</span> <span class="pre">1)</span> <span class="pre">=</span> <span class="pre">(3</span> <span class="pre">*</span> <span class="pre">2)</span> <span class="pre">*</span> <span class="pre">fact</span> <span class="pre">1</span> <span class="pre">=</span> <span class="pre">6</span> <span class="pre">*</span> <span class="pre">(fact</span> <span class="pre">1)</span></code>. Different reduction sequences can be more efficient in terms of memory usage; the compiler should use heuristics and hints to choose the best strategy.</p>
<p>For maximum expressiveness, we also want to allow local nondeterminism. Even if a term has two or more applicable reduction rules and reduces to two normal forms, the context might give the same behavior on the different values. E.g. this should be allowed:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">a</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">b</span>
<span class="nf">a</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">c</span>
<span class="o">#</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">two</span><span class="w"> </span><span class="n">normal</span><span class="w"> </span><span class="n">forms</span><span class="p">,</span><span class="w"> </span><span class="n">nondeterministic</span>

<span class="nf">f</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">d</span>
<span class="nf">f</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">d</span>

<span class="nf">print</span><span class="w"> </span><span class="p">(</span><span class="n">f</span><span class="w"> </span><span class="n">a</span><span class="p">)</span><span class="w"> </span><span class="o">#</span><span class="w"> </span><span class="n">deterministically</span><span class="w"> </span><span class="n">prints</span><span class="w"> </span><span class="n">d</span>
</pre></div>
</div>
<p>However, top-level method dispatch nondeterminism is unresolvable. E.g. <code class="docutils literal notranslate"><span class="pre">print</span> <span class="pre">a</span></code> with this example is an error  - there is no way to reconcile <code class="docutils literal notranslate"><span class="pre">print</span> <span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">print</span> <span class="pre">c</span></code>, because the user can only see one output.</p>
<p>Exceptions complicate the semantics. The literature speaks of “normalizing” strategies that will eventually find a normal form if one exists, but otherwise are allowed to loop forever. In Stroscot non-termination is an exception, so the corresponding property is that if there is any reduction sequence that produces a non-exception value, Stroscot evaluates to that non-exception value, rather than an exception. So <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">amb</span> <span class="pre">(throw</span> <span class="pre">b)</span></code> should reduce to 1. This provides the benefits of lazy evaluation.</p>
<p>The alternative “strict” evaluation strategy would be what the literature calls a “perpetual” strategy - if any strategy diverges, then a perpetual strategy diverges. With a perpetual strategy inlining etc. hold only if reduction of the expression terminates, i.e. one must keep track of termination properties. A perpetual strategy gives the wrong behavior for if-then-else and short-circuit functions, so strict languages special-case these to ensure they don’t cause nontermination. Perpetual strategies are antagonistic, “I’ll crash your program if I can”. The evaluation strategies article discusses strict vs lazy more - overall lazy seems better.</p>
<p>Also, exception propagation is nondeterministic. For example <code class="docutils literal notranslate"><span class="pre">e</span> <span class="pre">=</span> <span class="pre">throw</span> <span class="pre">b</span> <span class="pre">+</span> <span class="pre">throw</span> <span class="pre">c</span></code> will throw either <code class="docutils literal notranslate"><span class="pre">b</span></code> or <code class="docutils literal notranslate"><span class="pre">c</span></code> depending on which is evaluated first, and the choice is observable in a program with <code class="docutils literal notranslate"><span class="pre">e</span> <span class="pre">catch</span> <span class="pre">print</span></code>. Exception nondeterminism is a different category from method dispatch nondeterminism and generally seems benign. So the compiler will not output a diagnostic and will resolve the <code class="docutils literal notranslate"><span class="pre">catch</span></code> using the exception that is most efficient to dispatch. But you can enable an error or warning that ensures caught exceptions are unique. Regardless, the verification system will verify properties for all choices of exception, i.e. <code class="docutils literal notranslate"><span class="pre">(case</span> <span class="pre">e</span> <span class="pre">of</span> <span class="pre">Exc</span> <span class="pre">b</span> <span class="pre">-&gt;</span> <span class="pre">1;</span> <span class="pre">Exc</span> <span class="pre">c</span> <span class="pre">-&gt;</span> <span class="pre">&quot;a&quot;)</span> <span class="pre">:</span> <span class="pre">Int</span></code> will fail but <code class="docutils literal notranslate"><span class="pre">(case</span> <span class="pre">(throw</span> <span class="pre">b)</span> <span class="pre">of</span> <span class="pre">Exc</span> <span class="pre">b</span> <span class="pre">-&gt;</span> <span class="pre">1;</span> <span class="pre">Exc</span> <span class="pre">c</span> <span class="pre">-&gt;</span> <span class="pre">&quot;a&quot;)</span> <span class="pre">:</span> <span class="pre">Int</span></code> will not because <code class="docutils literal notranslate"><span class="pre">c</span></code> is unreachable.</p>
</section>
<section id="infinite-reduction">
<h2>Infinite reduction<a class="headerlink" href="#infinite-reduction" title="Permalink to this heading"></a></h2>
<p>Infinite reduction is useful because it is “smoother” than finite reduction - normal forms exist more often. For example <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">::</span> <span class="pre">x</span></code> reduces to <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">::</span> <span class="pre">1</span> <span class="pre">::</span> <span class="pre">1</span> <span class="pre">::</span> <span class="pre">...</span></code>, <code class="docutils literal notranslate"><span class="pre">fib</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">::</span> <span class="pre">2</span> <span class="pre">::</span> <span class="pre">zipWith</span> <span class="pre">(+)</span> <span class="pre">fib</span> <span class="pre">(head</span> <span class="pre">fib)</span></code> reduces to <code class="docutils literal notranslate"><span class="pre">fib</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">::</span> <span class="pre">2</span> <span class="pre">::</span> <span class="pre">3</span> <span class="pre">::</span> <span class="pre">...</span></code>, and <code class="docutils literal notranslate"><span class="pre">foo</span> <span class="pre">=</span> <span class="pre">let</span> <span class="pre">t</span> <span class="pre">=</span> <span class="pre">\x.</span> <span class="pre">x</span> <span class="pre">x</span> <span class="pre">x</span> <span class="pre">in</span> <span class="pre">t</span> <span class="pre">t</span></code> reduces to <code class="docutils literal notranslate"><span class="pre">foo</span> <span class="pre">=</span> <span class="pre">...</span> <span class="pre">t</span> <span class="pre">t</span> <span class="pre">t</span> <span class="pre">t</span></code>. With finite reduction we would have to use head normal forms and partially evaluated terms. With infinite reduction all of these terms have a proper denotation. Also I/O can be modeled as an infinite value with sub-terms for each outcome of the I/O operation.</p>
<p>The idea is to extend our set of terms to include infinite terms, defined as the <a class="reference external" href="https://en.wikipedia.org/wiki/Complete_metric_space#Completion">metric completion</a> of finite terms with a distance function <span class="math notranslate nohighlight">\(2^{-n}\)</span> if the n-th level of the terms is the first level where a difference appears and 0 if the terms are equal. By convention the top level is level zero. This definition is equivalent to a co-inductive definition of terms, i.e. the largest set consisting of term-parts whose subterms are co-inductive terms.</p>
<p>This set, like the real numbers, is uncountably large and includes terms with no finite description. A more tractable subset is the rational terms, finite cyclic structures (called rational because rational numbers have the similar property that their decimal expansion repeats when written out), but these can’t represent non-repeating structures like the list of fibonacci numbers. The implementation will have to use some computable approximation. Practically most programs will only deal with finite or rational terms so performance on other types of terms is not critical.</p>
<p>There are various extensions of the transitive closure to infinitary reduction, so the question arises as to which one to use. <span id="id7">[]</span> discusses several and provides an ordering so that each is mostly a proper subset of the next (not sure about P* subset bi-infinite). Many of these use the monotonic closure X*, which is the least fixedpoint of the function G defined as G(R) = X(R) union R, which by the (transfinite) Kleene fixed-point theorem exists and is the limit/union of the sequence <span class="math notranslate nohighlight">\(X^0 = \emptyset, X^{n+1} = G(X^n), X^\delta = \bigcup_{\alpha &lt; \delta} X^\alpha\)</span>.</p>
<ul class="simple">
<li><p>S*, the monotonic closure of strongly converging reduction sequences, “strong” being a requirement that the depth of the redexes contracted in successive steps tends to infinity. S=S* for “compatible” TRSs, ones where t R u imply C[t] R C[u] for any context C, which all iTRSs satisfy.</p></li>
<li><p>W*=A=A*, the monotonic closure of weakly converging reduction sequences, and also the <a class="reference external" href="https://en.wikipedia.org/wiki/Adherent_point">adherent points</a> of reduction sequences in the metric space. Weak convergence by itself is not transitively closed, e.g. <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">=</span> <span class="pre">b;</span> <span class="pre">f</span> <span class="pre">x</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">f</span> <span class="pre">(g</span> <span class="pre">x)</span> <span class="pre">a</span></code> has <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">c</span> <span class="pre">a</span> <span class="pre">-ω&gt;</span> <span class="pre">f</span> <span class="pre">(g</span> <span class="pre">(g</span> <span class="pre">(g</span> <span class="pre">...)))</span> <span class="pre">a</span> <span class="pre">-&gt;</span> <span class="pre">f</span> <span class="pre">(g</span> <span class="pre">(g</span> <span class="pre">(g</span> <span class="pre">...)))</span> <span class="pre">b</span></code> <span id="id8">[]</span> <span id="id9">[<a class="reference internal" href="../zzreferences.html#id148" title="Jakob Grue Simonsen. Weak Convergence and Uniform Normalization in Infinitary Rewriting. In Christopher Lynch, editor, Proceedings of the 21st International Conference on Rewriting Techniques and Applications, volume 6 of Leibniz International Proceedings in Informatics (LIPIcs), 311–324. Dagstuhl, Germany, 2010. Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik. \subsection Other We study infinitary term rewriting systems containing finitely many rules. For these, we show that if a weakly convergent reduction is not strongly convergent, it contains a term that reduces to itself in one step (but the step itself need not be part of the reduction). Using this result, we prove the starkly surprising result that for any orthogonal system with finitely many rules, the system is weakly normalizing under weak convergence if\f\ it is strongly normalizing under weak convergence if\f\ it is weakly normalizing under strong convergence if\f\ it is strongly normalizing under strong convergence. As further corollaries, we derive a number of new results for weakly convergent rewriting: Systems with finitely many rules enjoy unique normal forms, and acyclic orthogonal systems are confluent. Our results suggest that it may be possible to recover some of the positive results for strongly convergent rewriting in the setting of weak convergence, if systems with finitely many rules are considered. Finally, we give a number of counterexamples showing failure of most of the results when infinite sets of rules are allowed. URL: http://drops.dagstuhl.de/opus/volltexte/2010/2660 (visited on 2022-07-25), doi:10.4230/LIPIcs.RTA.2010.311.">Sim10</a>]</span>, hence the need for closure. By definition of adherent point, each w-reduct is either an accumulation point, i.e. a appears arbitrarily close infinitely often in a reduction sequence, or an isolated point which can be reached in a finite number of reductions.</p></li>
<li><p>P*: the monotonic closure of the pointwise closure of the reflexive transitive closure (finite multi-step relation).</p></li>
<li><p>bi-infinite rewriting, defined in <span id="id10">[]</span> Section 6.2 as the greatest relation R such that R = the reflexive transitive closure of single-step rewriting union R lifted to apply to subterms.</p></li>
<li><p>T*: the monotonic closure of T, the topological closure of the reflexive transitive closure. T itself is not transitively closed, e.g. <code class="docutils literal notranslate"><span class="pre">leq</span> <span class="pre">0</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">true;</span> <span class="pre">leq</span> <span class="pre">(s</span> <span class="pre">x)</span> <span class="pre">(s</span> <span class="pre">y)</span> <span class="pre">=</span> <span class="pre">leq</span> <span class="pre">x</span> <span class="pre">y;</span> <span class="pre">inf</span> <span class="pre">=</span> <span class="pre">s</span> <span class="pre">inf</span></code> has <code class="docutils literal notranslate"><span class="pre">leq</span> <span class="pre">inf</span> <span class="pre">inf</span> <span class="pre">T</span> <span class="pre">leq</span> <span class="pre">(mu</span> <span class="pre">x.</span> <span class="pre">s</span> <span class="pre">x)</span> <span class="pre">(mu</span> <span class="pre">y.</span> <span class="pre">s</span> <span class="pre">y)</span> <span class="pre">T</span> <span class="pre">true</span></code> (by topological closure of finite approximations of the S towers) but not <code class="docutils literal notranslate"><span class="pre">leq</span> <span class="pre">inf</span> <span class="pre">inf</span> <span class="pre">T</span> <span class="pre">true</span></code> (because the terms are of finite depth). Alternatively I have defined T* as the smallest relation M such that M is reflexively, transitively, and topologically closed and contains the single-step relation, which I think is equivalent.</p></li>
</ul>
<p>S* is the standard in the literature but doesn’t have much going for it besides that. If there is a reduction that switches heads, <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">X</span> <span class="pre">=</span> <span class="pre">b</span> <span class="pre">(c</span> <span class="pre">X);</span> <span class="pre">b</span> <span class="pre">X</span> <span class="pre">=</span> <span class="pre">a</span> <span class="pre">(c</span> <span class="pre">X)</span></code>, then S* says there are no w-reductions. W* has <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">e</span> <span class="pre">-w&gt;</span> <span class="pre">a</span> <span class="pre">(mu</span> <span class="pre">x.</span> <span class="pre">c</span> <span class="pre">x)</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">e</span> <span class="pre">-w&gt;</span> <span class="pre">b</span> <span class="pre">(mu</span> <span class="pre">x.</span> <span class="pre">c</span> <span class="pre">x)</span></code>. TRSs are in general nondeterministic, so the “strong” definition that requires a single limit to exist is too strong.</p>
<p>For cycle condensation we would like to equate as many terms as possible to get large SCCs, and similarly a large reduction relation means there will be an escape from infinite regresses. As an example, with bi-infinite rewriting or T*, the hypercollapsing term <code class="docutils literal notranslate"><span class="pre">mu</span> <span class="pre">x.</span> <span class="pre">C</span> <span class="pre">x</span></code> with rule <code class="docutils literal notranslate"><span class="pre">C</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">x</span></code> will reduce to every term (limit of approximations <code class="docutils literal notranslate"><span class="pre">C^n</span> <span class="pre">f</span> <span class="pre">=</span> <span class="pre">f</span></code>), making it ambiguous, while with W* and P* the hypercollapsing term only reduces to itself hence is a condensed normal form. Similarly with <code class="docutils literal notranslate"><span class="pre">C</span> <span class="pre">A</span> <span class="pre">=</span> <span class="pre">A</span></code> where <code class="docutils literal notranslate"><span class="pre">A</span></code> is a constant, <code class="docutils literal notranslate"><span class="pre">mu</span> <span class="pre">x.</span> <span class="pre">C</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">A</span></code> with bi-infinite/T* but W*/P* don’t reduce at all. Bi-infinite and T* seem equally simple to formalize since they are both single fixed points, so it seems T* wins because it’s larger.</p>
<p>Also conditional rewriting can interact with infinite reduction and cause unwanted behavior with a weak closure. For example consider the system <code class="docutils literal notranslate"><span class="pre">ds</span> <span class="pre">x</span> <span class="pre">y</span> <span class="pre">|</span> <span class="pre">x</span> <span class="pre">==</span> <span class="pre">y</span> <span class="pre">=</span> <span class="pre">e</span></code> and reducing the infinite term <code class="docutils literal notranslate"><span class="pre">G</span> <span class="pre">=</span> <span class="pre">ds</span> <span class="pre">G</span> <span class="pre">G</span></code> (in <span id="id11">[<a class="reference internal" href="../zzreferences.html#id97" title="Jan Willem Klop. Combinatory Reduction Systems. PhD thesis, Rijksuniversiteit Utrecht, June 1980. URL: https://eprints.illc.uva.nl/id/eprint/1876/ (visited on 2022-09-24).">Klo80</a>]</span> this is achieved by the system <code class="docutils literal notranslate"><span class="pre">G</span> <span class="pre">=</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">c</span> <span class="pre">a;</span> <span class="pre">c</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">ds</span> <span class="pre">x</span> <span class="pre">(c</span> <span class="pre">x)</span></code>). Since <code class="docutils literal notranslate"><span class="pre">e</span></code> is a normal form hence equal to itself, all finite terms defined by <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">=</span> <span class="pre">{</span> <span class="pre">x</span> <span class="pre">:</span> <span class="pre">x</span> <span class="pre">==</span> <span class="pre">e</span> <span class="pre">or</span> <span class="pre">x</span> <span class="pre">in</span> <span class="pre">ds</span> <span class="pre">T</span> <span class="pre">T</span> <span class="pre">}</span></code> reduce to <code class="docutils literal notranslate"><span class="pre">e</span></code>. So using a bi-infinite closure, <code class="docutils literal notranslate"><span class="pre">G</span></code> uniquely reduces to <code class="docutils literal notranslate"><span class="pre">e</span></code>. But with a weak closure <code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">=</span> <span class="pre">ds</span> <span class="pre">e</span> <span class="pre">X</span></code> is a normal form and the system becomes nondeterministic. Similarly with <code class="docutils literal notranslate"><span class="pre">dk</span> <span class="pre">x</span> <span class="pre">y</span> <span class="pre">|</span> <span class="pre">x</span> <span class="pre">==</span> <span class="pre">y</span> <span class="pre">=</span> <span class="pre">e</span> <span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">G</span> <span class="pre">=</span> <span class="pre">dk</span> <span class="pre">G</span> <span class="pre">G</span></code>, we should get <code class="docutils literal notranslate"><span class="pre">e</span> <span class="pre">(e</span> <span class="pre">(e</span> <span class="pre">...))</span></code> as the unique result, but with a weak closure we don’t. Another tricky system is <code class="docutils literal notranslate"><span class="pre">c</span> <span class="pre">x</span> <span class="pre">|</span> <span class="pre">x</span> <span class="pre">==</span> <span class="pre">c</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">e;</span> <span class="pre">b</span> <span class="pre">=</span> <span class="pre">c</span> <span class="pre">b</span></code> - the obvious reduction is <code class="docutils literal notranslate"><span class="pre">b</span> <span class="pre">=</span> <span class="pre">mu</span> <span class="pre">x.</span> <span class="pre">c</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">e</span></code>, but this system has a hidden circularity of the form <code class="docutils literal notranslate"><span class="pre">mu</span> <span class="pre">x.</span> <span class="pre">c</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">e</span></code> if <code class="docutils literal notranslate"><span class="pre">mu</span> <span class="pre">x.</span> <span class="pre">c</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">e</span></code>.</p>
<p>The common notions of an ARS carry over to infinitary reductions: <span id="id12">[]</span></p>
<ul class="simple">
<li><p>transitive reduction: irreflexive kernel of reduction closure</p></li>
<li><p>normal form: irreducible term</p></li>
<li><p>strongly normalizing (terminating): every infinite reduction sequence has a limit</p></li>
<li><p>nonterminating reduction: infinite reduction sequence with no limit or that does not reduce to its limit</p></li>
<li><p>weakly normalizing (normalizing): every term has a reduction to a normal form</p></li>
<li><p>confluence: if t reduces to t1 and t2, then there is a common term s such that t1 and t2 reduce to s.</p></li>
<li><p>Church-Rosser: if t1 is equivalent to t2, then there is a common term s such that t1 and t2 reduce to s.</p></li>
<li><p>normal form property w.r.t. reduction:: if u reduces to t and s, and s is a normal form, then t reduces to s</p></li>
<li><p>normal form property: if t is equivalent to s and s is a normal form, then t reduces to s</p></li>
<li><p>unique normalization w.r.t. reduction: if t reduces to t1 and t2, and t1, t2 are normal forms, then t1=t2</p></li>
<li><p>unique normalization: if t1 is equivalent to t2, and t1, t2 are normal forms, then t1=t2</p></li>
</ul>
<p>However common theorems such as Newman’s lemma do not, so it is not clear how useful these are.</p>
</section>
<section id="meaningless-terms">
<h2>Meaningless terms<a class="headerlink" href="#meaningless-terms" title="Permalink to this heading"></a></h2>
<p>If a term never reaches a normal form, then there’s not much semantic meaning in it.  We could compute equivalence classes of these terms but it is easier to define them all away.:cite:<cite>kennawayMeaninglessTermsRewriting1999</cite> defines criteria for a set of meaningless terms:</p>
<ul class="simple">
<li><p>Contains all root-active terms. A term t is root-active if every reduct of t can be reduced to a term with a top-level redex.</p></li>
<li><p>Closure under reduction. If <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">∈</span> <span class="pre">U</span></code>, <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">→</span> <span class="pre">N</span></code> then <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">∈</span> <span class="pre">U</span></code>.</p></li>
<li><p>Closure under substitution. For all <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">∈</span> <span class="pre">U</span></code>, <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">/.</span> <span class="pre">σ</span> <span class="pre">∈</span> <span class="pre">U</span></code></p></li>
<li><p>Overlap. If a redex t overlaps a subterm, and this subterm is in U, then t in U. More specifically, if M nontrivially matches a subterm of the LHS of some rule, i.e. for some position <code class="docutils literal notranslate"><span class="pre">u</span></code> and substitution <code class="docutils literal notranslate"><span class="pre">σ</span></code>, <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">=</span> <span class="pre">subterm</span> <span class="pre">(l</span> <span class="pre">/.</span> <span class="pre">σ)</span> <span class="pre">u</span></code> and <code class="docutils literal notranslate"><span class="pre">subterm</span> <span class="pre">l</span> <span class="pre">u</span></code> is not a variable, then the overall LHS is in U, <code class="docutils literal notranslate"><span class="pre">l</span> <span class="pre">/.</span> <span class="pre">σ</span> <span class="pre">∈</span> <span class="pre">U</span></code>. Specifically for the lambda calculus, if <code class="docutils literal notranslate"><span class="pre">(\x.M)</span> <span class="pre">∈</span> <span class="pre">U</span></code> then <code class="docutils literal notranslate"><span class="pre">(\x.M)</span> <span class="pre">N</span> <span class="pre">∈</span> <span class="pre">U</span></code>. Another way of looking at it is that we want to ensure adding rules <code class="docutils literal notranslate"><span class="pre">t</span> <span class="pre">=</span> <span class="pre">Meaningless</span></code> preserves confluence.</p></li>
<li><p>Indiscernibility - the meaningfullness of a term does not depend on its meaningless subterms. For all M, N, if N can be obtained from M by replacing a set of pairwise disjoint subterms in U with other terms of U, then M ∈ U if and only if N ∈ U.</p></li>
</ul>
<p><span id="id13">[<a class="reference internal" href="../zzreferences.html#id137" title="Paula Severi and Fer-Jan de Vries. Decomposing the Lattice of Meaningless Sets in the Infinitary Lambda Calculus. In Lev D. Beklemishev and Ruy de Queiroz, editors, Logic, Language, Information and Computation, Lecture Notes in Computer Science, 210–227. Berlin, Heidelberg, 2011. Springer. doi:10.1007/978-3-642-20920-8_22.">SdeVries11</a>]</span> adds closure under expansion: if <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">∈</span> <span class="pre">U</span></code>, <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">→</span> <span class="pre">N</span></code> then <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">∈</span> <span class="pre">U</span></code>. This makes the set easier to reason about, but we want <code class="docutils literal notranslate"><span class="pre">t</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">amb</span> <span class="pre">Meaningless</span></code> to evaluate to 1, so <code class="docutils literal notranslate"><span class="pre">t</span></code> can’t be meaningless itself, hence we don’t want this property.</p>
<p>We do add topological closure as a property of the mute terms, to preserve the property that the infinitary rewriting relation is closed. Essentially we are constructing a relation <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">=</span> <span class="pre">{</span> <span class="pre">(u,Meaningless)</span> <span class="pre">:</span> <span class="pre">u</span> <span class="pre">in</span> <span class="pre">U</span> <span class="pre">}</span></code>; it is easy to to see from our metric definition that this is closed iff U is closed. Then our new relation is <code class="docutils literal notranslate"><span class="pre">R'</span> <span class="pre">=</span> <span class="pre">R</span> <span class="pre">union</span> <span class="pre">M</span></code> which is closed because the union of two closed sets is closed.</p>
<p>There are various sets of meaningless terms, going roughly in decreasing size as follows:</p>
<ul class="simple">
<li><p>not head normalizing - head active or infinite left spine form or infinite abstraction</p></li>
<li><p>head active or infinite left spine form x1 … xn -&gt; (…P2)P1.</p></li>
<li><p>head active or infinite abstraction x1 -&gt; x2 -&gt; …</p></li>
<li><p>head active - x1 … xn -&gt; R P1 … Pk where R is root-active</p></li>
<li><p>not weak head normalizing - strong active or strong infinite left spine form (…P2) P1</p></li>
<li><p>strong active - R P1 … Pk where R is root-active</p></li>
<li><p>mute / root-active = not top normalizing</p></li>
</ul>
<p>Root-active or the set of “mute” terms is the smallest set (included by definition), and seems fine. It satisfies all the other properties, meaning we just have to check root-activeness.</p>
<p>A meaningless term set forms an easy set, <span id="id14">[<a class="reference internal" href="../zzreferences.html#id24" title="A. Bucciarelli, A. Carraro, G. Favro, and A. Salibra. Graph easy sets of mute lambda terms. Theoretical Computer Science, 629:51–63, May 2016. URL: https://www.sciencedirect.com/science/article/pii/S0304397515011858 (visited on 2022-07-01), doi:10.1016/j.tcs.2015.12.024.">BCFS16</a>]</span> meaning we can safely equate all meaningless terms to an exception term without changing the semantics of normal terms. In particular we can equate them to a <code class="docutils literal notranslate"><span class="pre">Meaningless</span></code> exception.</p>
<p>With these reductions every term has a normal form. Proof <span id="id15">[]</span>: A term t is either meaningless or not (ignoring reductions to <code class="docutils literal notranslate"><span class="pre">Meaningless</span></code>). If it is meaningless, it reduces to the normal form <code class="docutils literal notranslate"><span class="pre">Meaningless</span></code>. If it is not, then it can be reduced to a root-stable term <code class="docutils literal notranslate"><span class="pre">s</span></code>. Repeating the construction recursively on the subterms of s at depth 1 constructs a reduction of t to a term which is stable at every depth, i.e. a normal form.</p>
<p>Every TRS with unique normal forms (UN=) can be extended to a confluent TRS with the same set of normal forms by adding bottom terms and reductions to normal forms and bottoms that preserve the equivalence classes of terms. <span id="id16">[<a class="reference internal" href="../zzreferences.html#id112" title="Aart Middeldorp. Modular aspects of properties of term rewriting systems related to normal forms. In G. Goos, J. Hartmanis, D. Barstow, W. Brauer, P. Brinch Hansen, D. Gries, D. Luckham, C. Moler, A. Pnueli, G. Seegmüller, J. Stoer, N. Wirth, and Nachum Dershowitz, editors, Rewriting Techniques and Applications, volume 355, pages 263–277. Springer Berlin Heidelberg, Berlin, Heidelberg, 1989. URL: http://link.springer.com/10.1007/3-540-51081-8_113 (visited on 2021-09-14), doi:10.1007/3-540-51081-8_113.">Mid89</a>]</span> Meaningless terms don’t accomplish this extension because a term <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">amb</span> <span class="pre">meaningless</span></code> can reduce to <code class="docutils literal notranslate"><span class="pre">Meaningless</span></code> instead of <code class="docutils literal notranslate"><span class="pre">1</span></code> hence breaking even UNR.</p>
</section>
<section id="left-nonlinearity">
<span id="trs-equality-linearity"></span><h2>Left-nonlinearity<a class="headerlink" href="#left-nonlinearity" title="Permalink to this heading"></a></h2>
<p>There are several notions of equality that could be used for non-linear patterns, here presented in the order of decreasing strength (earlier implies later):</p>
<ul class="simple">
<li><p>strict equality <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">==</span> <span class="pre">b</span></code> - true if both sides reduce to same unique normal form, false if reduce to different unique normal forms, indeterminate if could reduce to same or different normal forms.</p></li>
<li><p>syntactic equality <code class="docutils literal notranslate"><span class="pre">syn_eq</span> <span class="pre">a</span> <span class="pre">b</span></code> matches terms (reduced or unreduced) that are syntactically identical. It can match even if the term doesn’t have a normal form. It is the notion commonly used for non-left-linear TRSs in the literature.</p></li>
<li><p>oriented equality <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">-&gt;*</span> <span class="pre">b</span></code> holds if <code class="docutils literal notranslate"><span class="pre">a</span></code> reduces to <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p></li>
<li><p>join equality <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">↓</span> <span class="pre">b</span></code> means that a common reduct exists, i.e. there is a term <code class="docutils literal notranslate"><span class="pre">c</span></code> such that <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">-&gt;</span> <span class="pre">c</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span> <span class="pre">-&gt;</span> <span class="pre">c</span></code>.</p></li>
<li><p>semi-equational equality <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">≈</span> <span class="pre">b</span></code> means that <code class="docutils literal notranslate"><span class="pre">a</span></code> can be rewritten to <code class="docutils literal notranslate"><span class="pre">b</span></code> via rewrites and inverse rewrites.</p></li>
</ul>
<p>Computing any of these equalities is of complexity <span class="math notranslate nohighlight">\(\Sigma^0_1\)</span> - at least <span class="math notranslate nohighlight">\(\Sigma^0_1\)</span> because it is a nontrivial property of the reduction relation, but at most <span class="math notranslate nohighlight">\(\Sigma^0_1\)</span> because for equal terms there is a finite rewrite sequence as proof. If reduction is convergent, then for strict equality this reduction sequence can be computed straightforwardly by reducing to normal form, whereas the others involve a brute force search.</p>
<p>Semi-equational equality has “spooky action at a distance” when non-deterministic terms are involved. Consider the system <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">=</span> <span class="pre">b;</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">c;</span> <span class="pre">f</span> <span class="pre">x</span> <span class="pre">(not</span> <span class="pre">x)</span> <span class="pre">=</span> <span class="pre">d</span></code> and the terms <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">{a,b,c}</span> <span class="pre">{a,b,c}</span></code>.</p>
<ul class="simple">
<li><p>For semi-equational equality, <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">a</span> <span class="pre">a</span></code> reduces to the 4 combinations <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">{b,c}</span> <span class="pre">{b,c}</span></code>, but the “spooky” equality <code class="docutils literal notranslate"><span class="pre">b</span> <span class="pre">≈</span> <span class="pre">c</span></code> holds, so the <code class="docutils literal notranslate"><span class="pre">f</span></code> rule does not apply. Hence these 4 combinations are the normal forms.</p></li>
<li><p>For strict, syntactic, oriented, and join equalities, <code class="docutils literal notranslate"><span class="pre">b</span> <span class="pre">!=</span> <span class="pre">c</span></code> so the two heterogeneous combinations <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">b</span> <span class="pre">c</span></code> and <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">c</span> <span class="pre">b</span></code> reduce to <code class="docutils literal notranslate"><span class="pre">d</span></code>. The <code class="docutils literal notranslate"><span class="pre">f</span></code> rule does not apply to <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">a</span> <span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">b</span> <span class="pre">b</span></code>, or <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">c</span> <span class="pre">c</span></code>.</p></li>
</ul>
<p>To ensure convergence we have to have stable conditions, meaning if the terms involved are reduced then they are still equal (Terese 4.11.1, page 145 / PDF page 165). For example consider the system <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">=</span> <span class="pre">b;</span> <span class="pre">f</span> <span class="pre">x</span> <span class="pre">|</span> <span class="pre">x</span> <span class="pre">==</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">c</span></code> and the term <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">a</span></code>.</p>
<ul class="simple">
<li><p>For strict, join, and semi-equational equality, we have that <code class="docutils literal notranslate"><span class="pre">(a</span> <span class="pre">==</span> <span class="pre">a)</span> <span class="pre">=</span> <span class="pre">(a</span> <span class="pre">==</span> <span class="pre">b)</span> <span class="pre">=</span> <span class="pre">(b</span> <span class="pre">==</span> <span class="pre">b)</span> <span class="pre">=</span> <span class="pre">true</span></code> so <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">f</span> <span class="pre">b</span> <span class="pre">=</span> <span class="pre">c</span></code> and also <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">c</span></code> directly.</p></li>
<li><p>For syntactic and oriented equality, we do not have <code class="docutils literal notranslate"><span class="pre">b</span> <span class="pre">==</span> <span class="pre">a</span></code>, so <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">a</span></code> reduces to both <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> and the system is nondeterministic.</p></li>
</ul>
<p>Terese’s example 4.11.5 that join equality is not confluent does not work because with the optimal prefixedpoint we have <code class="docutils literal notranslate"><span class="pre">c</span> <span class="pre">e</span> <span class="pre">=</span> <span class="pre">e</span></code>. Still, join equality is unstable in a non-confluent system. For example <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">x</span> <span class="pre">|</span> <span class="pre">x</span> <span class="pre">==</span> <span class="pre">b</span> <span class="pre">=</span> <span class="pre">x;</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">b;</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">c</span></code> and the term <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">a</span></code>:</p>
<ul class="simple">
<li><p>With strict, syntactic, and oriented equality, there are only 2 NFs: <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">f</span> <span class="pre">b</span> <span class="pre">=</span> <span class="pre">b</span></code>, and <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">f</span> <span class="pre">c</span></code>.</p></li>
<li><p>With join and semi-equational equality, there is a third reduction pattern <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">a</span> <span class="pre">=</span> <span class="pre">b/c</span></code>, giving the additional normal form <code class="docutils literal notranslate"><span class="pre">c</span></code>.</p></li>
</ul>
<p>Overall strict equality is the most conservative (least accepting), and the one whose behavior seems easiest to understand. It does reduce the laziness of the language a bit but even Haskell’s <code class="docutils literal notranslate"><span class="pre">==</span></code> function is strict. So we’ll go with strict equality.</p>
<p>There is some question about reducible expressions as patterns, e.g. <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">=</span> <span class="pre">b;</span> <span class="pre">f</span> <span class="pre">a&#64;x</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">x</span></code>. I think this can be handled separately from non-linear patterns.</p>
<section id="confluence">
<h3>Confluence<a class="headerlink" href="#confluence" title="Permalink to this heading"></a></h3>
<p>Confluence has gotten a lot of attention as well and has automated provers. Confluence implies UN→; it is equivalent if the TRS is weakly normalizing. And there is an extension theorem:  Similarly a system can be shown to be UN= by presenting an extension of it that is confluent. <span id="id17">[<a class="reference internal" href="../zzreferences.html#id98" title="Jan Willem Klop and Roel de Vrijer. Extended term rewriting systems. In S. Kaplan and M. Okada, editors, Conditional and Typed Rewriting Systems, Lecture Notes in Computer Science, 26–50. Berlin, Heidelberg, 1991. Springer. URL: https://ir.cwi.nl/pub/20015/20015A.pdf, doi:10.1007/3-540-54317-1_79.">KdeVrijer91</a>]</span> So a UN= program is just a partially specified system. UN→ is a little more complex though. And the equivalence classes of terms are uncomputable in general so the extension is as well.</p>
<p>Confluence avoids situations where a system may branch into two distinct diverging states. It makes finding a normalizing strategy much easier as the strategy only has to avoid getting stuck evaluating a term infinitely (using the same rule infinitely often), as opposed to UN→ where the strategy must avoid using the wrong reduction rule at every step.</p>
<p>The Knuth-Bendix algorithm produces a confluent system from a set of non-oriented equations, but the rules in programs are oriented, so using this would be confusing. Not to mention that the algorithm fails often. So that’s out.</p>
<p>A necessary condition for confluence is weak/local confluence, i.e. each critical pair is convergent. But this is not sufficient. Newman’s lemma is that a terminating locally confluent TRS is confluent. But termination is quite strong. A generalization is a critical pair system <span id="id18">[<a class="reference internal" href="../zzreferences.html#id73" title="Nao Hirokawa and Aart Middeldorp. Decreasing Diagrams and Relative Termination. arXiv:0910.2853 [cs], October 2009. Comment: v3: missing references added. URL: http://arxiv.org/abs/0910.2853 (visited on 2021-09-14), arXiv:0910.2853.">HM09</a>]</span> (also called decreasingly confluent): the system must be left-linear, locally confluent, and its critical pair steps must be <em>relatively terminating</em>, i.e. the relation ‘arbitrary steps followed by a critical pair step followed by arbitrary steps’ is terminating. Trivial critical pair steps can be excluded, hence this includes weakly orthogonal TRSs. For a terminating TRS the TRS syntactic equality notion is equivalent to strict equality, hence the system is left linear in the CTRS sense, hence why this includes Newman’s lemma.</p>
<p>We say → has random descent (RD), if for each R:a ↔∗b with b in normal form, all maximal reductions from a have length d(R) and end in b. Systems with random descent are confluent.</p>
</section>
<section id="normalization">
<h3>Normalization<a class="headerlink" href="#normalization" title="Permalink to this heading"></a></h3>
<p>A hypernormalizing strategy is a strategy that is normalizing even if arbitrary reduction steps are taken before and after steps of the strategy. This allows the compiler to make optimizations without changing the behavior of the program. A hypernormalizing strategy allows aggressive optimizations and program transforms.</p>
<p>There are also stronger properties than normalization. A Church-Rosser strategy is one with common reducts, i.e. there exist m and n, such that <span class="math notranslate nohighlight">\(F^m(t)=F^n(u)\)</span> for every t and u equal via forward/backward evaluation. A normalizing strategy is Church-Rosser if the system is confluent and weakly normalizing (i.e. all objects have a normal form). In general a many-step CR strategy exists for effective ARS’s, i.e. countable (in a computable fashion) and with a computable reduction relation. But the strategy is quite hard to compute, as it has to synchronize reducing subterms so that all components are reduced the same amount. And it’s not clear that this synchronization offers anything to the programmer.</p>
<p>Cofinal strategies are weaker than Church-Rosser but stronger than normalizing: for every term a, if a reduces in a finite number of steps to b, then there is an object c obtained by applying the strategy some number of times to a such that b reduces to c. For critical pair TRSs any “fair” strategy that ensures every redex is eventually contracted is cofinal. The cofinal property provides slick proofs - it ensures every redex not part of a cycle is contracted. But at runtime non-normalizing terms have indistinguishable behavior (infinite loop), hence this means the cofinal strategy is doing unnecessary work.</p>
<p>There are also termination properties like strong convergence that ensure that for every term, there exists some number of reduction steps after which the head cannot be rewritten.
To ensure that term rewriting halts we probably also want a property like strong convergence, but this is a property of the rewriting strategy, not the TRS proper.</p>
</section>
</section>
<section id="evaluation-strategy">
<h2>Evaluation strategy<a class="headerlink" href="#evaluation-strategy" title="Permalink to this heading"></a></h2>
<p>For convergent (confluent and strongly normalizing) programs, such as the simply typed lambda calculus, all strategies are normalizing and the result is the same no matter how they are reduced. So the focus is on inferring convergence and doing reduction efficiently. “In the small” leftmost innermost ensures “complete development”, i.e. a subterm is reduced completely before the outer term, hence we can compute the subterm fully and only store an optimized representation of the normal form. So we can compile to fast assembly like a state machine. “In the large” optimal reduction ensures the smallest number of steps so we can avoid duplicating work and performing unneeded work.</p>
<p>But strongly normalizing implies not Turing complete, hence the termination verification will cause problems for complex programs. We need a fallback for these complex programs. Leftmost outermost reduction is the basis of lazy evaluation and is hypernormalizing for the lambda calculus. But for TRSs LO is only normalizing for left-normal TRSs, where variables do not precede function symbols in the left-hand sides of the rewrite rule. A better strategy is outermost fair (ensuring each outermost redex will eventually be evaluated - the simplest example is parallel outermost) - it’s hypernormalizing for critical pair TRSs (decreasingly confluent TRSs), in particular weakly orthogonal TRSs. <span id="id19">[<a class="reference internal" href="../zzreferences.html#id74" title="Nao Hirokawa and Aart Middeldorp. Strategies for Decreasingly Confluent Rewrite Systems. Reduction Strategies in Rewriting and Programming, pages 23, 2011. URL: http://elp.webs.upv.es/workshops/wrs2011/pre-proceedings.pdf#page=31.">HM11</a>]</span> So outermost fair seems a reasonable default, but there are non-orthogonal systems where it fails. The optimal reduction stuff is defined for match sequential TRSs but is a normalizing strategy that computes a result in the smallest number of reduction steps.</p>
<p>We could do user-specified strategies like Stratego, but then how would we know that they’re normalizing.</p>
<p>There are is also lenient evaluation which evaluates all redexes in parallel except inside the arms of conditionals and inside lambdas, but it adds extra memory overhead for parameter passing.</p>
<p>Now, one can argue about which computational strategy is better (time, space, parallelism, …)
Stroscot: be accepting of programs, ensure a normalizing strategy. But after that aim for most efficient in time/space for strict programs.</p>
<p>Q: can normalizing be as efficient as strict
profiling, other optimization tricks</p>
<p>So The way we handle cycles in the rewrite engine is something like:</p>
<ul class="simple">
<li><p>detect cyclic term via rule cycle detection or presence of AC operator</p></li>
<li><p>use specialized matching (eg AC matching or Tarjan SCC + memo hash table) to identify all reductions out of SCC</p></li>
<li><p>end with condensed normal form if no reduction out of SCC</p></li>
<li><p>otherwise, pick a reduction out of the SCC</p></li>
</ul>
<p>Then this infinite term is computed in chunks and fed to the surrounding context on demand (laziness), ensuring that a finite normal form is reached if possible and otherwise implementing an infinite stream of commands.</p>
<section id="higher-order-matching">
<h3>Higher-order matching<a class="headerlink" href="#higher-order-matching" title="Permalink to this heading"></a></h3>
<p>If the substitution calculus is convergent, then terms can be represented by preterms in normal form.</p>
<p>Handling lambdas in RHSs is fairly straightforward, just beta-reduce as much as possible when they are encountered. But in higher-order term rewriting systems the lambdas can show up on the left hand side, in the pattern. The rewriting system is then defined modulo lambda reduction.</p>
<p>Finding the contexts <code class="docutils literal notranslate"><span class="pre">C</span></code> is fairly straightforward, just enumerate all the subterms of <code class="docutils literal notranslate"><span class="pre">t</span></code>. But solving the equation <code class="docutils literal notranslate"><span class="pre">s</span> <span class="pre">=</span> <span class="pre">lθ</span></code> is an instance of higher-order unification (specifically higher-order matching).  The λ-superposition calculus relies on complete sets of unifiers (CSUs). The
CSU for s and t, with respect to a set of variables V , denoted by CSUV (s, t), is a
set of unifiers such that for any unifier % of s and t, there exists a σ ∈ CSUV (s, t)
and θ such that %(X) = (σ◦θ)(X) for all X ∈ V . The set X is used to distinguish
between important and auxiliary variables. We can normally leave it implicit</p>
<p>Higher order matching is decidable for the simply typed lambda calculus. But the proof is of the form “the minimal solution is of size at most 2^2^2^2…, the number of 2’s proportional to the size of the problem”. There are 3 transformations presented in the proof which reduce a larger solution to a smaller solution. These might be usable to prune the search tree. But at the end of the day it’s mostly brute-force.</p>
<p>The proof relies on some properties of the STLC, namely normalization and that terms have a defined eta long form (canonical form).</p>
<p>It is not clear if there is a way to do untyped higher order matching for general lambda patterns.</p>
<p>As a consequence of confluence each rewrite step is composed of an expansion in the substitution calculus, a replacement by applying some rule, and a reduction in the substitution calculus, so it is M &lt;&lt;- C[l] and C[r] -&gt;&gt; N</p>
<p>If reduction does not end in a condensed normal form, then the sequence of terms must be infinitely expanding in the sense that for every size s there is a point in the reduction where terms are always at least size s. Otherwise, assuming a finite number of term symbols, there are only finitely many terms of size &lt; s, so there would be a cycle in the reduction and reduction would end in a condensed normal form.</p>
<p>A context is linear if every hole occurs exactly once.</p>
</section>
</section>
<section id="verifying-confluence">
<h2>Verifying confluence<a class="headerlink" href="#verifying-confluence" title="Permalink to this heading"></a></h2>
<p>We often want to prove confluence. There are some key algorithms:</p>
<ul>
<li><p>The decreasing diagrams technique is a complete method for confluence on countable abstract rewrite systems.</p></li>
<li><p>Computing critical pairs. A non-joinable critical pair means the system is not confluent. If all critical pairs are joinable the system is said to be locally confluent. An orthogonal system is one with no critical pairs, while a weakly orthogonal system is one with critical pairs that are trivially joinable. For an HORS there are more constraints to be orthogonal in addition to no critical pairs (“every set of redexes is pairwise simultaneous”). The substitution calculus must be complete, only needed for gluing, a descendant rewriting system, parametric, have head-defined rules, and be naturally closed under substitution. Parallel rewrite steps must be serializable and left-hand sides of rules must be linear.</p>
<p>V. van Oostrom. Developing developments. TCS, 175(1):159–181, 1997.
V. van Oostrom and F. van Raamsdonk. Weak orthogonality implies confluence: The higher order case. In Proc. 3rd LFCS, volume 813 of LNCS, pages 379–392, 1994.</p>
</li>
<li><p>Proving termination. The Knuth Bendix Criterion (Newmann’s lemma) says a terminating system is confluent iff it is locally confluent. Termination can be shown by exhibiting a well-ordering, such as recursive path ordering, dependency graph decomposition, and the subterm criterion.</p>
<p>WANDA has more advanced techniques. Cynthia Kop. Higher Order Termination. PhD thesis, Vrije Universiteit, Amsterdam, 2012</p>
<p>TTT2 also has some good techniques.</p>
<p>Gramlich–Ohlebusch’s criterion says for innermost-terminating TRSs R with no innermost critical pairs, R is confluent if and only if all critical pairs are joinable by innermost reduction. There are innermost terminating systems that aren’t terminating so this criterion can prove some systems that Knuth-Bendix can’t.</p>
</li>
<li><p>Decomposition: Several properties allow dividing the system into smaller, more tractable systems. First is modularity, that the disjoint union of two systems with the property has the property. We also usually have the converse, the disjoint union has the property only if the subsystems have the property.</p>
<ul class="simple">
<li><p>Weak normalization and consistency (w.r.t. equivalence) are modular for first-order systems.</p></li>
<li><p>Left linearity, confluence, and unique normal forms (w.r.t. equivalence) are modular for semi-equational CTRSs.</p></li>
<li><p>Confluence is modular for join and semi-equational CTRSs. In fact if the disjoint union is confluent then the component systems must be confluent.</p></li>
<li><p>Confluence plus left linearity is modular for higher-order TRSs.</p></li>
<li><p>Weak termination, weak innermost termination, and strong innermost termination are modular for CTRSs in combination with confluence or the property that there are no extra variables in the conditions.</p></li>
<li><p>NF, unique normal forms with respect to reduction, and consistency with respect to reduction are modular in combination with left linearity. Consistency w.r.t. reduction means that there is no term reducing to two distinct variables; it is implied by the unique normal form property w.r.t. reduction as variables are normal forms.</p></li>
<li><p>Strong normalization plus consistency w.r.t. reduction plus left linearity is modular. This likely holds for CTRSs without extra variables as well.</p></li>
</ul>
<p>Order-sorted decomposition uses persistence of confluence. If sorts can be assigned to all terms and rule variables such that all rules don’t increase the sort, then confluence can be separately considered for each sort and confluence as a whole follows from confluence on well-sorted terms.</p>
<p>Decreasing diagrams allows decomposing a left-linear TRS into duplicating and non-duplicating rules. The TRS is confluent if all critical peaks are decreasing with respect to a rule labeling and the duplicating rules are terminating relative to the non-terminating rules.</p>
<p>Layer-preserving decomposition decomposes TRSs into minimal pieces such that taking pieces pairwise they form layer-preserving combinations, i.e. rules in one piece operate only on terms of that piece. It is used in CSI.</p>
</li>
<li><ol class="upperalpha simple" start="10">
<li><p>Nagele, B. Felgenhauer, and A. Middeldorp. Improving automatic confluence analysis of rewrite systems by redundant rules. In Proc. 26th RTA, volume 36 of LIPIcs, pages 257–268, 2015.</p></li>
</ol>
</li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Syntax.html" class="btn btn-neutral float-left" title="Syntax" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Time.html" class="btn btn-neutral float-right" title="Time API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2022 Mathnerd314.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>