<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Intermediate representation &mdash; Stroscot  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/hexagon_favicon.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Intrinsics" href="Intrinsics.html" />
    <link rel="prev" title="As fast as C" href="Fastest.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html">
            
              <img src="../_static/hexagon_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/index.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../HowTo/index.html">How to</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Reference/index.html">Language Reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Commentary</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Assembly.html">Assembly</a></li>
<li class="toctree-l2"><a class="reference internal" href="BuildSystem.html">Build system</a></li>
<li class="toctree-l2"><a class="reference internal" href="Checklist.html">Checklist</a></li>
<li class="toctree-l2"><a class="reference internal" href="Code-Generation.html">Code generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Compiler.html">Compiler design</a></li>
<li class="toctree-l2"><a class="reference internal" href="Compiler-Library.html">Compiler library</a></li>
<li class="toctree-l2"><a class="reference internal" href="CompilerOutput.html">Compiler output</a></li>
<li class="toctree-l2"><a class="reference internal" href="Concurrency.html">Concurrency</a></li>
<li class="toctree-l2"><a class="reference internal" href="CoreSyntax.html">Core syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="Dispatch.html">Dispatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="Errors.html">Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="Evaluation-Strategy.html">Evaluation strategy</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exceptions.html">Exceptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="Fastest.html">As fast as C</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Intermediate representation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#goals">Goals</a></li>
<li class="toctree-l3"><a class="reference internal" href="#transformations">Transformations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sequent-core">Sequent Core</a></li>
<li class="toctree-l3"><a class="reference internal" href="#operations">Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#control-flow">Control flow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#blocks">Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id19">Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#values">Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Intrinsics.html">Intrinsics</a></li>
<li class="toctree-l2"><a class="reference internal" href="Learning.html">Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Logic.html">Logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="LogicProgramming.html">Logic programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="Macros.html">Macros</a></li>
<li class="toctree-l2"><a class="reference internal" href="Memory-Management.html">Memory management</a></li>
<li class="toctree-l2"><a class="reference internal" href="Meta.html">Meta</a></li>
<li class="toctree-l2"><a class="reference internal" href="Modules.html">Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="Objects.html">Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="PackageManager.html">Package manager</a></li>
<li class="toctree-l2"><a class="reference internal" href="Parsing.html">Parsing</a></li>
<li class="toctree-l2"><a class="reference internal" href="Posets.html">Posets</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html">Profiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#resources">Resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#metrics">Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#statistics">Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#methods">Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#action">Action</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html#caches">Caches</a></li>
<li class="toctree-l2"><a class="reference internal" href="Programs.html">Exemplary programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction.html">Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction-Example.html">Reduction example</a></li>
<li class="toctree-l2"><a class="reference internal" href="Resource-Management.html">Resource management</a></li>
<li class="toctree-l2"><a class="reference internal" href="Sets.html">Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="Standard-Library.html">Standard library</a></li>
<li class="toctree-l2"><a class="reference internal" href="State.html">Stateful programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="Syntax.html">Syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="TermRewriting.html">Term rewriting</a></li>
<li class="toctree-l2"><a class="reference internal" href="Time.html">Time API</a></li>
<li class="toctree-l2"><a class="reference internal" href="Tools.html">Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="Types.html">Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="Units.html">Units</a></li>
<li class="toctree-l2"><a class="reference internal" href="Verification.html">Verification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../zzreferences.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Stroscot</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Commentary</a></li>
      <li class="breadcrumb-item active">Intermediate representation</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/Mathnerd314/stroscot/edit/master/docs/Commentary/IR.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="intermediate-representation">
<h1>Intermediate representation<a class="headerlink" href="#intermediate-representation" title="Permalink to this heading"></a></h1>
<p>The intermediate representation (IR) is the main workhorse of Stroscot’s execution engine. In most cases, source code is loaded once and transformed into IR, and never transformed back. IR allows many things that are not possible or efficient using a source code representation, as it stores more information and avoids irrelevant syntactic details.</p>
<section id="goals">
<h2>Goals<a class="headerlink" href="#goals" title="Permalink to this heading"></a></h2>
<p>An IR represents the initial and final states of a transformation phase in the compilation pipeline. Considering the entire compiler as a transformation, we see that the source language should be valid IR, as well as machine code. All the source constructs of the source language should be expressible 1-1 and print out exactly, and similarly there should be IR constructs to output any sequence of bytes into the resulting executable. Of course the fewer constructs the better, but considering the wide range of variation in hardware, some amount of redundancy is fine.</p>
<p>But compilation is insufficient, we would also like to use the IR for the interpreter. Thus every IR node should have an execution semantics. This avoids most instances of vagueness or edge cases in the specification. It also ensures that expanding high level abstractions into lots of small low-level instructions is only necessary for compilation, whereas the interpreter can use fewer, more expensive high-level instructions to get lower instruction dispatch overhead. In particular, type checks, method dispatch, and mathematical values like unbounded integers and computable reals can all benefit from having specialized operations.</p>
<p>In the case of interpreting machine code, we get a “literal machine” like Zed Shaw’s EaRing. Unlike traditional “virtual” machines where interpreting even the lowest-level IR instruction may still take several machine code instructions, the interpreter executes each IR machine instruction as a single machine code instruction, allowing pretty efficient “pre-compiled methods”. The interpreter or “literal machine” might alternatively be termed an “assembler” because it takes an “assembly language”, but LLVM and Java started using the term VM a long time ago, so “machine” is more fun. Also, traditionally assemblers are compilers rather than interpreters - Stroscot allows dynamic loading of new code, running code at a REPL, and introspection such as listing constants and functions from imports. It makes learning assembly pretty fun.</p>
<p>Like MLIR, the IR comes in three different forms, all describing the same semantic content:</p>
<ul class="simple">
<li><p>an in-memory form. This should have a low memory footprint, although not compressed. It should be low overhead to generate from AST, analyze, and interpret directly. Transformations should be localized, meaning they only affect a small portion of the IR and only need a few memory accesses rather than a full traversal of the graph.</p></li>
<li><p>a textual form. This should have all IR information so as to be suitable for debugging (lossless). It should be easily parsable so that scripting tasks do not require building the full in-memory representation (easy to read for machines). Within those constraints, it should be as human-readable as possible (easy to read for humans), and easily diff’able (avoiding redundantly repeating information). This enables a workflow where IR can be read from a file, sent through a few passes, dumped to another file, and the passes can be messed with until the output is correct.</p></li>
<li><p>a serialized “bytecode” form. The main use is build system caching. It should be compact so that disk/network usage is minimized. Gzipping the textual format seems the obvious possibility, but maybe a true binary format will be more efficient. It is also important to be able to serialize snippets of IR in isolation.</p></li>
</ul>
<p>Also like MLIR, the IR is a <a class="reference external" href="https://en.wikipedia.org/wiki/Wide-spectrum_language">wide-spectrum language</a>, coming in various dialects, roughly ordered linearly on a spectrum of abstraction level from source-like to assembly-like. The compilation process gradually down-translates and eliminates dialects, but any set of dialects may be in use for a particular phase. The use of a common IR representation across dialects allows sharing infrastructure for certain transformations, such as constant folding, dead code elimination, and graph rewriting. It also avoids unnecessarily translating data by allowing it to be pre-specified in a usable format. The transformations are designed to be extensible, passing through unknown operations uninterpreted. Codegen can treat unknown ops as clobbering all registers, although of course producing machine code requires knowing how to emit the operation. The IR also supports metadata, so that analysis passes can add necessary annotations.</p>
<p>Unlike Java bytecode, the IR is target-specific. Specific instances of the IR will assume processor features and other configuration, such as microarchitecture, calling conventions, alignment requirements, etc. Practically, code is “portable” only because of the use of conditional compilation for specific platforms that papers over the differences. Java files, networking, GUI, threading, and native methods are targer-specific, LLVM IR is target-specific, even WASM has different incompatible system interfaces. Maintaining these conditionals as opaque operations at the IR level would prevent many useful optimizations, although of course the opaque format does allow certain optimization rules to only be written once.</p>
<p>For debugging and diagnostic purposes, it is important to define a reverse transformation back from IR to AST, so that error messages can display the relevant code. For example, inlining may expand a macro, and the error in the macro may require showing bits of the IR for context. The AST generated from the IR does not have to be the original AST, it should instead accurately depict the IR. But the IR should capture source locations and other information necessary for good error messages.</p>
</section>
<section id="transformations">
<h2>Transformations<a class="headerlink" href="#transformations" title="Permalink to this heading"></a></h2>
<p>As mentioned in the goals section, the in-memory form of IR should be suitable for all of the various transformations analyses. A <a class="reference external" href="http://venge.net/graydon/talks/CompilerTalk-2019.pdf">talk</a> by Graydon Hoare on compilers mentions the paper <span id="id1">[<a class="reference internal" href="../zzreferences.html#id6" title="Frances E Allen and John Cocke. A catalogue of optimizing transformations. IBM Research Center, pages 30, 1971. URL: https://www.clear.rice.edu/comp512/Lectures/Papers/1971-allen-catalog.pdf.">AC71</a>]</span>. He says we need 8 optimization passes to get 80% of GCC/LLVM performance: Inline, Unroll (&amp; Vectorize), CSE, DCE, Code Motion, Constant Fold, Peephole. An ideal IR makes these optimizations as cheap as possible.</p>
<p>Constant folding, inlining, and unrolling all fall under compile-time reduction. Specifically:</p>
<ul class="simple">
<li><p>Constant folding reduces closed expressions, like <code class="docutils literal notranslate"><span class="pre">1+2</span></code> to <code class="docutils literal notranslate"><span class="pre">3</span></code>.</p></li>
<li><p>Inlining replaces a term with its expansion, like a rewrite step in term rewriting. Per <span id="id2">[<a class="reference internal" href="../zzreferences.html#id125" title="Simon Peyton Jones and Simon Marlow. Secrets of the Glasgow Haskell Compiler inliner. Journal of Functional Programming, 12(4):393–434, July 2002. URL: https://www.microsoft.com/en-us/research/wp-content/uploads/2002/07/inline.pdf (visited on 2020-07-01), doi:10.1017/S0956796802004331.">PJM02</a>]</span>, inlining subsumes copy propagation and jump elimination.</p></li>
<li><p>Loop-unrolling is typically phrased in an iterative setting, e.g. <code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">(x</span> <span class="pre">=</span> <span class="pre">0;</span> <span class="pre">x</span> <span class="pre">&lt;</span> <span class="pre">100;</span> <span class="pre">x++)</span> <span class="pre">delete(x)</span></code> to <code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">(x</span> <span class="pre">=</span> <span class="pre">0;</span> <span class="pre">x</span> <span class="pre">&lt;</span> <span class="pre">100;</span> <span class="pre">x</span> <span class="pre">+=</span> <span class="pre">2)</span> <span class="pre">{</span> <span class="pre">delete(x);</span> <span class="pre">delete(x+1);</span> <span class="pre">}</span></code>. Phrased as recursion, we are transforming <code class="docutils literal notranslate"><span class="pre">let</span> <span class="pre">loop</span> <span class="pre">x</span> <span class="pre">|</span> <span class="pre">x</span> <span class="pre">&gt;=</span> <span class="pre">100</span> <span class="pre">=</span> <span class="pre">{};</span> <span class="pre">loop</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">{</span> <span class="pre">delete</span> <span class="pre">x;</span> <span class="pre">loop</span> <span class="pre">(x</span> <span class="pre">+</span> <span class="pre">1)</span> <span class="pre">}</span> <span class="pre">in</span> <span class="pre">loop</span> <span class="pre">0</span></code> to <code class="docutils literal notranslate"><span class="pre">let</span> <span class="pre">loop2</span> <span class="pre">x</span> <span class="pre">|</span> <span class="pre">x</span> <span class="pre">&gt;=</span> <span class="pre">100</span> <span class="pre">=</span> <span class="pre">{};</span> <span class="pre">loop2</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">{</span> <span class="pre">delete</span> <span class="pre">x;</span> <span class="pre">delete</span> <span class="pre">(x+1);</span> <span class="pre">loop</span> <span class="pre">(x</span> <span class="pre">+</span> <span class="pre">2)</span> <span class="pre">}</span> <span class="pre">in</span> <span class="pre">loop2</span> <span class="pre">0</span></code>. This is clearly just inlining the definition of <code class="docutils literal notranslate"><span class="pre">loop</span></code> inside the body of <code class="docutils literal notranslate"><span class="pre">loop</span></code> and then performing some simplifying reductions.</p></li>
</ul>
<p>Strong reduction can reduce inside lambdas and in any order of evaluation. It needs a careful definition of the interpreter’s evaluation semantics to avoid changing behavior. Strong reduction can be extended to supercompilation / partial evaluation, so that a state graph is constructed based on global information flow. There are several issues with reduction:</p>
<ul class="simple">
<li><p>duplication - reduction can duplicate expressions or contexts. Optimal sharing graphs avoid this duplication.</p></li>
<li><p>name capture - the no-shadowing strategy: maintain the set of in-scope variables, and rename any bound variable for which there is an enclosing binding. Main advantage is idempotency. Another strategy is a graph representation, no names in the first place.</p></li>
<li><p>termination - Cut elimination on finite typed terms is terminating, but other forms of reduction such as TRS reduction are not, so in general reduction is Turing-complete. Reduction consumes compile time and may speed up runtime by avoiding work or slow it down by bloating code. It’s not useful on on cold expressions. Bounding the number of reduction steps to normal form, via an ordering metric, might give a good estimate of reduction cost. Bounds like a maximum term depth and number of reduction steps avoid bloating, but are somewhat arbitrary and have to be stored in the IR to be idempotent. GHC uses loop-breakers for definition cycles, but again is somewhat arbitrary. It’s possible to prove non-termination or divergence of expansion, then it’s clear that no further work is useful. Another technique is to record the set of all observed states in an E-graph, then loops are obvious.</p></li>
</ul>
<p>Vectorization is an instruction selection task, but means that the interaction between instruction selection and reduction is non-trivial.</p>
<p>Peephole is an instruction selection task as well, when it does not correspond to reduction.</p>
<p>Common subexpression elimination is intimately related to graph reduction. Per <span id="id3">[]</span>, graph reduction can be characterized as giving each term in the unshared IR a label, and using an implementation such that all terms with the same label are represented as a single object (node) and reduced as a unit. Common subexpression “elimination” is then identifying identical expressions in the IR and giving them the same label in the initial labelling. The specific technique to identify duplicate expressions is “hash-consing”. Hash-consing can be applied incrementally, so that CSE can be applied continuosly as other transformations are applied. One issue is merging alpha-equivalent expressions, <span id="id4">[]</span>, which can be dealt with by encoding variable backedges as paths through a spanning tree. <span id="id5">[<a class="reference internal" href="../zzreferences.html#id109" title="Laurent Mauborgne. Representation of Sets of Trees for Abstract Interpretation. PhD thesis, Ecole Polytechnique, November 1999. URL: http://software.imdea.org/~mauborgn/publi/t.pdf.">Mau99</a>]</span> gives an algorithm identifying sharable components in cyclic graphs, useful for recursive structures.</p>
<p>As optimal reduction is also a term labelling, there should be an “optimal hash-consing” technique that identifies the Levy-labelling of terms with maximal sharing. The reduction <code class="docutils literal notranslate"><span class="pre">(\x.</span> <span class="pre">E[x])</span> <span class="pre">e</span> <span class="pre">--&gt;</span> <span class="pre">E[e]</span></code> shows that it will share all identical expressions, just as CSE with graph reduction. But it will also share an expression and its reduction, hence computing the labelling is at least of complexity <span class="math notranslate nohighlight">\(\Sigma^0_1\)</span> - but if we restrict to family reductions, e.g. by pre-reducing to normal form, then this is not an issue. And it is fine if the analysis is conservative and does not necessarily identify maximal sharing, just some sharing. But it should at least merging obvious shared contexts, like the function call context <code class="docutils literal notranslate"><span class="pre">g</span> <span class="pre">(h</span> <span class="pre">[])</span></code> in <code class="docutils literal notranslate"><span class="pre">g</span> <span class="pre">(h</span> <span class="pre">x)</span></code> and <code class="docutils literal notranslate"><span class="pre">g</span> <span class="pre">(h</span> <span class="pre">y)</span></code>. Ideally, this labelling should be the result of some actual initial expression and reduction history. To show that a maximal labelling exists, we need a join property of the form “for a term+history a, and another term+history b, there is a term+history c with all equivalences from a and also those from b”. Then, because the set of possible labelings is finite (or in the infinite case appealing to the term depth being a well-ordering hence infinite joins existing), the greatest element must exist as the join of all labellings. But we would also like a more efficient way to compute the labelling than brute force. Noting that the labelled beta-reduction operation only concatenates labels, we can safely replace a set of labels where no label is a prefix of another with a set of fresh distinct labels, preserving some sharing.</p>
<p>“Dead code elimination” is an umbrella term per ChatGPT. In GHC it refers to eliminating unused bindings. Wikipedia also lists conditional branch elimination and unreachable code elimination, which require a more involved reachability analysis.</p>
<p>Last is code motion.</p>
<blockquote>
<div><ul class="simple">
<li><p>induction variable analysis to replace multiplication by a loop index with addition</p></li>
<li><p>loop reversal - changing condition to zero comparison</p></li>
<li><p>loop unswitching - moving conditional outside loop</p></li>
<li><p>hoisting invariants, partial/total redundancy elimination</p></li>
<li><p>parallelization - multi-threaded or vectorized code</p></li>
</ul>
</div></blockquote>
<p>, loop-invariant code motion (hoisting)</p>
<ul class="simple">
<li><p>storing arrays on the heap in the most efficient of a few straightforward ways</p></li>
</ul>
<p>Because of unsharing fans it can share parents regardless of their other children; this doesn’t increase the graph size and may decrease code size/computation.</p>
<ul class="simple">
<li><p>Purely functional: Fixes evaluation order only for stateful operations, passes states explicitly. It is difficult to reason about imperative state mutation efficiently.</p></li>
<li><p>CPS: At the lowest level, an operation is “save all processor state to memory and jump”.</p></li>
<li><p>Like Thorin: SSA (explicit non-local control flow)</p></li>
<li><p>Like Sea of nodes: Cliff says it’s fast</p></li>
<li><p>Like GNU lightning: IDK, need some basic starting point for design and features of assembly opcodes</p></li>
</ul>
<p>Expanding machine code instructions into unpack, mathematical operations, round/repack means that there is a lot of overhead in code generation recognizing patterns of operations as instructions. On the other hand it allows writing a fewer number of more generic and powerful optimizations, instead of many processor-specific instruction patterns. So this choice favors ahead-of-time compilation at the expense of interpretation and JITing.</p>
</section>
<section id="sequent-core">
<h2>Sequent Core<a class="headerlink" href="#sequent-core" title="Permalink to this heading"></a></h2>
<p>CPS does expose control flow as continuation values, but it has problems. First, per <span id="id6">[<a class="reference internal" href="../zzreferences.html#id48" title="Paul Downen, Luke Maurer, Zena M. Ariola, and Simon Peyton Jones. Sequent calculus as a compiler intermediate language. In Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming, ICFP 2016, 74–88. Nara, Japan, September 2016. Association for Computing Machinery. URL: https://www.microsoft.com/en-us/research/publication/sequent-calculus-as-a-compiler-intermediate-language/ (visited on 2020-06-14), doi:10.1145/2951913.2951931.">DMAPJ16</a>]</span>, there is not one CPS transform, but rather a family, each CPS transform fixing an evaluation order. One must choose among call-by-value, call-by-name, or call-by-need. As a benefit, the evaluation order of the translation target doesn’t matter, and strong beta-eta reduction of the CPS’d term is sound. In fact, per <span id="id7">[<a class="reference internal" href="../zzreferences.html#id122" title="Chris Okasaki, Peter Lee, and David Tarditi. Call-by-need and continuation-passing style. LISP and Symbolic Computation, 7(1):57–81, January 1994. URL: https://www.researchgate.net/profile/Peter-Lee-88/publication/220606923_Call-by-Need_and_Continuation-Passing_Style/links/55633a2108ae8c0cab3509ba/Call-by-Need-and-Continuation-Passing-Style.pdf (visited on 2023-05-02), doi:10.1007/BF01019945.">OLT94</a>]</span>, all CPS translations are based on CBV, and call-by-name/call-by-need CPS translations can be decomposed as a conversion to CBV pass followed by a CBV CPS translation. IOdeally, the compiler should be able to freely choose the evaluation order, to trade-off the locality of innermost vs. the hypernormalization of outermost. Being unable to safely perform out-of-order reductions is a deal-breaker.</p>
<p>The CBV CPS encoding is quite annoying, e.g. <span id="id8">[<a class="reference internal" href="../zzreferences.html#id48" title="Paul Downen, Luke Maurer, Zena M. Ariola, and Simon Peyton Jones. Sequent calculus as a compiler intermediate language. In Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming, ICFP 2016, 74–88. Nara, Japan, September 2016. Association for Computing Machinery. URL: https://www.microsoft.com/en-us/research/publication/sequent-calculus-as-a-compiler-intermediate-language/ (visited on 2020-06-14), doi:10.1145/2951913.2951931.">DMAPJ16</a>]</span> it inverts nested function calls <code class="docutils literal notranslate"><span class="pre">map</span> <span class="pre">f</span> <span class="pre">(map</span> <span class="pre">g</span> <span class="pre">xs)</span></code> as <code class="docutils literal notranslate"><span class="pre">λk.map</span> <span class="pre">g</span> <span class="pre">(λh.h</span> <span class="pre">xs</span> <span class="pre">(λys.map</span> <span class="pre">f</span> <span class="pre">(λh'.h'</span> <span class="pre">ys</span> <span class="pre">k)))</span></code>. Per <span id="id9">[]</span> this makes CSE harder, e.g. <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">(g</span> <span class="pre">x)</span> <span class="pre">(g</span> <span class="pre">x)</span></code> vs <code class="docutils literal notranslate"><span class="pre">g</span> <span class="pre">(\xv.</span> <span class="pre">g</span> <span class="pre">(\yv.</span> <span class="pre">f</span> <span class="pre">k</span> <span class="pre">xv</span> <span class="pre">yv)</span> <span class="pre">x)</span> <span class="pre">x</span></code>. Also rewrite rules are harder to apply. Even CBV has an encoding - <span id="id10">[]</span> point out that “realistic” CBV CPS compilers mark source function calls as using special continuation closures to allow efficient calls. The call-by-need transform is worse - <span id="id11">[<a class="reference internal" href="../zzreferences.html#id122" title="Chris Okasaki, Peter Lee, and David Tarditi. Call-by-need and continuation-passing style. LISP and Symbolic Computation, 7(1):57–81, January 1994. URL: https://www.researchgate.net/profile/Peter-Lee-88/publication/220606923_Call-by-Need_and_Continuation-Passing_Style/links/55633a2108ae8c0cab3509ba/Call-by-Need-and-Continuation-Passing-Style.pdf (visited on 2023-05-02), doi:10.1007/BF01019945.">OLT94</a>]</span> describes how the thunk graph itself must be represented in the CPS term. It does have the benefit that the term graph is built incrementally, by gluing together subgraphs generated on demand by reduction, but the graph is still obfuscated as imperative code. <span id="id12">[]</span> states assigning names to continuations is really a benefit, but doesn’t discuss the other drawbacks of the encoding.</p>
<p><span id="id13">[]</span> demonstrated that CBV CPS was reversible, and proved that beta-eta-reduction in CPS corresponded to the A-reductions plus call-by-value reduction on the original term. Hence, per <span id="id14">[]</span>, many compilers adopted reducing the expression to A normal form between other transformations as a replacement for CPS. However, per <span id="id15">[]</span>, ANF is not closed under beta-reduction - inlining can create nested lets, which then have to be “renormalized”, floated out or rearranged via “commuting conversions”. Similarly, the A-reduction <code class="docutils literal notranslate"><span class="pre">E</span> <span class="pre">(if</span> <span class="pre">x</span> <span class="pre">then</span> <span class="pre">a</span> <span class="pre">else</span> <span class="pre">b)</span> <span class="pre">=</span> <span class="pre">if</span> <span class="pre">x</span> <span class="pre">then</span> <span class="pre">E</span> <span class="pre">a</span> <span class="pre">else</span> <span class="pre">E</span> <span class="pre">b</span></code> duplicates the evaluation context, and as such is commonly left out. The workaround is to introduce a “join point”, the <code class="docutils literal notranslate"><span class="pre">e</span></code> in <code class="docutils literal notranslate"><span class="pre">let</span> <span class="pre">e</span> <span class="pre">z</span> <span class="pre">=</span> <span class="pre">...</span> <span class="pre">in</span> <span class="pre">if</span> <span class="pre">x</span> <span class="pre">then</span> <span class="pre">e</span> <span class="pre">a</span> <span class="pre">else</span> <span class="pre">e</span> <span class="pre">b</span></code>. But join points are essentially continuations, second-class in that they are represented by function bindings. Even if specifically marked, they are fragile, in that per <span id="id16">[]</span> the case-of-case transformation must handle join points specially, and similarly other transformations must preserve join points (e.g. not inlining the join point. Furthermore, they are not really functions, requiring a special calling convention to compile efficiently. As Kennedy says, “Better to start off with a language that makes continuations explicit.”</p>
<p>So both CPS and ANF suck. Fortunately, <span id="id17">[<a class="reference internal" href="../zzreferences.html#id48" title="Paul Downen, Luke Maurer, Zena M. Ariola, and Simon Peyton Jones. Sequent calculus as a compiler intermediate language. In Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming, ICFP 2016, 74–88. Nara, Japan, September 2016. Association for Computing Machinery. URL: https://www.microsoft.com/en-us/research/publication/sequent-calculus-as-a-compiler-intermediate-language/ (visited on 2020-06-14), doi:10.1145/2951913.2951931.">DMAPJ16</a>]</span> presents Sequent Core, which retains the advantages of first-class continuations while avoiding the drawbacks. Sequent Core does not force choosing an evaluation order. A nested function application is munged a little, but the order is not inverted and CSE still works. <code class="docutils literal notranslate"><span class="pre">Cut</span></code> glues together graph pieces, but is itself part of the graph, hence does not need to encode its sub-graphs. Functions reduce to join points and other types of sequent, rather than the reverse. Reduction is uniformly cut-elimination, and does not require renormalization.</p>
<p>SSA represents code as procedures containing imperative blocks, and can’t express higher-order features. But, per <span id="id18">[]</span>, SSA code blocks map directly to mutually recursive tail-called functions, with the procedure as a distinguished function. Indeed, the Swift Intermediate Language adopted block arguments instead of φ-nodes. SSA’s basic blocks identify “small” functions that can be compiled easily, but this pass can be replicated in any IR. The other aspect of SSA, single static variable assignment, is reflected in a pass that remove mutable variables by replacing them with additional input and output arguments.</p>
<p>Thorin [23] is a graph-based representation aiming to support both
imperative and functional code by combining a flat structure for ease
of code transformation and first-class closures for implementing
higher-order languages. However, Thorin is still intended for use
in strict languages with pervasive side effects; it remains to be
seen whether such a representation could be adapted for high-level
optimizations in a non-strict regime such as Haskell.</p>
</section>
<section id="operations">
<h2>Operations<a class="headerlink" href="#operations" title="Permalink to this heading"></a></h2>
<p>At the top level, an IR is a list of operation instances. An operation is identified by a name (string), an optional JSON-ish dictionary of “inherent” operation attributes, and an optional source location. Operation instances also have an optional instance-specific “discardable” attribute dictionary, used for storing type analysis and similar semantic analysis. An instance produces (return) a list zero or more result values. They receive (take) a list of zero or more operand values. An operation instance also has zero or more successor blocks, and zero or more enclosed regions, enabling terminator instructions and hierarchical structures to be represented.</p>
</section>
<section id="control-flow">
<h2>Control flow<a class="headerlink" href="#control-flow" title="Permalink to this heading"></a></h2>
<p>The ADD instruction is not so simple</p>
<p>Control flow graph</p>
</section>
<section id="blocks">
<h2>Blocks<a class="headerlink" href="#blocks" title="Permalink to this heading"></a></h2>
<p>A basic block (BB) is a sequence of instructions that is entered only from the top, and that contains no terminator instructions except for a single one at the end. The last instruction in a BB must be a terminator instruction, so execution cannot fall through the end of the BB but instead jumps to a new BB.</p>
<p>Terminator instructions are unconditional branches.</p>
<p>Per cranelift:</p>
<dl class="simple">
<dt>EBB parameter</dt><dd><p>A formal parameter for an EBB is an SSA value that dominates everything
in the EBB. For each parameter declared by an EBB, a corresponding
argument value must be passed when branching to the EBB. The function’s
entry EBB has parameters that correspond to the function’s parameters.</p>
</dd>
<dt>EBB argument</dt><dd><p>Similar to function arguments, EBB arguments must be provided when
branching to an EBB that declares formal parameters. When execution
begins at the top of an EBB, the formal parameters have the values of
the arguments passed in the branch.</p>
</dd>
</dl>
<p>A basic block is a mixture of jump and non-jump instructions that is complete, in the sense that any execution of the program will take one of the jumps. Any arbitrary sequence of instructions can be turned into a basic block by adding an unconditional jump at the end.</p>
<p>Although phi nodes were an interesting idea all the <a class="reference external" href="https://mlir.llvm.org/docs/Rationale/Rationale/#block-arguments-vs-phi-nodes">cool kids</a> are now using block arguments. Blocks arguments fit better into various analysis passes.</p>
</section>
<section id="id19">
<h2>Blocks<a class="headerlink" href="#id19" title="Permalink to this heading"></a></h2>
<p>From a user perspective there are two types of jumpable addresses:</p>
<p>memory - effective address computation
SIB addressing form, where the index register is not used in address calculation, Scale is ignored. Only the base and displacement are used in effective address calculation.
VSIB memory addressing</p>
<p>Memory and the program counter are virtualized as well, using labels. A label refers to a memory location with a specific block of code loaded. The blocks are not ordered, so unconditional jumps must be inserted between blocks if necessary. The block order can be determined using profiling, removing the unconditional jump that is taken most often.</p>
<p>Memory references should be virtualized as well, so we also have memory labels. The alignment and format of the memory address should be specified.</p>
<p>Instructions and blocks are marked by the virtual registers they consume and use (input / output registers). The call and jump instructions are special in that a mapping may be given between the virtual registers and physical registers. Instruction constraints:
* Output: the register must not contain a value used after the block
* Output early clobber: output and the register must not be used for any inputs of the block
* Input: the register is read but not written to. Multiple inputs may all be assigned to the same register, if they all contain the same value.
* Tied input: register that is read and written
* Tied input early clobber: register that is read and written and does not share a register with any other input
* alignstack, sideeffect</p>
<p>There are also constraints from the ABI calling convention: <a class="reference external" href="https://gitlab.com/x86-psABIs/x86-64-ABI">https://gitlab.com/x86-psABIs/x86-64-ABI</a></p>
</section>
<section id="values">
<h2>Values<a class="headerlink" href="#values" title="Permalink to this heading"></a></h2>
<p>Since all values are representable in memory, we could use bytes in the IR for values. But this would lose the type information. So instead we must support all the value types listed in <span class="xref std std-ref">Values</span>.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Fastest.html" class="btn btn-neutral float-left" title="As fast as C" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Intrinsics.html" class="btn btn-neutral float-right" title="Intrinsics" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2022 Mathnerd314.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>