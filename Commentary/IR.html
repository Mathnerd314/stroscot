<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Intermediate representation &mdash; Stroscot  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/hexagon_favicon.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=7f41d439"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Learning" href="Learning.html" />
    <link rel="prev" title="Functional logic" href="FunctionalLogic.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html">
            
              <img src="../_static/hexagon_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/index.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../HowTo/index.html">How to</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Reference/index.html">Language Reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Commentary</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Aspects.html">Aspects</a></li>
<li class="toctree-l2"><a class="reference internal" href="Assembly.html">Assembly</a></li>
<li class="toctree-l2"><a class="reference internal" href="BuildSystem.html">Build system</a></li>
<li class="toctree-l2"><a class="reference internal" href="Checklist.html">Checklist</a></li>
<li class="toctree-l2"><a class="reference internal" href="Code-Generation.html">Code generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Compiler.html">Compiler design</a></li>
<li class="toctree-l2"><a class="reference internal" href="Compiler-Library.html">Compiler library</a></li>
<li class="toctree-l2"><a class="reference internal" href="CompilerOutput.html">Compiler output</a></li>
<li class="toctree-l2"><a class="reference internal" href="Concurrency.html">Concurrency</a></li>
<li class="toctree-l2"><a class="reference internal" href="CoreSyntax.html">Core syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="Dispatch.html">Dispatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="Errors.html">Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="Evaluation-Strategy.html">Evaluation strategy</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exceptions.html">Exceptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="Fastest.html">As fast as C</a></li>
<li class="toctree-l2"><a class="reference internal" href="FunctionalLogic.html">Functional logic</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Intermediate representation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#goals">Goals</a></li>
<li class="toctree-l3"><a class="reference internal" href="#optimizations">Optimizations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#reduction">Reduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#instruction-selection">Instruction selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cse">CSE</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dce">DCE</a></li>
<li class="toctree-l4"><a class="reference internal" href="#code-motion">Code motion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#more-on-ir">More on IR</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sequent-core">Sequent Core</a></li>
<li class="toctree-l3"><a class="reference internal" href="#operations">Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#control-flow">Control flow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#blocks">Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id19">Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#values">Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Learning.html">Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Logic.html">Logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="LogicProgramming.html">Logic programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="Macros.html">Macros</a></li>
<li class="toctree-l2"><a class="reference internal" href="Memory-Management.html">Memory management</a></li>
<li class="toctree-l2"><a class="reference internal" href="Meta.html">Meta</a></li>
<li class="toctree-l2"><a class="reference internal" href="Modules.html">Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="Objects.html">Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="OpPrims.html">Operational primitives</a></li>
<li class="toctree-l2"><a class="reference internal" href="PackageManager.html">Package manager</a></li>
<li class="toctree-l2"><a class="reference internal" href="Parsing.html">Parsing</a></li>
<li class="toctree-l2"><a class="reference internal" href="Posets.html">Posets</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html">Profiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="Programs.html">Exemplary programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction.html">Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction-Example.html">Reduction example</a></li>
<li class="toctree-l2"><a class="reference internal" href="Resource-Management.html">Resource management</a></li>
<li class="toctree-l2"><a class="reference internal" href="Security.html">Security</a></li>
<li class="toctree-l2"><a class="reference internal" href="Sets.html">Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="Standard-Library.html">Standard library</a></li>
<li class="toctree-l2"><a class="reference internal" href="State.html">Stateful programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="Symbolic.html">Symbolic computing</a></li>
<li class="toctree-l2"><a class="reference internal" href="Syntax.html">Syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="TermRewriting.html">Term rewriting</a></li>
<li class="toctree-l2"><a class="reference internal" href="Time.html">Time API</a></li>
<li class="toctree-l2"><a class="reference internal" href="Tools.html">Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="Types.html">Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="Units.html">Units</a></li>
<li class="toctree-l2"><a class="reference internal" href="Values.html">Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="Verification.html">Verification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../zzreferences.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Stroscot</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Commentary</a></li>
      <li class="breadcrumb-item active">Intermediate representation</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/Mathnerd314/stroscot/edit/master/docs/Commentary/IR.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="intermediate-representation">
<h1>Intermediate representation<a class="headerlink" href="#intermediate-representation" title="Link to this heading"></a></h1>
<p>The intermediate representation (IR) is the main workhorse of Stroscot’s execution engine. In most cases, source code is loaded once and transformed into IR, and never transformed back. IR allows many things that are not possible or efficient using a source code representation, as it stores more information and avoids irrelevant syntactic details.</p>
<section id="goals">
<h2>Goals<a class="headerlink" href="#goals" title="Link to this heading"></a></h2>
<p>An IR represents the initial and final states of a transformation phase in the compilation pipeline. Considering the entire compiler as a transformation, we see that the source language should be valid IR, as well as machine code. All the source constructs of the source language should be expressible 1-1 and print out exactly, and similarly there should be IR constructs to output any sequence of bytes into the resulting executable. Of course the fewer constructs the better, but considering the wide range of variation in hardware, some amount of redundancy is fine.</p>
<p>But compilation is insufficient, we would also like to use the IR for the interpreter. Thus every IR node should have an execution semantics. This avoids most instances of vagueness or edge cases in the specification. It also ensures that expanding high level abstractions into lots of small low-level instructions is only necessary for compilation, whereas the interpreter can use fewer, more expensive high-level instructions to get lower instruction dispatch overhead. In particular, type checks, method dispatch, and mathematical values like unbounded integers and computable reals can all benefit from having specialized operations.</p>
<p>In the case of interpreting machine code, we get a “literal machine” like Zed Shaw’s EaRing. Unlike traditional “virtual” machines where interpreting even the lowest-level IR instruction may still take several machine code instructions, the interpreter executes each IR machine instruction as a single machine code instruction, allowing pretty efficient “pre-compiled methods”. The interpreter or “literal machine” might alternatively be termed an “assembler” because it takes an “assembly language”, but LLVM and Java started using the term VM a long time ago, so “machine” is more fun. Also, traditionally assemblers are compilers rather than interpreters - Stroscot allows dynamic loading of new code, running code at a REPL, and introspection such as listing constants and functions from imports. It makes learning assembly pretty fun.</p>
<p>Like MLIR, the IR comes in three different forms, all describing the same semantic content:</p>
<ul class="simple">
<li><p>an in-memory form. This should have a low memory footprint, although not compressed. It should be low overhead to generate from AST, analyze, and interpret directly. Transformations should be localized, meaning they only affect a small portion of the IR and only need a few memory accesses rather than a full traversal of the graph.</p></li>
<li><p>a textual form. This should have all IR information so as to be suitable for debugging (lossless). It should be easily parsable so that scripting tasks do not require building the full in-memory representation (easy to read for machines). Within those constraints, it should be as human-readable as possible (easy to read for humans), and easily diff’able (avoiding redundantly repeating information). This enables a workflow where IR can be read from a file, sent through a few passes, dumped to another file, and the passes can be messed with until the output is correct.</p></li>
<li><p>a serialized “bytecode” form. The main use is build system caching. It should be compact so that disk/network usage is minimized. Gzipping the textual format seems the obvious possibility, but maybe a true binary format will be more efficient. It is also important to be able to serialize snippets of IR in isolation.</p></li>
</ul>
<p>Also like MLIR, the IR is a <a class="reference external" href="https://en.wikipedia.org/wiki/Wide-spectrum_language">wide-spectrum language</a>, coming in various dialects, roughly ordered linearly on a spectrum of abstraction level from source-like to assembly-like. The compilation process gradually down-translates and eliminates dialects, but any set of dialects may be in use for a particular phase. The use of a common IR representation across dialects allows sharing infrastructure for certain transformations, such as constant folding, dead code elimination, and graph rewriting. It also avoids unnecessarily translating data by allowing it to be pre-specified in a usable format. The transformations are designed to be extensible, passing through unknown operations uninterpreted. Codegen can treat unknown ops as clobbering all registers, although of course producing machine code requires knowing how to emit the operation. The IR also supports metadata, so that analysis passes can add necessary annotations.</p>
<p>Unlike Java bytecode, the IR is target-specific. Specific instances of the IR will assume processor features and other configuration, such as microarchitecture, calling conventions, alignment requirements, etc. Practically, code is “portable” only because of the use of conditional compilation for specific platforms that papers over the differences. Java files, networking, GUI, threading, and native methods are targer-specific, LLVM IR is target-specific, even WASM has different incompatible system interfaces. Maintaining these conditionals as opaque operations at the IR level would prevent many useful optimizations, although of course the opaque format does allow certain optimization rules to only be written once.</p>
<p>For debugging and diagnostic purposes, it is important to define a reverse transformation back from IR to AST, so that error messages can display the relevant code. For example, inlining may expand a macro, and the error in the macro may require showing bits of the IR for context. The AST generated from the IR does not have to be the original AST, it should instead accurately depict the IR. But the IR should capture source locations and other information necessary for good error messages.</p>
</section>
<section id="optimizations">
<h2>Optimizations<a class="headerlink" href="#optimizations" title="Link to this heading"></a></h2>
<p>As mentioned in the goals section, the in-memory form of IR should be suitable for all of the various transformations and optimizations. An ideal IR makes these optimizations very cheap - not free (otherwise the initial IR wouldn’t be a faithful representation of the source) but not more than a few operations either. In particular having to do a scan of the entire IR for a transformation is a no-no.</p>
<ul class="simple">
<li><p>removal of unused parameters</p></li>
<li><p>replacement of parameters passed by reference by parameters passed by value.</p></li>
<li><p>replace standard functions with faster alternatives when possible</p></li>
<li><p>inlining</p></li>
<li><p>deduplication of constants, functions, code sequences (tail merging / cross jumping)</p></li>
<li><p>common subexpression elimination (CSE)</p></li>
<li><p>dead code/store eliminate (DCE/DSE)</p></li>
<li><p>conditional dead code elimination (DCE) for calls to built-in functions that may set errno but are otherwise free of side effects</p></li>
<li><p>global constant and copy propagation</p></li>
<li><p>constant propagation - which values/bits of values passed to functions are constants, function cloning</p></li>
<li><p>value range propagation - like constant propagation but value ranges</p></li>
<li><p>sparse conditional constant propagation (CCP), including bit-level</p></li>
<li><p>elimination of always true/false conditions</p></li>
<li><p>move loads/stores outside loops</p></li>
<li><p>loop unrolling/peeling</p></li>
<li><p>loop exit test</p></li>
<li><p>cross-jumping transformation</p></li>
<li><p>constant folding</p></li>
<li><p>specializing call dispatch (possible targets, likely targets, test/branch)</p></li>
<li><p>Code hoisting - evaluate guaranteed-evaluated expressions as early as possible</p></li>
<li><p>copy propagation - eliminate unnecessary copy operations</p></li>
<li><p>Discover which variables escape</p></li>
<li><p>partial/full redundancy elimination (PRE/FRE)</p></li>
<li><p>modified/referenced memory analysis, points-to analysis, aliasing</p></li>
<li><p>strips sign operations if the sign of a value never matters</p></li>
<li><p>convert initialization in switch to initialization from a scalar array</p></li>
<li><p>termination checking</p></li>
<li><p>loop nest optimizer based on the Pluto optimization algorithms. It calculates a loop structure optimized for data-locality and parallelism.</p></li>
<li><p>graphite - loop distribution, loop interchange, unroll, jam, peel, split, unswitch, parallelize, copy variables, inline to use first iteration values, predictive commoning, prefetch</p></li>
<li><p>final value replacement - loop to calculation using initial value and number of loop iterations</p></li>
<li><p>explode structures to scalars in registers</p></li>
<li><p>vectorization - loop vectorization, basic block vectorization, cost free (for debugging), likely faster, or code size</p></li>
<li><p>reorder blocks, duplicate blocks, partition into hot/cold to improve paging and cache locality</p></li>
<li><p>specialization of division operations using knowledge of the denominator</p></li>
</ul>
<p>Magic numbers:</p>
<ul class="simple">
<li><p>search space sizes - Increasing values mean more aggressive optimization, making the compilation time increase, but with diminishing improvement in runtime execution time. Generally a formula producing a boolean “try optimization” answer or an integer “maximum number of possibilities to consider”.</p></li>
<li><p>memory limit - If more memory than specified is required, the optimization is not done.</p></li>
<li><p>analysis skipping - ignore objects larger than some size</p></li>
<li><p>ratios - if inlining grows code by more than this, cancel inlining. tends to be overly conservative on small functions which can increase by 300%.</p></li>
</ul>
<blockquote>
<div><p>A <a class="reference external" href="http://venge.net/graydon/talks/CompilerTalk-2019.pdf">talk</a> by Graydon Hoare on compilers mentions the paper <span id="id1">[<a class="reference internal" href="../zzreferences.html#id6" title="Frances E Allen and John Cocke. A catalogue of optimizing transformations. IBM Research Center, pages 30, 1971. URL: https://www.clear.rice.edu/comp512/Lectures/Papers/1971-allen-catalog.pdf.">AC71</a>]</span>. He says we need 8 optimization passes to get 80% of GCC/LLVM performance: Inline, Unroll (&amp; Vectorize), CSE, DCE, Code Motion, Constant Fold, Peephole.</p>
</div></blockquote>
<section id="reduction">
<h3>Reduction<a class="headerlink" href="#reduction" title="Link to this heading"></a></h3>
<p>Reduction covers constant folding, inlining, and unrolling. Specifically:</p>
<ul class="simple">
<li><p>Constant folding reduces closed expressions, like <code class="docutils literal notranslate"><span class="pre">1+2</span></code> to <code class="docutils literal notranslate"><span class="pre">3</span></code>.</p></li>
<li><p>Inlining replaces a term with its expansion, like a rewrite step in term rewriting.  It differs from constant folding in that unevaluated expressions may be substituted, like <code class="docutils literal notranslate"><span class="pre">2*x</span></code> to <code class="docutils literal notranslate"><span class="pre">x+x</span></code>. Per <span id="id2">[<a class="reference internal" href="../zzreferences.html#id126" title="Simon Peyton Jones and Simon Marlow. Secrets of the Glasgow Haskell Compiler inliner. Journal of Functional Programming, 12(4):393–434, July 2002. URL: https://www.microsoft.com/en-us/research/wp-content/uploads/2002/07/inline.pdf (visited on 2020-07-01), doi:10.1017/S0956796802004331.">PJM02</a>]</span>, inlining subsumes copy propagation and jump elimination.</p></li>
<li><p>Loop-unrolling is typically phrased in an iterative setting, e.g. <code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">(x</span> <span class="pre">=</span> <span class="pre">0;</span> <span class="pre">x</span> <span class="pre">&lt;</span> <span class="pre">100;</span> <span class="pre">x++)</span> <span class="pre">delete(x)</span></code> to <code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">(x</span> <span class="pre">=</span> <span class="pre">0;</span> <span class="pre">x</span> <span class="pre">&lt;</span> <span class="pre">100;</span> <span class="pre">x</span> <span class="pre">+=</span> <span class="pre">2)</span> <span class="pre">{</span> <span class="pre">delete(x);</span> <span class="pre">delete(x+1);</span> <span class="pre">}</span></code>. Phrased as recursion, we are transforming <code class="docutils literal notranslate"><span class="pre">let</span> <span class="pre">loop</span> <span class="pre">x</span> <span class="pre">|</span> <span class="pre">x</span> <span class="pre">&gt;=</span> <span class="pre">100</span> <span class="pre">=</span> <span class="pre">{};</span> <span class="pre">loop</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">{</span> <span class="pre">delete</span> <span class="pre">x;</span> <span class="pre">loop</span> <span class="pre">(x</span> <span class="pre">+</span> <span class="pre">1)</span> <span class="pre">}</span> <span class="pre">in</span> <span class="pre">loop</span> <span class="pre">0</span></code> to <code class="docutils literal notranslate"><span class="pre">let</span> <span class="pre">loop2</span> <span class="pre">x</span> <span class="pre">|</span> <span class="pre">x</span> <span class="pre">&gt;=</span> <span class="pre">100</span> <span class="pre">=</span> <span class="pre">{};</span> <span class="pre">loop2</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">{</span> <span class="pre">delete</span> <span class="pre">x;</span> <span class="pre">delete</span> <span class="pre">(x+1);</span> <span class="pre">loop</span> <span class="pre">(x</span> <span class="pre">+</span> <span class="pre">2)</span> <span class="pre">}</span> <span class="pre">in</span> <span class="pre">loop2</span> <span class="pre">0</span></code>. This is clearly just inlining the definition of <code class="docutils literal notranslate"><span class="pre">loop</span></code> inside the body of <code class="docutils literal notranslate"><span class="pre">loop</span></code> and then performing some simplifying reductions.</p></li>
</ul>
<p>There are also user-specified rewrite rules, which make everything more complicated.</p>
<p>Strong reduction can reduce inside lambdas and in any order of evaluation. It needs a careful definition of the interpreter’s evaluation semantics to avoid changing behavior. Strong reduction can be extended to supercompilation / partial evaluation, so that a state graph is constructed based on global information flow. There are several issues with reduction:</p>
<ul class="simple">
<li><p>duplication - reduction can duplicate expressions or contexts. Optimal sharing graphs avoid this duplication.</p></li>
<li><p>name capture - the no-shadowing strategy: maintain the set of in-scope variables, and rename any bound variable for which there is an enclosing binding. Main advantage is idempotency. Another strategy is a graph representation, no names in the first place.</p></li>
<li><p>termination - Cut elimination on finite typed terms is terminating, but other forms of reduction such as TRS reduction are not, so in general reduction is Turing-complete. Reduction consumes compile time and may speed up runtime by avoiding work or slow it down by bloating code. It’s not useful on on cold expressions. Bounding the number of reduction steps to normal form, via an ordering metric, might give a good estimate of reduction cost. Bounds like a maximum term depth and number of reduction steps avoid bloating, but are somewhat arbitrary and have to be stored in the IR to be idempotent. GHC uses loop-breakers for definition cycles, but again is somewhat arbitrary. It’s possible to prove non-termination or divergence of expansion, then it’s clear that no further work is useful. Another technique is to record the set of all observed states in an E-graph, then loops are obvious.</p></li>
</ul>
</section>
<section id="instruction-selection">
<h3>Instruction selection<a class="headerlink" href="#instruction-selection" title="Link to this heading"></a></h3>
<p>Once the IR has been reduced as far as possible, it must be converted to machine code. Vectorization and peephole optimization are essentially instruction selection features. They do interact a bit with reduction though - some peephole optimizations can also be cast as reductions, and some reductions may make it harder to recognize opportunities for vectorization.</p>
</section>
<section id="cse">
<h3>CSE<a class="headerlink" href="#cse" title="Link to this heading"></a></h3>
<p>Common subexpression “elimination” is actually identifying identical expressions in the IR and giving them a shared representation in an IR graph. It is related to graph reduction, which per <span id="id3">[]</span>, can be characterized as giving each term in the unshared IR a label, and using an implementation such that all terms with the same label are represented as a single object (node) and reduced as a unit.  The specific technique to identify duplicate expressions is “hash-consing”. Hash-consing can be applied incrementally, so that CSE can be applied continuosly as other transformations are applied. One issue is merging alpha-equivalent expressions, <span id="id4">[]</span>, which can be dealt with by encoding variable backedges as paths through a spanning tree. <span id="id5">[<a class="reference internal" href="../zzreferences.html#id110" title="Laurent Mauborgne. Representation of Sets of Trees for Abstract Interpretation. PhD thesis, Ecole Polytechnique, November 1999. URL: http://software.imdea.org/~mauborgn/publi/t.pdf.">Mau99</a>]</span> gives an algorithm identifying sharable components in cyclic graphs, useful for recursive structures.</p>
<p>As optimal reduction is also a term labelling, there should be an “optimal hash-consing” technique that identifies the Levy-labelling of terms with maximal sharing. More formally, there are three ways to define the equivalence relation of optimal reduction. The first is Levy labelling - take an initial term with unique atomic labels for every subterm, perform reductions according to a special label-generation rule, then observe which labels are equivalent in the result. The second is extraction, which maps a redex and its history to its origin. The third is the zig-zig relation, the smallest equivalence relation containing the “copy of” relation, based purely on reduction history. All of these relations are equivalent on redexes. But to make the semantics as a reduction graph tractable, all of these are defined with respect to an initial lambda term. For compile-time usage though, we would like the maximal equivalence - a “hash consing” algorithm which takes an unlabelled term and produces the labelling with maximal sharing. In the zig-zag relation, we would like to equate all redexes that can be produced by copying from any initial term, not</p>
<p>The reduction <code class="docutils literal notranslate"><span class="pre">(\x.</span> <span class="pre">E[x])</span> <span class="pre">e</span> <span class="pre">--&gt;</span> <span class="pre">E[e]</span></code> shows that it will share all identical expressions, just as CSE with graph reduction. But it will also share an expression and its reduction, hence computing the labelling is at least of complexity <span class="math notranslate nohighlight">\(\Sigma^0_1\)</span>. Let’s avoid that by only considering terms pre-reduced to normal form. Are there any other equivalences besides normal CSE?</p>
<blockquote>
<div><p>Consider each case of lambda term:</p>
</div></blockquote>
<ul class="simple">
<li><p>Bound variable with bound variable: a bound variable may equate with all of its other occurrences. But since the term is reduced, it cannot unify with anything else - each unique variable must have a unique label in the initial history. For example, for <code class="docutils literal notranslate"><span class="pre">λy.y</span> <span class="pre">(λx.xx)</span></code>, the two bound appearances of <code class="docutils literal notranslate"><span class="pre">x</span></code> may be equated from an initial term <code class="docutils literal notranslate"><span class="pre">λx.(λz.zz)x</span></code>. But we know that <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> cannot be equated, and similarly in <code class="docutils literal notranslate"><span class="pre">λy.λy.x</span> <span class="pre">y</span></code>.</p></li>
<li><p>Lambda abstraction: A lambda abstraction cannot equate Suppose we have <code class="docutils literal notranslate"><span class="pre">λx.M</span></code> and <code class="docutils literal notranslate"><span class="pre">λy.N</span></code>.</p></li>
</ul>
<blockquote>
<div><p>To show that a maximal labelling exists, we need a join property of the form “for a term+history a, and another term+history b, there is a term+history c with all equivalences from a and also those from b”.</p>
</div></blockquote>
<p>I am not sure how to prove this but let’s look at <a class="reference external" href="https://cs.stackexchange.com/questions/99492/confluence-of-beta-expansion">some examples</a> of non-confluence.</p>
<p>First we have <code class="docutils literal notranslate"><span class="pre">(λx.bx(bc))c</span></code> and <code class="docutils literal notranslate"><span class="pre">(λx.xx)(bc)</span></code>. The first results in no sharing. The second results in <code class="docutils literal notranslate"><span class="pre">(b^1</span> <span class="pre">c^2)</span> <span class="pre">(b^1</span> <span class="pre">c^2)</span></code>. This seems to be the maximal sharing.</p>
<p>(Plotkin).
(λx.a(bx))(cd)
and a((λy.b(cy))d) (Van Oostrom).</p>
<blockquote>
<div><p>then this is not an issue. And it is fine if the analysis is conservative and does not necessarily identify maximal sharing, just some sharing. But it should at least merging obvious shared contexts, like the function call context <code class="docutils literal notranslate"><span class="pre">g</span> <span class="pre">(h</span> <span class="pre">[])</span></code> in <code class="docutils literal notranslate"><span class="pre">g</span> <span class="pre">(h</span> <span class="pre">x)</span></code> and <code class="docutils literal notranslate"><span class="pre">g</span> <span class="pre">(h</span> <span class="pre">y)</span></code>. Ideally, this labelling should be the result of some actual initial expression and reduction history.  Then, because the set of possible labelings is finite (or in the infinite case appealing to the term depth being a well-ordering hence infinite joins existing), the greatest element must exist as the join of all labellings. But we would also like a more efficient way to compute the labelling than brute force. Noting that the labelled beta-reduction operation only concatenates labels, we can safely replace a set of labels where no label is a prefix of another with a set of fresh distinct labels, preserving some sharing.</p>
</div></blockquote>
</section>
<section id="dce">
<h3>DCE<a class="headerlink" href="#dce" title="Link to this heading"></a></h3>
<p>“Dead code elimination” is an umbrella term per ChatGPT. In GHC it refers to eliminating unused bindings. Wikipedia also lists conditional branch elimination and unreachable code elimination, which require a more involved reachability analysis.</p>
</section>
<section id="code-motion">
<h3>Code motion<a class="headerlink" href="#code-motion" title="Link to this heading"></a></h3>
<blockquote>
<div><ul class="simple">
<li><p>induction variable analysis to replace multiplication by a loop index with addition</p></li>
<li><p>loop reversal - changing condition to zero comparison</p></li>
<li><p>loop unswitching - moving conditional outside loop</p></li>
<li><p>hoisting invariants</p></li>
<li><p>partial/total redundancy elimination</p></li>
<li><p>parallelization - multi-threaded or vectorized code</p></li>
</ul>
</div></blockquote>
<ul class="simple">
<li><p>storing arrays on the heap in the most efficient of a few straightforward ways</p></li>
</ul>
<p>Because of unsharing fans it can share parents regardless of their other children; this doesn’t increase the graph size and may decrease code size/computation.</p>
</section>
</section>
<section id="more-on-ir">
<h2>More on IR<a class="headerlink" href="#more-on-ir" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>Purely functional: Fixes evaluation order only for stateful operations, passes states explicitly. It is difficult to reason about imperative state mutation efficiently.</p></li>
<li><p>CPS: At the lowest level, an operation is “save all processor state to memory and jump”.</p></li>
<li><p>Like Thorin: SSA (explicit non-local control flow)</p></li>
<li><p>Like Sea of nodes: Cliff says it’s fast</p></li>
<li><p>Like GNU lightning: IDK, need some basic starting point for design and features of assembly opcodes</p></li>
</ul>
<p>Expanding machine code instructions into unpack, mathematical operations, round/repack means that there is a lot of overhead in code generation recognizing patterns of operations as instructions. On the other hand it allows writing a fewer number of more generic and powerful optimizations, instead of many processor-specific instruction patterns. So this choice favors ahead-of-time compilation at the expense of interpretation and JITing.</p>
</section>
<section id="sequent-core">
<h2>Sequent Core<a class="headerlink" href="#sequent-core" title="Link to this heading"></a></h2>
<p>CPS does expose control flow as continuation values, but it has problems. First, per <span id="id6">[<a class="reference internal" href="../zzreferences.html#id49" title="Paul Downen, Luke Maurer, Zena M. Ariola, and Simon Peyton Jones. Sequent calculus as a compiler intermediate language. In Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming, ICFP 2016, 74–88. Nara, Japan, September 2016. Association for Computing Machinery. URL: https://www.microsoft.com/en-us/research/publication/sequent-calculus-as-a-compiler-intermediate-language/ (visited on 2020-06-14), doi:10.1145/2951913.2951931.">DMAPJ16</a>]</span>, there is not one CPS transform, but rather a family, each CPS transform fixing an evaluation order. One must choose among call-by-value, call-by-name, or call-by-need. As a benefit, the evaluation order of the translation target doesn’t matter, and strong beta-eta reduction of the CPS’d term is sound. In fact, per <span id="id7">[<a class="reference internal" href="../zzreferences.html#id123" title="Chris Okasaki, Peter Lee, and David Tarditi. Call-by-need and continuation-passing style. LISP and Symbolic Computation, 7(1):57–81, January 1994. URL: https://www.researchgate.net/profile/Peter-Lee-88/publication/220606923_Call-by-Need_and_Continuation-Passing_Style/links/55633a2108ae8c0cab3509ba/Call-by-Need-and-Continuation-Passing-Style.pdf (visited on 2023-05-02), doi:10.1007/BF01019945.">OLT94</a>]</span>, all CPS translations are based on CBV, and call-by-name/call-by-need CPS translations can be decomposed as a conversion to CBV pass followed by a CBV CPS translation. IOdeally, the compiler should be able to freely choose the evaluation order, to trade-off the locality of innermost vs. the hypernormalization of outermost. Being unable to safely perform out-of-order reductions is a deal-breaker.</p>
<p>The CBV CPS encoding is quite annoying, e.g. <span id="id8">[<a class="reference internal" href="../zzreferences.html#id49" title="Paul Downen, Luke Maurer, Zena M. Ariola, and Simon Peyton Jones. Sequent calculus as a compiler intermediate language. In Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming, ICFP 2016, 74–88. Nara, Japan, September 2016. Association for Computing Machinery. URL: https://www.microsoft.com/en-us/research/publication/sequent-calculus-as-a-compiler-intermediate-language/ (visited on 2020-06-14), doi:10.1145/2951913.2951931.">DMAPJ16</a>]</span> it inverts nested function calls <code class="docutils literal notranslate"><span class="pre">map</span> <span class="pre">f</span> <span class="pre">(map</span> <span class="pre">g</span> <span class="pre">xs)</span></code> as <code class="docutils literal notranslate"><span class="pre">λk.map</span> <span class="pre">g</span> <span class="pre">(λh.h</span> <span class="pre">xs</span> <span class="pre">(λys.map</span> <span class="pre">f</span> <span class="pre">(λh'.h'</span> <span class="pre">ys</span> <span class="pre">k)))</span></code>. Per <span id="id9">[]</span> this makes CSE harder, e.g. <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">(g</span> <span class="pre">x)</span> <span class="pre">(g</span> <span class="pre">x)</span></code> vs <code class="docutils literal notranslate"><span class="pre">g</span> <span class="pre">(\xv.</span> <span class="pre">g</span> <span class="pre">(\yv.</span> <span class="pre">f</span> <span class="pre">k</span> <span class="pre">xv</span> <span class="pre">yv)</span> <span class="pre">x)</span> <span class="pre">x</span></code>. Also rewrite rules are harder to apply. Even CBV has an encoding - <span id="id10">[]</span> point out that “realistic” CBV CPS compilers mark source function calls as using special continuation closures to allow efficient calls. The call-by-need transform is worse - <span id="id11">[<a class="reference internal" href="../zzreferences.html#id123" title="Chris Okasaki, Peter Lee, and David Tarditi. Call-by-need and continuation-passing style. LISP and Symbolic Computation, 7(1):57–81, January 1994. URL: https://www.researchgate.net/profile/Peter-Lee-88/publication/220606923_Call-by-Need_and_Continuation-Passing_Style/links/55633a2108ae8c0cab3509ba/Call-by-Need-and-Continuation-Passing-Style.pdf (visited on 2023-05-02), doi:10.1007/BF01019945.">OLT94</a>]</span> describes how the thunk graph itself must be represented in the CPS term. It does have the benefit that the term graph is built incrementally, by gluing together subgraphs generated on demand by reduction, but the graph is still obfuscated as imperative code. <span id="id12">[]</span> states assigning names to continuations is really a benefit, but doesn’t discuss the other drawbacks of the encoding.</p>
<p><span id="id13">[]</span> demonstrated that CBV CPS was reversible, and proved that beta-eta-reduction in CPS corresponded to the A-reductions plus call-by-value reduction on the original term. Hence, per <span id="id14">[]</span>, many compilers adopted reducing the expression to A normal form between other transformations as a replacement for CPS. However, per <span id="id15">[]</span>, ANF is not closed under beta-reduction - inlining can create nested lets, which then have to be “renormalized”, floated out or rearranged via “commuting conversions”. Similarly, the A-reduction <code class="docutils literal notranslate"><span class="pre">E</span> <span class="pre">(if</span> <span class="pre">x</span> <span class="pre">then</span> <span class="pre">a</span> <span class="pre">else</span> <span class="pre">b)</span> <span class="pre">=</span> <span class="pre">if</span> <span class="pre">x</span> <span class="pre">then</span> <span class="pre">E</span> <span class="pre">a</span> <span class="pre">else</span> <span class="pre">E</span> <span class="pre">b</span></code> duplicates the evaluation context, and as such is commonly left out. The workaround is to introduce a “join point”, the <code class="docutils literal notranslate"><span class="pre">e</span></code> in <code class="docutils literal notranslate"><span class="pre">let</span> <span class="pre">e</span> <span class="pre">z</span> <span class="pre">=</span> <span class="pre">...</span> <span class="pre">in</span> <span class="pre">if</span> <span class="pre">x</span> <span class="pre">then</span> <span class="pre">e</span> <span class="pre">a</span> <span class="pre">else</span> <span class="pre">e</span> <span class="pre">b</span></code>. But join points are essentially continuations, second-class in that they are represented by function bindings. Even if specifically marked, they are fragile, in that per <span id="id16">[]</span> the case-of-case transformation must handle join points specially, and similarly other transformations must preserve join points (e.g. not inlining the join point). Furthermore, they are not really functions, requiring a special calling convention to compile efficiently. As Kennedy says, “Better to start off with a language that makes continuations explicit.”</p>
<p>So all of CPS, ANF, and joint points suck. Fortunately, <span id="id17">[<a class="reference internal" href="../zzreferences.html#id49" title="Paul Downen, Luke Maurer, Zena M. Ariola, and Simon Peyton Jones. Sequent calculus as a compiler intermediate language. In Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming, ICFP 2016, 74–88. Nara, Japan, September 2016. Association for Computing Machinery. URL: https://www.microsoft.com/en-us/research/publication/sequent-calculus-as-a-compiler-intermediate-language/ (visited on 2020-06-14), doi:10.1145/2951913.2951931.">DMAPJ16</a>]</span> presents Sequent Core, which retains the advantages of first-class continuations while avoiding the drawbacks. Sequent Core does not force choosing an evaluation order. A nested function application is munged a little, but the order is not inverted and CSE still works. <code class="docutils literal notranslate"><span class="pre">Cut</span></code> glues together graph pieces, but is itself part of the graph, hence does not need to encode its sub-graphs. Functions reduce to join points and other types of sequent, rather than the reverse. Reduction is uniformly cut-elimination, and does not require renormalization. Downen at al. implemented Sequent Core, but the implementation was complex. I think though that this complexity was mainly due to the need to interface with GHC and closely follow the design of GHC’s original System F-like Core. A novel implementation focusing on a “clean” sequent logic, and emphasizing duality and symmetries, like Stroscot’s, should be able to avoid this implementation complexity. I asked SPJ and he was like “go for it.”</p>
<p>SSA represents code as procedures containing imperative blocks, and can’t express higher-order features. But, per <span id="id18">[]</span>, SSA code blocks map directly to mutually recursive tail-called functions, with the procedure as a distinguished function. Indeed, the Swift Intermediate Language adopted block arguments instead of φ-nodes. SSA’s basic blocks identify “small” functions that can be compiled easily, but this pass can be replicated in any IR. The other aspect of SSA, single static variable assignment, is reflected in a pass that remove mutable variables by replacing them with additional input and output arguments.</p>
<p>Thorin [23] is a graph-based representation aiming to support both
imperative and functional code by combining a flat structure for ease
of code transformation and first-class closures for implementing
higher-order languages. However, Thorin is still intended for use
in strict languages with pervasive side effects; it remains to be
seen whether such a representation could be adapted for high-level
optimizations in a non-strict regime such as Haskell.</p>
</section>
<section id="operations">
<h2>Operations<a class="headerlink" href="#operations" title="Link to this heading"></a></h2>
<p>At the top level, an IR is a list of operation instances. An operation is identified by a name (string), an optional JSON-ish dictionary of “inherent” operation attributes, and an optional source location. Operation instances also have an optional instance-specific “discardable” attribute dictionary, used for storing type analysis and similar semantic analysis. An instance produces (return) a list zero or more result values. They receive (take) a list of zero or more operand values. An operation instance also has zero or more successor blocks, and zero or more enclosed regions, enabling terminator instructions and hierarchical structures to be represented.</p>
</section>
<section id="control-flow">
<h2>Control flow<a class="headerlink" href="#control-flow" title="Link to this heading"></a></h2>
<p>The ADD instruction is not so simple</p>
<p>Control flow graph</p>
</section>
<section id="blocks">
<h2>Blocks<a class="headerlink" href="#blocks" title="Link to this heading"></a></h2>
<p>A basic block (BB) is a sequence of instructions that is entered only from the top, and that contains no terminator instructions except for a single one at the end. The last instruction in a BB must be a terminator instruction, so execution cannot fall through the end of the BB but instead jumps to a new BB.</p>
<p>Terminator instructions are unconditional branches.</p>
<p>Per cranelift:</p>
<dl class="simple">
<dt>EBB parameter</dt><dd><p>A formal parameter for an EBB is an SSA value that dominates everything
in the EBB. For each parameter declared by an EBB, a corresponding
argument value must be passed when branching to the EBB. The function’s
entry EBB has parameters that correspond to the function’s parameters.</p>
</dd>
<dt>EBB argument</dt><dd><p>Similar to function arguments, EBB arguments must be provided when
branching to an EBB that declares formal parameters. When execution
begins at the top of an EBB, the formal parameters have the values of
the arguments passed in the branch.</p>
</dd>
</dl>
<p>A basic block is a mixture of jump and non-jump instructions that is complete, in the sense that any execution of the program will take one of the jumps. Any arbitrary sequence of instructions can be turned into a basic block by adding an unconditional jump at the end.</p>
<p>Although phi nodes were an interesting idea all the <a class="reference external" href="https://mlir.llvm.org/docs/Rationale/Rationale/#block-arguments-vs-phi-nodes">cool kids</a> are now using block arguments. Blocks arguments fit better into various analysis passes.</p>
</section>
<section id="id19">
<h2>Blocks<a class="headerlink" href="#id19" title="Link to this heading"></a></h2>
<p>From a user perspective there are two types of jumpable addresses:</p>
<p>memory - effective address computation
SIB addressing form, where the index register is not used in address calculation, Scale is ignored. Only the base and displacement are used in effective address calculation.
VSIB memory addressing</p>
<p>Memory and the program counter are virtualized as well, using labels. A label refers to a memory location with a specific block of code loaded. The blocks are not ordered, so unconditional jumps must be inserted between blocks if necessary. The block order can be determined using profiling, removing the unconditional jump that is taken most often.</p>
<p>Memory references should be virtualized as well, so we also have memory labels. The alignment and format of the memory address should be specified.</p>
<p>Instructions and blocks are marked by the virtual registers they consume and use (input / output registers). The call and jump instructions are special in that a mapping may be given between the virtual registers and physical registers. Instruction constraints:
* Output: the register must not contain a value used after the block
* Output early clobber: output and the register must not be used for any inputs of the block
* Input: the register is read but not written to. Multiple inputs may all be assigned to the same register, if they all contain the same value.
* Tied input: register that is read and written
* Tied input early clobber: register that is read and written and does not share a register with any other input
* alignstack, sideeffect</p>
<p>There are also constraints from the ABI calling convention: <a class="reference external" href="https://gitlab.com/x86-psABIs/x86-64-ABI">https://gitlab.com/x86-psABIs/x86-64-ABI</a></p>
</section>
<section id="values">
<h2>Values<a class="headerlink" href="#values" title="Link to this heading"></a></h2>
<p>Since all values are representable in memory, we could use bytes in the IR for values. But this would lose the type information. So instead we must support all the value types listed in <span class="xref std std-ref">Values</span>.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="FunctionalLogic.html" class="btn btn-neutral float-left" title="Functional logic" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Learning.html" class="btn btn-neutral float-right" title="Learning" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2022 Mathnerd314.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>