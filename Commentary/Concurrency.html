<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Concurrency &mdash; Stroscot  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/hexagon_favicon.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Core syntax" href="CoreSyntax.html" />
    <link rel="prev" title="Compiler output" href="CompilerOutput.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html">
            
              <img src="../_static/hexagon_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/index.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../HowTo/index.html">How to</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Reference/index.html">Language Reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Commentary</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Assembly.html">Assembly</a></li>
<li class="toctree-l2"><a class="reference internal" href="BuildSystem.html">Build system</a></li>
<li class="toctree-l2"><a class="reference internal" href="Checklist.html">Checklist</a></li>
<li class="toctree-l2"><a class="reference internal" href="Code-Generation.html">Code generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Compiler.html">Compiler design</a></li>
<li class="toctree-l2"><a class="reference internal" href="Compiler-Library.html">Compiler library</a></li>
<li class="toctree-l2"><a class="reference internal" href="CompilerOutput.html">Compiler output</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Concurrency</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concurrent-operations">Concurrent operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memory-models-and-races">Memory models and races</a></li>
<li class="toctree-l3"><a class="reference internal" href="#other-types-of-races">Other types of races</a></li>
<li class="toctree-l3"><a class="reference internal" href="#blocking">Blocking</a></li>
<li class="toctree-l3"><a class="reference internal" href="#simulation">Simulation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parallelism">Parallelism</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="CoreSyntax.html">Core syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="Dispatch.html">Dispatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="Errors.html">Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="Evaluation-Strategy.html">Evaluation strategy</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exceptions.html">Exceptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="Fastest.html">As fast as C</a></li>
<li class="toctree-l2"><a class="reference internal" href="IR.html">Intermediate representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Intrinsics.html">Intrinsics</a></li>
<li class="toctree-l2"><a class="reference internal" href="Learning.html">Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Logic.html">Logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="LogicProgramming.html">Logic programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="Macros.html">Macros</a></li>
<li class="toctree-l2"><a class="reference internal" href="Memory-Management.html">Memory management</a></li>
<li class="toctree-l2"><a class="reference internal" href="Meta.html">Meta</a></li>
<li class="toctree-l2"><a class="reference internal" href="Modules.html">Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="Objects.html">Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="PackageManager.html">Package manager</a></li>
<li class="toctree-l2"><a class="reference internal" href="Parsing.html">Parsing</a></li>
<li class="toctree-l2"><a class="reference internal" href="Posets.html">Posets</a></li>
<li class="toctree-l2"><a class="reference internal" href="Profiling.html">Profiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="Programs.html">Exemplary programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction.html">Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction-Example.html">Reduction example</a></li>
<li class="toctree-l2"><a class="reference internal" href="Resource-Management.html">Resource management</a></li>
<li class="toctree-l2"><a class="reference internal" href="Security.html">Security</a></li>
<li class="toctree-l2"><a class="reference internal" href="Sets.html">Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="Standard-Library.html">Standard library</a></li>
<li class="toctree-l2"><a class="reference internal" href="State.html">Stateful programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="Syntax.html">Syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="TermRewriting.html">Term rewriting</a></li>
<li class="toctree-l2"><a class="reference internal" href="Time.html">Time API</a></li>
<li class="toctree-l2"><a class="reference internal" href="Tools.html">Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="Types.html">Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="Units.html">Units</a></li>
<li class="toctree-l2"><a class="reference internal" href="Verification.html">Verification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../zzreferences.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Stroscot</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Commentary</a></li>
      <li class="breadcrumb-item active">Concurrency</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/Mathnerd314/stroscot/edit/master/docs/Commentary/Concurrency.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="concurrency">
<h1>Concurrency<a class="headerlink" href="#concurrency" title="Permalink to this heading"></a></h1>
<p>As Go says, the rise of multicore CPUs means that a language should provide first-class support for concurrency and parallelism. But concurrency and multi-threaded programming have over time developed a reputation for difficulty. So let’s get it right.</p>
<section id="model">
<h2>Model<a class="headerlink" href="#model" title="Permalink to this heading"></a></h2>
<p>The general idea with concurrency is there are multiple threads of execution. But practically there are several types of threads:</p>
<ul class="simple">
<li><p>An OS thread is the basic unit to which the operating system allocates processor time. A thread can execute any part of the process code, including parts currently being executed by another thread. A thread may be bound to a core or have that decided by the OS. There is thread-local storage but generally fiber-local storage should be preferred. (<a class="reference external" href="https://devblogs.microsoft.com/oldnewthing/20191011-00/?p=102989">1</a>, <span id="id1">[<a class="reference internal" href="../zzreferences.html#id120" title="Gor Nishanov. Fibers under the magnifying glass. November 2018. URL: http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1364r0.pdf (visited on 2021-11-04).">Nis18</a>]</span> section 2.3.1)</p></li>
<li><p>A UMS thread is a special type of Windows thread which has more application control. An application can switch between UMS threads in user mode without involving the system scheduler and regain control of the processor if a UMS thread blocks in the kernel. Each UMS thread has its own thread context. The ability to switch between threads in user mode makes UMS more efficient than thread pools for short-duration work items that require few system calls.</p></li>
<li><p>A fiber (green thread, virtual thread, goroutine) consists of a stack, saved registers, and fiber local storage. A fiber runs in the context of a thread and shares the thread context with other fibers. Fiber switching is fewer instructions than a thread context switch. When fibers are integrated into the runtime they can be more memory efficient than OS threads - Go uses only one page for the stack and reallocates the stack if it needs a larger one (<a class="reference external" href="https://docs.google.com/document/d/1wAaf1rYoM4S4gtnPh0zOlGzWtrZFQ5suE8qr2sD8uWQ/pub">contiguous stacks</a>). Per Microsoft, fibers in C do not provide many advantages over threads.</p></li>
</ul>
<p>Threads have their own thread-local state/storage, but they do not exist in a vacuum; most of their state is shared with other threads running in the same context. This context may have several levels:</p>
<ul class="simple">
<li><p>A node is a physical or virtual machine in a cluster</p></li>
<li><p>A pod is a group of one or more containers, that share storage and network resources and runs on a single node</p></li>
<li><p>A container / namespace (Linux) / silo (Windows) contains one or more applications in an isolated form with all dependencies loaded from the container image</p></li>
<li><p>A cgroup (Linux) / job object (Windows) is a group of processes whose resource usage is managed as a unit. Cgroups / job objects are arranged in a hierarchy of containment - cgroups may have multiple hierarchies for distinct resources, but job objects have only one hierarchy. A process belongs to one most specific job object / cgroup in each hierarchy. Cgroups / job objects have rules for assigning newly spawned processes to themselves, and there is an atomic API call to terminate all processes in the cgroup / job object, contrary to <a class="reference external" href="http://jdebp.info/FGA/linux-control-groups-are-not-jobs.html">what this says</a>  (the API call was added later).</p></li>
<li><p>An application is the result of invoking a binary and consists of one or more running processes.</p></li>
<li><p>A process is an executing program and has a memory space and other resources allocated. One or more threads run in the context of the process.</p></li>
</ul>
<p>As far as storage, all immutable data exists in ambient space and is transparently copied by the memory management system as needed. Mutable data is stored in a specific location (TLS, process context, etc.) and is accessed via specialized, imperative concurrent operations.</p>
</section>
<section id="concurrent-operations">
<h2>Concurrent operations<a class="headerlink" href="#concurrent-operations" title="Permalink to this heading"></a></h2>
<p>At the lowest level, a thread uses a combination of hardware and OS operations. The hardware operations are read/write on mutable shared memory, and various memory barrier/fence instructions. The OS syscalls are a mess but can be roughly tagged as files, networking, process, (shared) memory, permissions, system clock, futex, System V IPC, and signals. In the cloud, a thread uses mostly network-centric operations, message-passing between nodes, while on a node the operations are mostly shared memory operations due to current machine architectures.</p>
<p>There are many higher-level I/O concurrency abstractions: mutexes, condition variables, channels, MVars, transactional memory. These high-level interfaces are conceptually much simpler to reason about than mutable shared memory, in particular avoiding aliasing, even if there is still mutable shared memory under the covers. But mutable shared memory is a key feature of modern C++ concurrency implementations and it would significantly reduce expressiveness to forbid it from Stroscot. Sharing is caring.</p>
<p>TODO: create complete list of higher-level abstractions and figure out how to nicely expose them in the language as libraries</p>
<p>In Erlang we have the actor model. This had the following concurrent operations: spawn process (identified by ID), send message (any value) to process, receive next message (block indefinitely), receive next message (with timeout). These are implemented by a runtime, which ensures processes are lightweight, schedules and runs them, and manages memory like the message queues.</p>
</section>
<section id="memory-models-and-races">
<h2>Memory models and races<a class="headerlink" href="#memory-models-and-races" title="Permalink to this heading"></a></h2>
<p>The smallest examples of races runtimewise just have memory access. For example this program SB: <span id="id2">[<a class="reference internal" href="../zzreferences.html#id139" title="Peter Sewell, Susmit Sarkar, Scott Owens, Francesco Zappa Nardelli, and Magnus O. Myreen. X86-TSO: a rigorous and usable programmer's model for x86 multiprocessors. Communications of the ACM, 53(7):89–97, July 2010. URL: https://dl.acm.org/doi/10.1145/1785414.1785443 (visited on 2021-07-09), doi:10.1145/1785414.1785443.">SSO+10</a>]</span></p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">x</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">mem</span><span class="w"> </span><span class="mi">0</span>
<span class="nf">u</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">mem</span><span class="w"> </span><span class="mi">0</span>
<span class="kt">A</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">mem</span><span class="w"> </span><span class="mi">0</span>
<span class="kt">B</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">mem</span><span class="w"> </span><span class="mi">0</span>
<span class="nf">t1</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">fork</span><span class="w"> </span><span class="p">{</span><span class="kt">A</span><span class="w"> </span><span class="kt">:=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="kt">:=</span><span class="w"> </span><span class="o">!</span><span class="p">(</span><span class="n">read</span><span class="w"> </span><span class="kt">B</span><span class="p">)</span><span class="w"> </span><span class="p">}</span>
<span class="nf">t2</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">fork</span><span class="w"> </span><span class="p">{</span><span class="kt">B</span><span class="w"> </span><span class="kt">:=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">u</span><span class="w"> </span><span class="kt">:=</span><span class="w"> </span><span class="o">!</span><span class="p">(</span><span class="n">read</span><span class="w"> </span><span class="kt">A</span><span class="p">)</span><span class="w"> </span><span class="p">}</span>
<span class="nf">join</span><span class="w"> </span><span class="p">(</span><span class="n">t1</span><span class="p">,</span><span class="w"> </span><span class="n">t2</span><span class="p">)</span>
<span class="nf">print</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="p">(</span><span class="n">read</span><span class="w"> </span><span class="n">x</span><span class="p">),</span><span class="w"> </span><span class="o">!</span><span class="p">(</span><span class="n">read</span><span class="w"> </span><span class="n">u</span><span class="p">))</span>
</pre></div>
</div>
<p>Here the threads are provided by the C stdlib’s pthreads, and the operations are hardware load/store instructions.
This program has a race condition, i.e. the order of writing and reading from A, B, x and u is not fixed.</p>
<p>At this point one might be tempted to mimic C++ or Java and say a race is undefined behavior. But in fact C++ provides an escape hatch: atomics. Every type has a corresponding atomic type, so the program can just be made valid by making every variable and operation atomic. So this is a perfectly reasonable program. C++ is just adding more ways to shoot yourself in the foot by having non-atomic shared variables.</p>
<p>Suppose we actually run the program on a processor a lot of times - we will see that the printed outcome may be <code class="docutils literal notranslate"><span class="pre">(1,1)</span></code>, <code class="docutils literal notranslate"><span class="pre">(1,0)</span></code>, <code class="docutils literal notranslate"><span class="pre">(0,1)</span></code>, or <code class="docutils literal notranslate"><span class="pre">(0,0)</span></code>, but values other than 0 or 1 are not observed. To predict this behavior there are corresponding “relaxed memory models”, such as x86-TSO <span id="id3">[<a class="reference internal" href="../zzreferences.html#id139" title="Peter Sewell, Susmit Sarkar, Scott Owens, Francesco Zappa Nardelli, and Magnus O. Myreen. X86-TSO: a rigorous and usable programmer's model for x86 multiprocessors. Communications of the ACM, 53(7):89–97, July 2010. URL: https://dl.acm.org/doi/10.1145/1785414.1785443 (visited on 2021-07-09), doi:10.1145/1785414.1785443.">SSO+10</a>]</span> for x86 and multicopy atomicicity (MCA) <span id="id4">[<a class="reference internal" href="../zzreferences.html#id132" title="Christopher Pulte, Shaked Flur, Will Deacon, Jon French, Susmit Sarkar, and Peter Sewell. Simplifying ARM concurrency: multicopy-atomic axiomatic and operational models for ARMv8. Proceedings of the ACM on Programming Languages, 2(POPL):19:1–19:29, December 2017. URL: https://doi.org/10.1145/3158107 (visited on 2021-07-19), doi:10.1145/3158107.">PFD+17</a>]</span> for ARMv8. These models have been tested to match physical processors for a wide variety of concurrent programs (‘litmus tests’) and appear to be accepted by the processor vendors as standard.</p>
<p>Another example is independent reads of independent writes (IRIW):</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="n">a</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">X</span><span class="p">;</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">Y</span><span class="p">}</span>
<span class="p">{</span><span class="kt">X</span><span class="w"> </span><span class="kt">:=</span><span class="w"> </span><span class="mi">1</span><span class="p">}</span>
<span class="p">{</span><span class="kt">Y</span><span class="w"> </span><span class="kt">:=</span><span class="w"> </span><span class="mi">1</span><span class="p">}</span>
<span class="p">{</span><span class="n">c</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">Y</span><span class="p">;</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kt">X</span><span class="p">}</span>
</pre></div>
</div>
<p>Here the initial state is <code class="docutils literal notranslate"><span class="pre">(X,Y)=(0,0)</span></code>, and the final state can be <code class="docutils literal notranslate"><span class="pre">(a,b,c,d)=(1,0,1,0)</span></code> under POWER. But both ARMv8 and x86 forbid this outcome.</p>
<p>Now there have been attempts to make cross-platform memory models, e.g. there is a C++11 memory model, a Java memory model, a Linux kernel memory memory model, etc. But each of these models is a poor match for hardware - the non-relaxed modes prevent outcomes possible in hardware, and require too many fences and are slow, and the relaxed mode is just the hardware but without fences. Early specifications of these models even allowed outcomes that hardware would not (e.g. reading values out of thin air). So Stroscot avoids all this abstraction overhead by using the target hardware’s memory model. This does mean some more work to implement a new platform, but I think it’s worth it. Weaker fences are more performant, and you’ll have the wrong cost model if you aren’t optimizing using the processor’s memory model. For example x86’s TSO model means that concurrent memory writes don’t need a fence at all.</p>
<p>Now for cross-platform programming, there are tricky cases. For example LDRD on ARM is atomic <a class="reference external" href="https://gcc.gnu.org/pipermail/gcc-patches/2017-April/471979.html">only if</a> LPAE (large physical address extension) is supported by the processor, and even then LDRD is atomic only if it is naturally aligned. For this the cross-platform memory models are useful. But we don’t need to implement the whole model, we just have to use the fairly well-defined assembly instruction translations, for example <a class="reference external" href="https://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html">C/C++</a> and <a class="reference external" href="https://gee.cs.oswego.edu/dl/jmm/cookbook.html">Java</a>. Then we can use the processor memory model to optimize.</p>
<p>So overall, determining whether a synchronization pattern is correct requires checking many cases and conditions - exactly what static verification using a memory model can help with.</p>
<blockquote>
<div><p>the easy strateg is to just do a strong fence every time you perform a concurrent operation, such as dmb on ARM. This ensures sequential consistency which is essentially everyone’s intuitive memory model.</p>
<p>instead of a cross-platform model, Stroscot encourages checking platform compatibility of the program, i.e. that the two memory models make the program produce equivalent results.</p>
</div></blockquote>
</section>
<section id="other-types-of-races">
<h2>Other types of races<a class="headerlink" href="#other-types-of-races" title="Permalink to this heading"></a></h2>
<p>Races not involving memory can also happen:</p>
<ul class="simple">
<li><p>Two acquires of a mutex with different continuations.</p></li>
<li><p>Appending to a file from multiple threads</p></li>
<li><p>Writing files in a different order</p></li>
<li><p>Exiting the program from a thread, when the program is doing anything else</p></li>
</ul>
<p>Races could conceivably be desired, e.g. when writing litmus tests, so it is just a warning. Also a “race” like the order of writing to files is generally not important.</p>
</section>
<section id="blocking">
<h2>Blocking<a class="headerlink" href="#blocking" title="Permalink to this heading"></a></h2>
<p>Acquiring a lock blocks until the lock is released. This introduces the problems of deadlock and starvation, which can be detected as the absence of progressing execution orders. With wait-free / atomic operations we never need to block.</p>
<p>Go map operations do not grab a mutex and must be synchronized by some larger data structure or computation for access from multiple goroutines. This speeds up most programs but means some programs must add synchronization to avoid crashing. It is safe to use the map read-only, and a runtime check can report when a map is modified unsafely by concurrent execution.</p>
</section>
<section id="simulation">
<h2>Simulation<a class="headerlink" href="#simulation" title="Permalink to this heading"></a></h2>
<p>On a program level Stroscot simulates the program’s (concurrent) execution, and will give a warning if it’s not deterministic or if deadlock is possible - the program is required to have the same result regardless of data race outcomes. This is checked by the verification system. Basically the simulation runs through the concurrency model and errors when the program behavior becomes visibly inconsistent. The verification system handles the nondeterminism somehow, check out papers on concurrency verification.</p>
<p>It’s a bit lengthy to simulate the OS interface, but operations change infrequently, so it should be maintainable. The behavior of the OS scheduler is complicated and hard to model except as an adversary. The Linux scheduler might take an unreasonably long time to schedule a particular thread even if every other thread is sleeping or calls yield. Or it might decide to run it immediately, or move it on another core, etc.</p>
</section>
<section id="parallelism">
<h2>Parallelism<a class="headerlink" href="#parallelism" title="Permalink to this heading"></a></h2>
<p>Parallelism - the root is “parallel” or “happening at the same time”. But with <a class="reference external" href="https://en.wikipedia.org/wiki/Relativity_of_simultaneity">relativity</a>, simultaneity is not absolute. We instead consider <a class="reference external" href="https://en.wikipedia.org/wiki/Causal_structure">causal structure</a> - event separation can be timelike or spacelike. Timelike separation communicates information from past to future, while no dependency is possible with spacelike separation. Hence we define an execution as a directed graph of information flow, where a node is a value and an edge is read “can casually influence” (we could also use the reverse “reads data from”). Assuming no time travel the graph is acyclic and its transitive closure forms a partial order or poset. Then things happen “in parallel” if neither causally influences the other.</p>
<p>For example, <a class="reference external" href="https://en.wikipedia.org/wiki/Matrix_multiplication_algorithm#Parallel_and_distributed_algorithms">multiplying</a> two 2x2 matrices:</p>
<img alt="../_images/matrix-multiply.svg" src="../_images/matrix-multiply.svg" /><p>The multiplications all happen in parallel and the additions in parallel.</p>
<p>There’s no explicit syntax for parallelism - pure computations have inherent parallelism. Writing it out looks like:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">multiply</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="ow">=</span>
<span class="w">  </span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">dim</span><span class="w"> </span><span class="n">a</span>
<span class="w">  </span><span class="p">(</span><span class="n">n&#39;</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">n&#39;</span><span class="p">,</span><span class="n">o</span><span class="p">)</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">dim</span><span class="w"> </span><span class="n">b</span>
<span class="w">  </span><span class="n">for</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="o">..</span><span class="n">m</span><span class="p">]</span><span class="w"> </span><span class="o">$</span><span class="w"> </span><span class="nf">\</span><span class="n">i</span><span class="w"> </span><span class="ow">-&gt;</span>
<span class="w">    </span><span class="n">for</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="o">..</span><span class="n">o</span><span class="p">]</span><span class="w"> </span><span class="o">$</span><span class="w"> </span><span class="nf">\</span><span class="n">j</span><span class="w"> </span><span class="ow">-&gt;</span>
<span class="w">      </span><span class="n">sum</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="o">!!</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">b</span><span class="w"> </span><span class="o">!!</span><span class="w"> </span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">j</span><span class="p">))</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">&lt;-</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="w"> </span><span class="o">..</span><span class="w"> </span><span class="n">n</span><span class="p">]</span><span class="w"> </span><span class="p">]</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">for</span></code> and <code class="docutils literal notranslate"><span class="pre">sum</span></code> can evaluate arguments in parallel. More complicated is allowing functions, for example <code class="docutils literal notranslate"><span class="pre">foldMap</span> <span class="pre">f</span> <span class="pre">g</span> <span class="pre">(x:xs)</span> <span class="pre">=</span> <span class="pre">g</span> <span class="pre">(f</span> <span class="pre">x)</span> <span class="pre">(foldMap</span> <span class="pre">f</span> <span class="pre">g</span> <span class="pre">xs)</span></code> generates a DAG of f’s and g’s if the list spine is known. Even with general recursion it should still be possible to identify data dependencies and assign DAG cells to temporary values in some fashion. Conditionals are a little hard to schedule because you have to make sure both sides can be speculated or discard the untaken branch promptly.</p>
<p>Stroscot schedules the instructions to maximize instruction-level parallelism, where appropriate. This takes advantage of the design of modern CPUs, where there are multiple “ports” and each port can execute an instruction simultaneously.</p>
<p>With large (&gt;1000 width) matrices we might want to multiply sub-matrices on multiple threads (cores). That requires concurrency, so is handled by writing the synchronization operations explicitly.  Stroscot doesn’t parallelize on the thread level by default because automatically spawning threads would be surprising, and the choice of thread/scheduler/performance model (OpenMP, OS thread, green thread) influences what granularity to split up the computation at.</p>
<p>But still, for complex data science computations we might want automatic parallelization that takes advantage of multicore hardware. So we can provide a DSL function <code class="docutils literal notranslate"><span class="pre">parallelize</span></code> to automatically rewrite pure computations to concurrent ones, implementing the “small on single thread, big splits into small” operations on top of fork/join model and taking the thread / task queue implementation as a parameter. Doug Lea’s work stealing task queues can be very efficient given the correct task granularity.</p>
<p>Haskell’s “par” is interesting, but too fine-grained to be efficient. You have to manually add in a depth threshold and manually optimize it. It’s just as clear to use explicit fork/join operations, and indeed the <code class="docutils literal notranslate"><span class="pre">rpar/rpar/rseq/rseq</span></code> pattern proposed in <a class="reference external" href="https://www.oreilly.com/library/view/parallel-and-concurrent/9781449335939/ch02.html">the Parallel Haskell book</a> is just fork/join with different naming.</p>
<p>As far as the actual task granularity, Cliff Click says the break-even point is somewhere around the middle of the microsecond range, thousands of cycles / machine code instructions. Below that the overhead for forking the task exceeds the speedup from parallelism, but above you can make useful progress in another thread.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="CompilerOutput.html" class="btn btn-neutral float-left" title="Compiler output" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="CoreSyntax.html" class="btn btn-neutral float-right" title="Core syntax" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2022 Mathnerd314.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>