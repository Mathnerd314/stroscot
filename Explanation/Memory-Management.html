

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Memory management &mdash; Stroscot  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../_static/hexagon_favicon.png"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Assembly" href="Assembly.html" />
    <link rel="prev" title="Compiler design" href="Compiler.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/hexagon_logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted/index.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../HowTo/index.html">How to</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Reference/index.html">Language Reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Discussion</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Meta.html">About</a></li>
<li class="toctree-l2"><a class="reference internal" href="State.html">Imperative programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="Delimited-Continuations.html">Delimited continuations</a></li>
<li class="toctree-l2"><a class="reference internal" href="Syntax.html">Syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="Verification.html">Verification</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction.html">Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction.html#random-old-junk">Random old junk</a></li>
<li class="toctree-l2"><a class="reference internal" href="Reduction-Example.html">Reduction example</a></li>
<li class="toctree-l2"><a class="reference internal" href="Compiler.html">Compiler design</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Memory management</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#allocator">Allocator</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pieces">Pieces</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#mutator">Mutator</a></li>
<li class="toctree-l4"><a class="reference internal" href="#collector">Collector</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id5">Allocator</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Assembly.html">Assembly</a></li>
<li class="toctree-l2"><a class="reference internal" href="PackageManager.html">Package manager</a></li>
<li class="toctree-l2"><a class="reference internal" href="Programs.html">Exemplary programs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../zzreferences.html">References</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Stroscot</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">Discussion</a> &raquo;</li>
        
      <li>Memory management</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            
              <a href="https://github.com/Mathnerd314/stroscot/edit/master/docs/Explanation/Memory-Management.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="memory-management">
<h1>Memory management<a class="headerlink" href="#memory-management" title="Permalink to this headline">¶</a></h1>
<p>The malloc/free model is not correct; what we need to keep track of is what will be accessed and where it will be stored. Memory leaks are a pervasive problem, in general there is no real solution besides profiling and buying more RAM. Stroscot can prove memory will not be accessed in the future and hence free it, with a more precise analysis than traditional GC. On the other hand use-after-free and double free can be statically checked for pointers, and aren’t a problem at all for the rest of the language because Stroscot frees automatically.</p>
<p>A scratch buffer, as exemplified by GNU C’s <a class="reference external" href="https://www.gnu.org/software/libc/manual/html_node/Obstacks.html">obstack</a> seems to be an array variable plus metadata. They don’t require any special support AFAICT.</p>
<p>Memory management is not about finding a place to store things. If it was, global storage capacity is measured in zettabytes, so we could just store everything in the cloud. Or hard drives would be sufficient for almost all purposes. The issue is storing and retrieving things in the most efficient way possible, with little overhead - in particular preserving cache locality. Examples:
* A loop that allocates and deallocates a scratch buffer is much more performant if the buffer is allocated to the same location every time - the allocation/deallocation code can even be pulled out of the loop.
* Grouping hot variables into a page, so the page is always loaded and ready
* Grouping things that will be freed together (pools/arenas)</p>
<p>Ownership a la Rust cannot even handle doubly-linked lists so is not worth considering. Code frequently switches to the <code class="docutils literal notranslate"><span class="pre">Rc</span></code> reference counted type, which besides cycles has the semantics of GC. There is even a <a class="reference external" href="https://github.com/Others/shredder">library</a> for a <code class="docutils literal notranslate"><span class="pre">Gc</span></code> type that does intrusive scanning. GC is more composable and it can also be faster than manual memory management <span id="id1">[<a class="reference internal" href="../zzreferences.html#id8" title="Andrew W. Appel. Garbage collection can be faster than stack allocation. Information Processing Letters, 25(4):275–279, June 1987. URL: https://www.cs.princeton.edu/~appel/papers/45.pdf (visited on 2020-07-24), doi:10.1016/0020-0190(87)90175-X.">App87</a>]</span>. As Appel points out, even if freeing an individual object is a single machine instruction, such as a stack pop, freeing a lot of objects still has significant overhead compared to copying out the useful data. But garbage collection scanning slows things down because it pulls in a lot of memory; generational GC reduces this somewhat, but the more interesting area of memory management research is static analysis. To that end some work <span id="id2">[<a class="reference internal" href="../zzreferences.html#id54" title="Raphaël L Proust. ASAP: As Static As Possible memory management. Technical Report UCAM-CL-TR-908, University of Cambridge Computer Laboratory, July 2017. URL: https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-908.pdf.">Pro17</a>]</span> <span id="id3">[<a class="reference internal" href="../zzreferences.html#id15" title="Nathan Corbyn. Practical Static Memory Management. Bachelor's Thesis, King’s College, May 2020. URL: http://nathancorbyn.com/nc513.pdf.">Cor20</a>]</span> on “as static as possible” (ASAP) memory management is quite relevant. Conceptually we are taking a tracing GC algorithm and replacing the tracing with a compile time analysis that outputs a comparatively small bit of runtime checks. It’s whole program and undecidable, but Stroscot already has 3 or 4 of those planned.</p>
<p>Why hasn’t anyone done static memory management before? Well, the notion of termination analysis only got started in 2007 or so. 10 years later Proust applies the techniques to memory, it’s slow but there is a conceptual leap in going from program verification to program synthesis. It could be faster but I can see why it isn’t.</p>
<ul class="simple">
<li><p>The newly-dead set for a state transition <code class="docutils literal notranslate"><span class="pre">s</span> <span class="pre">-&gt;</span> <span class="pre">t</span></code> is all objects that are accessed before but not accessed later, <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">=</span> <span class="pre">{z</span> <span class="pre">|</span> <span class="pre">Access(s,z)</span> <span class="pre">=</span> <span class="pre">yes</span> <span class="pre">&amp;&amp;</span> <span class="pre">Access(t,z)</span> <span class="pre">=</span> <span class="pre">no}</span> <span class="pre">=</span> <span class="pre">L(s)</span> <span class="pre">intersect</span> <span class="pre">D(t)</span></code>.</p></li>
</ul>
<p>We deallocate the newly-dead set after each operation. This doesn’t necessarily reclaim the memory, but ensures freeing is timely if needed. We also can compact the live set by removing dead fields.</p>
<p>Quad-color marking</p>
<p>The GC status of an object is set by two bits, the mark bit and the gray bit. The mark bit is stored in a bitmap, can be white or black. The gray bit is stored in a boxed_value object, determining whether an object has been fully marked. Only traversable objects have a gray bit and hence quad colors. Non-traversable (flat) objects have very simple state transitions (just white-&gt;black-&gt;white).</p>
<div class="graphviz"><object data="../_images/graphviz-7f2ca21b2f6ecc209a4430ce511dca39779c7cce.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph G {
  &quot;Newly allocated traversable object&quot; [fillcolor=lightgray,style=filled]
  s1 [label=&quot;Sweep&quot;]
  s2 [label=&quot;Sweep&quot;]
  wb1 [label=&quot;Write&quot;,fillcolor=lightgray,style=filled]
  wb2 [label=&quot;Write&quot;]
  &quot;Object Fully Traversed&quot; [fillcolor=black,fontcolor=white,style=filled]
  &quot;Gray Stack&quot; [fillcolor=grey22,fontcolor=white,style=filled]

  &quot;New Object&quot; -&gt; s1
  s1 -&gt; &quot;Object Is Freed&quot;
  &quot;Object Is Freed&quot; -&gt; s2
  s2 -&gt; &quot;Sweep Resets To white&quot;
  &quot;Sweep Resets To white&quot; -&gt; wb1
  wb1 -&gt; s1 [label=&quot;Flat&quot;]
  wb1 -&gt; &quot;Traversal Starts: Object Was Rooted Or Referenced&quot;
  &quot;New Object&quot; -&gt; &quot;Traversal Starts: Object Was Rooted Or Referenced&quot;
  &quot;Traversal Starts: Object Was Rooted Or Referenced&quot; -&gt; &quot;Push&quot;
  wb2 -&gt; &quot;Push&quot;
  &quot;Object Fully Traversed&quot; -&gt; &quot;Sweep Resets To white&quot;
  &quot;Object Fully Traversed&quot; -&gt; wb2
  &quot;Push&quot; -&gt; &quot;Gray Stack&quot;
  &quot;Gray Stack&quot; -&gt; &quot;Pop&quot;
  &quot;Pop&quot; -&gt; &quot;Add Referenced Objects To Gray Stack&quot;
  &quot;Add Referenced Objects To Gray Stack&quot; -&gt; &quot;Object Fully Traversed&quot;
}</p></object></div>
<p>local (“arena”) allocators speed up short-running programs, keep long–running ones from slowing down over time. All global allocators eventually exhibit diffusion–i.e., memory initially dispensed and therefore (coincidentally) accessed contiguously, over time, ceases to remain so, hence runtime performance invariably degrades. This form of degradation has little to do with the runtime performance of the allocator used, but rather is endemic to the program itself as well as the underlying computer platform, which invariably thrives on locality of reference.”
diffusion should not be confused with fragmentation–an entirely different phenomenon pertaining solely to (“coalescing”) allocators (not covered in this paper) where initially large chunks of contiguous memory decay into many smaller (non-adjacent) ones, thereby precluding larger ones from subsequently being allocated –even though there is sufficient total memory available to accommodate the request. Substituting a pooling allocator, such as theone used in this benchmark (AS7), is a well-known solution to the fragmentationproblems that might otherwise threaten long-running mission-critical systems.”</p>
<p>Newly allocated traversable objects are light-gray. Writing only changes the state of non-gray objects.</p>
<p>When the object is marked during the mark phase, it’s turned dark-gray (mark bit turned black) and pushed onto the gray stack. In case it’s unreachable, the sweep phase can free a light-gray object like any other object marked white.</p>
<p>Dark-gray objects are turned black after traversal (clearing the gray bit) and turned white after sweeping. The write barrier may trigger during this short period and move the barrier back by turning it dark-gray again.</p>
<p>An object that survived one GC cycle is turned white like all other survivors. In case the object is written to after that, it’s turned light-gray again. But this doesn’t push the object onto the gray stack right away! In fact, only the gray bit needs to be flipped, which avoids further barriers as explained above.</p>
<p>The main advantage of the quad-color algorithm is the ultra-cheap write barrier: just check the gray bit, which needs only 2 or 3 machine instructions. And due to the initial coloring and the specific color transitions, write barriers for e.g. tables are hardly ever triggered in practice. The fast path of the write barrier doesn’t need to access the mark bitmap, which avoids polluting the cache with GC metadata while the mutator is running.</p>
<p>The quad-color algorithm can easily fall back to the tri-color algorithm for some traversable objects by turning them white initially and using forward write barriers. And there’s an obvious shortcut for non-traversable objects: marking turns a white object black right away, which touches the mark bitmap only. Since these kind of objects are in segregated arenas, they don’t need to be traversed and their data never needs to be brought into the cache during the mark phase.</p>
<p>Arena-based bump allocator for objects
Cheap write barrier in the common case
Mark-and-compact collection for oldest generation
Copying generational collection for younger generations
Special space (in cache?) for nursery generation
State Transitions</p>
<p>I think it’s better to write a faster GC than to try to special-case various types of allocation. The GC itself can special case things. Optimizing requires global information and only the GC has a global view.</p>
<p>Static immutable data should be interned.</p>
<p>Compress strings with shoco <a class="reference external" href="https://github.com/Ed-von-Schleck/shoco">https://github.com/Ed-von-Schleck/shoco</a> or  the sequitur algorithm <a class="reference external" href="http://www.sequitur.info/">http://www.sequitur.info/</a>. Maybe can fit into a 64-bit word. Cleaning the dictionary periodically would probably have to happen to avoid resource leaks, which might have to recompress every relevant string. Fortunately, long strings tend to be fairly long-lived.</p>
<p><a class="reference external" href="https://github.com/ollef/sixten">https://github.com/ollef/sixten</a> talks about being able to represent intrusive lists. I experimented with allowing the decision of pointer vs direct storage to be made in pack, but it really simplifies the code a lot to require all pack functions to produce flat blobs of data.</p>
<p>Destructors are inspired by C++ RAII destructors, hence the name. Admittedly the actual API doesn’t bear much resemblance. <a class="reference external" href="https://en.wikipedia.org/wiki/Finalizer">Finalizers</a> can resurrect objects and don’t have deterministic execution, hence would be a bad name. Go’s defer statement and try-finally are related, but they only work locally and have imprecise execution semantics.</p>
<p>Portable mmap:
* Yu virtualalloc <a class="reference external" href="https://github.com/alpha123/yu/tree/master/src/platform">https://github.com/alpha123/yu/tree/master/src/platform</a>
* Go: <a class="reference external" href="https://github.com/edsrzf/mmap-go">https://github.com/edsrzf/mmap-go</a>
* C: mmap on windows <a class="reference external" href="https://github.com/alitrack/mman-win32">https://github.com/alitrack/mman-win32</a>
* C++: <a class="reference external" href="https://github.com/mandreyel/mio">https://github.com/mandreyel/mio</a>
* Rust: <a class="reference external" href="https://github.com/RazrFalcon/memmap2-rs">https://github.com/RazrFalcon/memmap2-rs</a></p>
<div class="section" id="model">
<h2>Model<a class="headerlink" href="#model" title="Permalink to this headline">¶</a></h2>
<p>For memory management we have to consider values, called objects. Pointers are manually freed and hence don’t need to be managed.</p>
<p>An invalidate queue is more like a store buffer, but it’s part of the memory system, not the CPU. Basically it is a queue that keeps track of invalidations and ensures that they complete properly so that a cache can take ownership of a cache line so it can then write that line. A load queue is a speculative structure that keeps track of in-flight loads in the out of order processor. For example, the following can occur</p>
<blockquote>
<div><p>CPU speculatively issue a load from X
That load was in program order after a store to Y, but the address of Y is not resolved yet, so the store does not proceed.
Y is resolved and it turns out to be equal to X. At the time that the store to Y is resolved, that store searches the load queue for speculative loads that have issued, but are present after the store to Y in program order. It will notice the load to X (which is equal to Y) and have to squash those instructions starting with load X and following.</p>
</div></blockquote>
<p>A store buffer is a speculative structure that exists in the CPU, just like the load queue and is for allowing the CPU to speculate on stores. A write combining buffer is part of the memory system and essentially takes a bunch of small writes (think 8 byte writes) and packs them into a single larger transaction (a 64-byte cache line) before sending them to the memory system. These writes are not speculative and are part of the coherence protocol. The goal is to save bus bandwidth. Typically, a write combining buffer is used for uncached writes to I/O devices (often for graphics cards). It’s typical in I/O devices to do a bunch of programming of device registers by doing 8 byte writes and the write combining buffer allows those writes to be combined into larger transactions when shipping them out past the cache.</p>
</div>
<div class="section" id="allocator">
<h2>Allocator<a class="headerlink" href="#allocator" title="Permalink to this headline">¶</a></h2>
<p>ultimate allocator - steal features from all other allocators. It’s one of those well-researched areas where a few percent lives. Substitution isn’t really an option but maybe some components could be pluggable. Thread safe but values are pure and references can be determined to be thread-local so lots of optimizations.</p>
<p>We want to automatically determine the number of allocation regions and their size to maximize locality.</p>
<p>locate memory leaks - places where allocated memory is never getting freed - memory usage profiling</p>
<p>Handling OOM gracefully - non-allocating subset of language. Should be enough to implement “Release some resources and try again” and “Save the user’s work and exit” strategies. Dumping core is trivial so doesn’t need to be considered.</p>
<p>Layout is usually defined by its size, alignment, padding/stride, and field offsets, but this only specifies the representation of simple flat records. With enumerations, there is the question of how to encode constants. It gets even more complicated with ADTs, like JS’s <a class="reference external" href="https://wingolog.org/archives/2011/05/18/value-representation-in-javascript-implementations">value type</a>, and the choices often impact performance significantly. Finally there is the use of pointers. It complicates the memory management a bit to handle non-contiguous memory layouts, but the algorithms all deal with pointer trees anyway so I don’t think it’s intractable.</p>
<p>The pack/unpack idea is similar to the <a class="reference external" href="https://github.com/mgsloan/store/blob/master/store-core/src/Data/Store/Core.hs">store library</a> and the encode/decode functions used by Narcissus <span id="id4">[<a class="reference internal" href="../zzreferences.html#id18" title="Benjamin Delaware, Sorawit Suriyakarn, Clément Pit-Claudel, Qianchuan Ye, and Adam Chlipala. Narcissus: correct-by-construction derivation of decoders and encoders from binary formats. Proceedings of the ACM on Programming Languages, 3(ICFP):1–29, July 2019. URL: https://www.cs.purdue.edu/homes/bendy/Narcissus/narcissus.pdf (visited on 2020-07-26), doi:10.1145/3341686.">DSPitClaudel+19</a>]</span>.</p>
<p>Narcissus is too complex IMO:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="kt">Format</span> <span class="ow">=</span> <span class="kt">Set</span> <span class="p">(</span><span class="kt">S</span><span class="p">,</span> <span class="kt">St</span><span class="p">,</span> <span class="kt">T</span><span class="p">,</span> <span class="kt">St</span><span class="p">)</span>
<span class="kt">Encode</span> <span class="ow">=</span> <span class="kt">S</span> <span class="ow">-&gt;</span> <span class="kt">St</span> <span class="ow">-&gt;</span> <span class="kt">Option</span> <span class="p">(</span><span class="kt">T</span><span class="p">,</span> <span class="kt">St</span><span class="p">)</span>
<span class="kt">Decode</span> <span class="ow">=</span> <span class="kt">T</span> <span class="ow">-&gt;</span> <span class="kt">St</span> <span class="ow">-&gt;</span> <span class="kt">Option</span> <span class="p">(</span><span class="kt">S</span><span class="p">,</span> <span class="kt">St</span><span class="p">)</span>
</pre></div>
</div>
<p>The state parameter can be gotten rid of by defining <code class="docutils literal notranslate"><span class="pre">S</span> <span class="pre">=</span> <span class="pre">(S,St),</span> <span class="pre">T</span> <span class="pre">=</span> <span class="pre">(T,St)</span></code>:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="kt">Format</span> <span class="ow">=</span> <span class="kt">Set</span> <span class="p">(</span><span class="kt">S</span><span class="p">,</span> <span class="kt">T</span><span class="p">)</span>
<span class="kt">Encode</span> <span class="ow">=</span> <span class="kt">S</span> <span class="ow">-&gt;</span> <span class="kt">Option</span> <span class="kt">T</span>
<span class="kt">Decode</span> <span class="ow">=</span> <span class="kt">T</span> <span class="ow">-&gt;</span> <span class="kt">Option</span> <span class="kt">S</span>
</pre></div>
</div>
<p>And we can make encode/decode total by defining <code class="docutils literal notranslate"><span class="pre">S</span> <span class="pre">=</span> <span class="pre">{s</span> <span class="pre">|</span> <span class="pre">exists</span> <span class="pre">t.</span> <span class="pre">(s,t)</span> <span class="pre">in</span> <span class="pre">Format}</span></code>, <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">=</span> <span class="pre">{t</span> <span class="pre">|</span> <span class="pre">exists</span> <span class="pre">s.</span> <span class="pre">(s,t)</span> <span class="pre">in</span> <span class="pre">Format}</span></code>.</p>
<p>I thought about letting <code class="docutils literal notranslate"><span class="pre">pack</span></code> narrow the range of values, e.g. rounding 1.23 to 1.2, but concluded that it would be surprising if storing a value to memory changed it. The rounding can be defined as a pre-pass over the data to convert it to a <code class="docutils literal notranslate"><span class="pre">Measurement</span></code> type that then has optimized storage.</p>
<p>One tricky part is that the naive way to specify types interferes with overloading, subtyping and implicit conversions. <code class="docutils literal notranslate"><span class="pre">pack</span> <span class="pre">(Int8</span> <span class="pre">1)</span></code> can give a byte as expected, but it can also implicitly convert to an <code class="docutils literal notranslate"><span class="pre">Int32</span></code> and give 4 bytes. Since we have dependent types this isn’t a real issue, just make sure the code generated after representation specialization passes the type explicitly: <code class="docutils literal notranslate"><span class="pre">pack</span> <span class="pre">Int32</span> <span class="pre">(Int8</span> <span class="pre">1)</span></code>.</p>
<p>A few things need to optimize away for reasonable performance.  <code class="docutils literal notranslate"><span class="pre">length</span> <span class="pre">.</span> <span class="pre">pack</span></code> should optimize to something like <code class="docutils literal notranslate"><span class="pre">const</span> <span class="pre">20</span></code> for most values, or at least something that doesn’t allocate, so that field accesses are independent and values can be allocated sanely. These functions might have to be hacked in, specializing to constant-sized values.</p>
<p>Since writing these serialization functions all the time would be tedious, we can make a format DSL that specifies the functions in a nicer way. Although one of these DSL’s will be the standard / default, it’ll be some kind of macro / constraint system, so defining new format DSLs for specific purposes shouldn’t be hard.</p>
<p>The translation to use pack is pretty simple: every value is wrapped in a call to pack, the result is stored as a tuple <code class="docutils literal notranslate"><span class="pre">(cell,unpack)</span></code>, and every usage applies unpack to the cell. The translation uses whatever pack is in scope; pack can be overridden like any other implicit parameters. The unpack functions will end up getting passed around a lot, but function pointers are cheap constants, and constant propagation is a thing, so it shouldn’t be an issue.</p>
<p>A derived pointer is a reference plus an offset. When the address and layout of the object is known we can store the derived pointer as the value address plus offset. But we could also just store the offset, so it’s only useful if computing the sum is necessary and expensive.</p>
<p>An object can be treated as an array, N[i] and N.length.</p>
<p>The array part of shared memory is necessary because there is a double-word CAS operation on x86 (CMPXCHG16B), and also for efficiency.</p>
<p>Supporting persistent memory: The pointer API, assembly wrapping, and OS calls cover using persistent memory via standard file APIs or memory-mapped DAX. Memory is volatile while persistent memory is not, so persistent memory is faster storage, not weird RAM. And storage is complex enough that it seems best handled by libraries. Making the memory management system memkind-aware seems possible, like memory bound to NUMA nodes.</p>
<p>With persistent memory only word-sized stores are atomic, hence the choice of shared memory as an array of words. <a class="reference external" href="https://stackoverflow.com/questions/46721075/can-modern-x86-hardware-not-store-a-single-byte-to-memory">https://stackoverflow.com/questions/46721075/can-modern-x86-hardware-not-store-a-single-byte-to-memory</a> says that there are in fact atomic x86 load/store instructions on the byte level.</p>
<p>Memory models: The actual hardware models (x86-TSO, Armv8 whatever, etc.) seem to be the most well-specified. Whereas C++11 is broken, Java was broken, … in the sense that the described memory model was unimplementable on hardware, preventing outcomes possible in hardware, or else allowed outcomes that hardware would not (e.g. reading values out of thin air). So use the hardware models. For cross-platform programming allow checking model compatibility, i.e. that the two memory models make the program produce equivalent results,</p>
<dl class="simple">
<dt>word</dt><dd><p>An integer <code class="docutils literal notranslate"><span class="pre">i</span></code> with <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">i</span> <span class="pre">&lt;</span> <span class="pre">MAX</span></code>.</p>
</dd>
</dl>
<p>Ternary: in current computers all words are some number of bits. Most discussion of ternary uses pure ternary, but IMO words will be a mixture of trits and bits - the mixture allows approximating the magic radix e more effectively. IDK. Whatever the case, the bit/trit (digit) is the smallest unit of memory, and all other data is a string of digits.</p>
<p>Since no commercially available computers support ternary it is not worth supporting explicitly in the language. But for future-proofing, we must ensure that anytime there is a binary string, the APi can be extended to use a mixed binary/ternary string.</p>
<p>Eliminating pointers entirely is not possible. But we can minimize the lifetime of pointers in the standard library to the duration of the call, and use values / references everywhere else.</p>
</div>
<div class="section" id="pieces">
<h2>Pieces<a class="headerlink" href="#pieces" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Safe - no dangling pointers (freeing object from live set)</p></li>
<li><p>Complete - no memory leaks (never freeing object from dead set). There is also excessive memory usage, where a program continually uses ever-growing arrays, e.g. an ever-growing Game of Life configuration. But this is not something the compiler can fix. The best the compiler can do is to optimize the program to remove large objects in cases where they aren’t necessary.</p></li>
<li><p>Promptness - time from object being dead to it being freed</p></li>
<li><p>Throughput - time to execute program including memory management</p></li>
<li><p>Pause time - time spent in memory manager with all other threads locked</p></li>
</ul>
<div class="section" id="mutator">
<h3>Mutator<a class="headerlink" href="#mutator" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">src</span>&#160; <span class="pre">=</span> <span class="pre">New</span></code> - an explicit API in the language, adding to the set of ever-allocated objects <code class="docutils literal notranslate"><span class="pre">O</span></code> and allocated objects <code class="docutils literal notranslate"><span class="pre">A</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">val</span> <span class="pre">=</span> <span class="pre">Read</span> <span class="pre">src</span></code> - reading the value of a cell</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Write</span> <span class="pre">src</span> <span class="pre">val</span></code> - changing the value of a cell. The unpack function may also change but it’s a constant-sized function pointer so can be stored easily.</p></li>
<li><p>Roots - objects with easily accessible references</p></li>
<li><p>Live objects will be accessed after the current state, <code class="docutils literal notranslate"><span class="pre">z</span> <span class="pre">in</span> <span class="pre">A</span> <span class="pre">and</span> <span class="pre">Access(s,z)</span> <span class="pre">=</span> <span class="pre">yes</span></code></p></li>
</ul>
</div>
<div class="section" id="collector">
<h3>Collector<a class="headerlink" href="#collector" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Deallocation/reclamantion - removing an object <code class="docutils literal notranslate"><span class="pre">o</span> <span class="pre">in</span> <span class="pre">O</span></code> from <code class="docutils literal notranslate"><span class="pre">A</span></code></p></li>
<li><p>A dead object is not live, <code class="docutils literal notranslate"><span class="pre">z</span> <span class="pre">in</span> <span class="pre">O</span> <span class="pre">and</span> <span class="pre">(Access(s,z)</span> <span class="pre">=</span> <span class="pre">no</span> <span class="pre">or</span> <span class="pre">z</span> <span class="pre">notin</span> <span class="pre">A)</span></code>.</p></li>
<li><p>A freed object is in <code class="docutils literal notranslate"><span class="pre">O</span> <span class="pre">\</span> <span class="pre">A</span></code></p></li>
<li><p>Dead reachable objects are called cruft.</p></li>
<li><p>Unreachable but not freed objects are called floating garbage.</p></li>
<li><p>Mark-sweep: mark all reachable objects as live, free all unreachable objects</p></li>
</ul>
<div class="graphviz"><object data="../_images/graphviz-94e6e279c6a240443df0d2eb24d274170380c6cf.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph G {
  black [fillcolor=black,fontcolor=white,style=filled,label=&quot;Presumed live&quot;]
  grey [fillcolor=grey22,fontcolor=white,style=filled,label=&quot;grey&quot;]
  white [label=&quot;Possibly dead&quot;]

  initial -&gt; white
  white -&gt; grey [label=&quot;mark push&quot;]
  grey -&gt; black [label=&quot;mark pop&quot;]
  white -&gt; dead [label=&quot;sweep&quot;]
  black -&gt; white [label=&quot;sweep&quot;]
}</p></object></div>
</div>
<div class="section" id="id5">
<h3>Allocator<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>allocate - reserves the underlying memory storage for an object</p></li>
<li><p>free - returns that storage to the allocator for subsequent re-use</p></li>
</ul>
<p>free list, buddy system, bump pointer, mmap/munmap</p>
<p>garbage collection</p>
<ul class="simple">
<li><p>pauses</p></li>
<li><p>bandwidth for tracing</p></li>
<li><p>design complexity</p></li>
<li><p>simple user code</p></li>
</ul>
<dl class="simple">
<dt>Root set</dt><dd><p>Any object references in the local variables and stack of any stack frame and any object references in the global object.</p>
</dd>
</dl>
<p>RC: count for reference</p>
<p>The count is changed when:</p>
<blockquote>
<div><p>When object first created it has one reference count
When any other variable is assigned a reference to that object, the object’s count is incremented.
When object reference does exit the current scope or assigned to the new value its reference count is decreased by one
when some object has zero reference count it is considered dead and object is instantly freed.
When an object is garbage collected, any objects that it refers to have their reference counts decremented.</p>
<p>does not detect cycles: two or more objects that refer to each other. An simple example of cycle in JS code:</p>
</div></blockquote>
<p>o = ref {} // count of object is 1
f := unpack o; // count of object is 2
o = null; // reference count of object is 1</p>
<p>mark &amp; sweep - reachable/unreachable objects</p>
<p>moving - move reachable object, updating all references to object</p>
<p>semi-space: objects are allocated in “to space” until it becomes full, then “to space” becomes the “from space”, and vice versa. reachable objects moved from the “from space” to the “to space”. new objects are once again allocated in the “to space” until it is once again full and the process is repeated.</p>
<p>requires 2x address space, lots of copying</p>
<p>Mark-compact: relocates reachable objects towards the beginning of the heap area. can be sliding, arbitrary, or optimize for locality</p>
<p>lazy sweep: when allocate memory and free list is empty, allocator
sweeps unsweeped chunk of memory.</p>
<p>generations: two or more sub-heaps, “generations” of objects. objects allocated to youngest, swept often. promoted to the next generation once sufficient sweep count. Each progressively older generation is swept less often than the next younger generation.</p>
<ol class="arabic simple">
<li><p>Write barrier: catch writes of new objects to already marked objects.</p></li>
</ol>
<dl class="simple">
<dt>function writeBarrier(object,field) {</dt><dd><dl class="simple">
<dt>if (isMarked(object) &amp;&amp; isNotMarked(field))</dt><dd><p>gcMark(field); // mark new field</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
<ol class="arabic simple" start="2">
<li><p>Read barriers: Read barriers are used when collector is moving. They help to get correct reference to the object when collection is running:</p></li>
</ol>
<dl class="simple">
<dt>function readBarrier(object) {</dt><dd><p>// if gc moved object we return new location of it
if (moved(object)) return newLocationOf(object);
return object;</p>
</dd>
</dl>
<p>}</p>
<p>Concurrent/incremental GC:
interleave program and GC, GC on separate thread</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="Assembly.html" class="btn btn-neutral float-right" title="Assembly" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="Compiler.html" class="btn btn-neutral float-left" title="Compiler design" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2019-2020 Mathnerd314.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>