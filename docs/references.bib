
@article{abramskyGeometryInteractionLinear2002,
  title = {Geometry of Interaction and Linear Combinatory Algebras.},
  author = {Abramsky, Samson and Haghverdi, Esfandiar and Scott, Philip},
  year = {2002},
  month = oct,
  journal = {Mathematical Structures in Computer Science},
  volume = {12},
  pages = {625--665},
  doi = {10.1017/S0960129502003730},
  url = {https://www.researchgate.net/profile/Samson_Abramsky/publication/220173613_Geometry_of_Interaction_and_Linear_Combinatory_Algebras/links/0c96052560eec33e21000000/Geometry-of-Interaction-and-Linear-Combinatory-Algebras.pdf},
  abstract = {this paper was quite di\#erent, stemming from the axiomatics of categories of tangles (although the authors were aware of possible connections to iteration theories. In fact, similar axiomatics in the symmetric case, motivated by flowcharts and "flownomials" had been developed some years earlier by Stefanescu (Stefanescu 2000).) However, the first author realized, following a stimulating discussion with Gordon Plotkin, that traced monoidal categories provided a common denominator for the axiomatics of both the Girard-style and Abramsky-Jagadeesan-style versions of the Geometry of Interaction, at the basic level of the multiplicatives. This insight was presented in (Abramsky 1996), in which Girard-style GoI was dubbed "particle-style", since it concerns information particles or tokens flowing around a network, while the Abramsky-Jagadeesan style GoI was dubbed "wave-style", since it concerns the evolution of a global information state or "wave". Formally, this distinction is based on whether the tensor product (i.e. the symmetric monoidal structure) in the underlying category is interpreted as a coproduct (particle style) or as a product (wave style). This computational distinction between coproduct and product interpretations of the same underlying network geometry turned out to have been partially anticipated, in a rather di\#erent context, in a pioneering paper by E. S. Bainbridge (Bainbridge 1976), as observed by Dusko Pavlovic. These two forms of interpretation, and ways of combining them, have also been studied recently in (Stefanescu 2000). He uses the terminology "additive" for coproduct-based (i.e. our "particle-style") and "multiplicative" for product-based (i.e. our "wave-style"); this is not suitable for our purposes, because of the clash with Linear Logic term...}
}
% == BibTeX quality report for abramskyGeometryInteractionLinear2002:
% ? unused Library catalog ("ResearchGate")

@incollection{abrusciNoncommutativeProofNets1995,
  title = {Noncommutative Proof Nets},
  booktitle = {Advances in {{Linear Logic}}},
  author = {Abrusci, V. M.},
  editor = {Girard, Jean-Yves and Regnier, Laurent and Lafont, Yves},
  year = {1995},
  series = {London {{Mathematical Society Lecture Note Series}}},
  pages = {271--296},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9780511629150.014},
  url = {https://www.cambridge.org/core/books/advances-in-linear-logic/noncommutative-proof-nets/D0811717B2F7F378AF56856575ECF891},
  urldate = {2021-03-03},
  abstract = {IntroductionThe aim of this paper is to give a purely graph-theoretical definition of noncommutative proof nets, i.e. graphs coming from proofs in MNLL (multiplicative noncommutative linear logic, the (⊗, ℘)-fragment of the one-sided sequent calculus for classical noncommutative linear logic, introduced in [Abr91]). Analogously, one of the aims of [Gir87] was to give a purely graph-theoretical definition of proof nets, i.e. graphs coming from the proofs in MLL (multiplicative linear logic, the (⊗, ℘)-fragment of the one-sided sequent calculus for classical linear logic - better, for classical commutative linear logic). - The relevance of the purely graph-theoretical definition of proof nets for the development of commutative linear logic is well-know; thus we hope the results of this paper will be useful for a similar development of noncommutative linear logic.The language for MNLL is an extension of the language for MLL, obtained simply adding, as atomic formulas, propositional letters with an arbitrary finite number of negations written after the propositional letter (linear post-negation) or before the propositional letter (linear retronegation). Every formula A of MNLL may be translated into a formula Tv(A) of MLL (simply by replacing each propositional letter with an even number of negations by the propositional letter without negations, and each propositional letter with an odd number of negations by the propositional letter with only one negation after the propositional letter).},
  isbn = {978-0-521-55961-4}
}

@article{albertResourceAnalysisDriven2019,
  title = {Resource {{Analysis}} Driven by ({{Conditional}}) {{Termination Proofs}}},
  author = {Albert, Elvira and Bofill, Miquel and Borralleras, Cristina and {Martin-Martin}, Enrique and Rubio, Albert},
  year = {2019},
  month = sep,
  journal = {Theory and Practice of Logic Programming},
  volume = {19},
  number = {5-6},
  eprint = {1907.10096},
  eprinttype = {arxiv},
  pages = {722--739},
  issn = {1471-0684, 1475-3081},
  doi = {10.1017/S1471068419000152},
  url = {http://arxiv.org/abs/1907.10096},
  urldate = {2020-06-22},
  abstract = {When programs feature a complex control flow, existing techniques for resource analysis produce cost relation systems (CRS) whose cost functions retain the complex flow of the program and, consequently, might not be solvable into closed-form upper bounds. This paper presents a novel approach to resource analysis that is driven by the result of a termination analysis. The fundamental idea is that the termination proof encapsulates the flows of the program which are relevant for the cost computation so that, by driving the generation of the CRS using the termination proof, we produce a linearly-bounded CRS (LB-CRS). A LB-CRS is composed of cost functions that are guaranteed to be locally bounded by linear ranking functions and thus greatly simplify the process of CRS solving. We have built a new resource analysis tool, named MaxCore, that is guided by the VeryMax termination analyzer and uses CoFloCo and PUBS as CRS solvers. Our experimental results on the set of benchmarks from the Complexity and Termination Competition 2019 for C Integer programs show that MaxCore outperforms all other resource analysis tools. Under consideration for acceptance in TPLP.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Logic in Computer Science,Computer Science - Programming Languages}
}

@article{allenCatalogueOptimizingTransformations1971,
  title = {A Catalogue of Optimizing Transformations},
  author = {Allen, Frances E and Cocke, John},
  year = {1971},
  journal = {IBM Research Center},
  pages = {30},
  url = {https://www.clear.rice.edu/comp512/Lectures/Papers/1971-allen-catalog.pdf},
  langid = {english}
}
% == BibTeX quality report for allenCatalogueOptimizingTransformations1971:
% ? unused Library catalog ("Zotero")

@inproceedings{amorimDeclarativeSpecificationIndentation2018,
  ids = {amorimDeclarativeSpecificationIndentation2018a},
  title = {Declarative Specification of Indentation Rules: A Tooling Perspective on Parsing and Pretty-Printing Layout-Sensitive Languages},
  shorttitle = {Declarative Specification of Indentation Rules},
  booktitle = {Proceedings of the 11th {{ACM SIGPLAN International Conference}} on {{Software Language Engineering}}  - {{SLE}} 2018},
  author = {Amorim, Luís Eduardo de Souza and Steindorfer, Michael J. and Erdweg, Sebastian and Visser, Eelco},
  year = {2018},
  pages = {3--15},
  publisher = {{ACM Press}},
  address = {{Boston, MA, USA}},
  doi = {10.1145/3276604.3276607},
  url = {http://udesou.info/wp-content/uploads/2018/10/layout-pp.pdf},
  urldate = {2020-06-15},
  abstract = {In layout-sensitive languages, the indentation of an expression or statement can influence how a program is parsed. While some of these languages (e.g., Haskell and Python) have been widely adopted, there is little support for software language engineers in building tools for layout-sensitive languages. As a result, parsers, pretty-printers, program analyses, and refactoring tools often need to be handwritten, which decreases the maintainability and extensibility of these tools. Even state-of-the-art language workbenches have little support for layout-sensitive languages, restricting the development and prototyping of such languages. In this paper, we introduce a novel approach to declarative specification of layout-sensitive languages using layout declarations. Layout declarations are high-level specifications of indentation rules that abstract from low-level technicalities. We show how to derive an efficient layout-sensitive generalized parser and a corresponding pretty-printer automatically from a language specification with layout declarations. We validate our approach in a case-study using a syntax definition for the Haskell programming language, investigating the performance of the generated parser and the correctness of the generated pretty-printer against 22191 Haskell files.},
  isbn = {978-1-4503-6029-6},
  langid = {english}
}
% == BibTeX quality report for amorimDeclarativeSpecificationIndentation2018:
% ? unused Conference name ("the 11th ACM SIGPLAN International Conference")
% ? unused Library catalog ("DOI.org (Crossref)")

@inproceedings{ananthanarayananKeepingMasterGreen2019,
  title = {Keeping Master Green at Scale},
  booktitle = {Proceedings of the {{Fourteenth EuroSys Conference}} 2019},
  author = {Ananthanarayanan, Sundaram and Ardekani, Masoud Saeida and Haenikel, Denis and Varadarajan, Balaji and Soriano, Simon and Patel, Dhaval and {Adl-Tabatabai}, Ali-Reza},
  year = {2019},
  month = mar,
  series = {{{EuroSys}} '19},
  pages = {1--15},
  publisher = {{Association for Computing Machinery}},
  address = {{Dresden, Germany}},
  doi = {10.1145/3302424.3303970},
  url = {https://doi.org/10.1145/3302424.3303970},
  urldate = {2020-07-06},
  abstract = {Giant monolithic source-code repositories are one of the fundamental pillars of the back end infrastructure in large and fast-paced software companies. The sheer volume of everyday code changes demands a reliable and efficient change management system with three uncompromisable key requirements --- always green master, high throughput, and low commit turnaround time. Green refers to a master branch that always successfully compiles and passes all build steps, the opposite being red. A broken master (red) leads to delayed feature rollouts because a faulty code commit needs to be detected and rolled backed. Additionally, a red master has a cascading effect that hampers developer productivity--- developers might face local test/build failures, or might end up working on a codebase that will eventually be rolled back. This paper presents the design and implementation of SubmitQueue. It guarantees an always green master branch at scale: all build steps (e.g., compilation, unit tests, UI tests) successfully execute for every commit point. SubmitQueue has been in production for over a year, and can scale to thousands of daily commits to giant monolithic repositories.},
  isbn = {978-1-4503-6281-8}
}
% == BibTeX quality report for ananthanarayananKeepingMasterGreen2019:
% ? unused Library catalog ("ACM Digital Library")

@article{appelGarbageCollectionCan1987,
  title = {Garbage Collection Can Be Faster than Stack Allocation},
  author = {Appel, Andrew W.},
  year = {1987},
  month = jun,
  journal = {Information Processing Letters},
  volume = {25},
  number = {4},
  pages = {275--279},
  issn = {00200190},
  doi = {10.1016/0020-0190(87)90175-X},
  url = {https://www.cs.princeton.edu/~appel/papers/45.pdf},
  urldate = {2020-07-24},
  abstract = {A very old and simple algorithm for garbage collection gives very good results when the physical memory is much larger than the number of reachable cells. In fact, the overhead associated with allocating and collecting cells from the heap can be reduced to less than one instruction per cell by increasing the size of physical memory. Special hardware, intricate garbage-collection algorithms, and fancy compiler analysis become unnecessary.},
  langid = {english}
}
% == BibTeX quality report for appelGarbageCollectionCan1987:
% ? unused Library catalog ("DOI.org (Crossref)")

@book{aspertiOptimalImplementationFunctional1999,
  title = {The Optimal Implementation of Functional Programming Languages},
  author = {Asperti, Andrea and Guerrini, Stefano},
  year = {1999},
  month = jan,
  series = {Cambridge {{Tracts}} in {{Theoretical Computer Science}}},
  edition = {1st},
  number = {45},
  publisher = {{Cambridge University Press}},
  address = {{USA}},
  abstract = {All traditional implementation techniques for functional languages fail to avoid useless repetition of work. They are not "optimal" in their implementation of sharing, often causing a catastrophic, exponential explosion in reduction time. Optimal reduction is an innovative graph reduction technique for functional expressions, introduced by Lamping in 1990, that solves the sharing problem. This work, the first on the subject, is a comprehensive account by two of its leading exponents. Practical implementation aspects are fully covered as are the mathematical underpinnings of the subject. The relationship to the pioneering work of L\&\#233;vy and to Girard's more recent "Geometry of Interaction" are explored; optimal reduction is thereby revealed as a prime example of how a beautiful mathematical theory can lead to practical benefit. The book is essentially self-contained, requiring no more than basic familiarity with functional languages. It will be welcomed by graduate students and research workers in lambda calculus, functional programming or linear logic.},
  isbn = {978-0-521-62112-0}
}
% == BibTeX quality report for aspertiOptimalImplementationFunctional1999:
% ? unused Library catalog ("ACM Digital Library")
% ? unused Number of pages ("408")

@article{beckerWhatDoesSaying2021,
  title = {What Does Saying That 'programming Is Hard' Really Say, and about Whom?},
  author = {Becker, Brett A.},
  year = {2021},
  month = aug,
  journal = {Communications of the ACM},
  volume = {64},
  number = {8},
  pages = {27--29},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3469115},
  url = {https://cacm.acm.org/magazines/2021/8/254304-what-does-saying-that-programming-is-hard-really-say-and-about-whom/fulltext},
  urldate = {2021-08-28},
  abstract = {Shifting the focus from the perceived difficulty of learning programming to making programming more universally accessible.},
  langid = {english}
}
% == BibTeX quality report for beckerWhatDoesSaying2021:
% ? unused Journal abbreviation ("Commun. ACM")
% ? unused Library catalog ("DOI.org (Crossref)")

@misc{ben-amramNotesPippengerComparison1996,
  title = {Notes on {{Pippenger}}'s {{Comparison}} of {{Pure}} and {{Impure LISP}}},
  author = {{Ben-amram}, Amir M.},
  year = {1996},
  abstract = {any impure-LISP program running in time t can be compiled into a pure-LISP program running in time O(t log t): first implement the impure-LISP operations using an array of size at most t. Then represent the array as a balanced binary tree, which can be done in pure LISP. The main result of the paper is a lower-bound theorem. It can roughly be described as follows. A problem P is presented, that can be solved in linear time, t = O(n), in impure  LISP. It is proved that for any pure-LISP program p for P , the worst-case time complexity is \textbackslash Omega\textbackslash Gamma n log n). 2 Restrictions of the Proof and Open Problems  The lower-bound result requires two restrictive assumptions. We first describe the restrictions and their technical implications. Next, we discuss the two questions that}
}
% == BibTeX quality report for ben-amramNotesPippengerComparison1996:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("CiteSeer")

@inproceedings{bhatotiaIThreadsThreadingLibrary2015,
  title = {{{iThreads}}: {{A Threading Library}} for {{Parallel Incremental Computation}}},
  shorttitle = {{{iThreads}}},
  booktitle = {Proceedings of the {{Twentieth International Conference}} on {{Architectural Support}} for {{Programming Languages}} and {{Operating Systems}} - {{ASPLOS}} '15},
  author = {Bhatotia, Pramod and Fonseca, Pedro and Acar, Umut A. and Brandenburg, Björn B. and Rodrigues, Rodrigo},
  year = {2015},
  pages = {645--659},
  publisher = {{ACM Press}},
  address = {{Istanbul, Turkey}},
  doi = {10.1145/2694344.2694371},
  url = {https://www.cs.purdue.edu/homes/pfonseca/papers/asplos2015-ithreads.pdf},
  urldate = {2020-10-25},
  isbn = {978-1-4503-2835-7},
  langid = {english}
}
% == BibTeX quality report for bhatotiaIThreadsThreadingLibrary2015:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Conference name ("the Twentieth International Conference")
% ? unused Library catalog ("DOI.org (Crossref)")

@article{birdMoreHasteLess1997,
  title = {More Haste, Less Speed: Lazy versus Eager Evaluation},
  shorttitle = {More Haste, Less Speed},
  author = {Bird, Richard and Jones, Geraint and Moor, Oege De},
  year = {1997},
  month = sep,
  journal = {Journal of Functional Programming},
  volume = {7},
  number = {5},
  pages = {541--547},
  publisher = {{Cambridge University Press}},
  issn = {1469-7653, 0956-7968},
  doi = {10.1017/S0956796897002827},
  url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/more-haste-less-speed-lazy-versus-eager-evaluation/162B391CBCD864794C766CA2A2EC7CBE},
  urldate = {2022-01-06},
  abstract = {Nicholas Pippenger has recently given a problem that, under two simple restrictions, can be solved in linear time by an impure Lisp program, but requires Ω(n log n) steps to be solved by any eager pure Lisp program. By showing how to solve the problem in linear time with a lazy functional program, we demonstrate that – for some problems at least – lazy evaluators are strictly more powerful than eager ones.},
  langid = {english}
}

@inproceedings{bolingbrokeSupercompilationEvaluation2010,
  title = {Supercompilation by Evaluation},
  booktitle = {Proceedings of the Third {{ACM Haskell}} Symposium on {{Haskell}}},
  author = {Bolingbroke, Maximilian and Peyton Jones, Simon},
  year = {2010},
  month = sep,
  series = {Haskell '10},
  pages = {135--146},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1863523.1863540},
  url = {https://www.microsoft.com/en-us/research/publication/supercompilation-by-evaluation/},
  urldate = {2021-03-24},
  abstract = {This paper shows how call-by-need supercompilation can be recast to be based explicitly on an evaluator, contrasting with standard presentations which are specified as algorithms that mix evaluation rules with reductions that are unique to supercompilation. Building on standard operational-semantics technology for call-by-need languages, we show how to extend the supercompilation algorithm to deal with recursive let expressions.},
  isbn = {978-1-4503-0252-4},
  langid = {american},
  keywords = {deforestation,haskell,optimisation,specialisation,supercompilation}
}
% == BibTeX quality report for bolingbrokeSupercompilationEvaluation2010:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("ACM Digital Library")

@article{brausseCDCLstyleCalculusSolving2019,
  title = {A {{CDCL-style}} Calculus for Solving Non-Linear Constraints},
  author = {Brauße, Franz and Korovin, Konstantin and Korovina, Margarita and Müller, Norbert Th},
  year = {2019},
  month = jul,
  journal = {arXiv:1905.09227 [cs]},
  eprint = {1905.09227},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1905.09227},
  urldate = {2020-07-25},
  abstract = {In this paper we propose a novel approach for checking satisfiability of non-linear constraints over the reals, called ksmt. The procedure is based on conflict resolution in CDCL-style calculus, using a composition of symbolical and numerical methods. To deal with the nonlinear components in case of conflicts we use numerically constructed restricted linearisations. This approach covers a large number of computable non-linear real functions such as polynomials, rational or trigonometrical functions and beyond. A prototypical implementation has been evaluated on several non-linear SMT-LIB examples and the results have been compared with state-of-the-art SMT solvers.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Logic in Computer Science}
}
% == BibTeX quality report for brausseCDCLstyleCalculusSolving2019:
% ? Possibly abbreviated journal title arXiv:1905.09227 [cs]

@article{castagnaCovarianceControvarianceFresh2020,
  title = {Covariance and {{Controvariance}}: A Fresh Look at an Old Issue (a Primer in Advanced Type Systems for Learning Functional Programmers)},
  shorttitle = {Covariance and {{Controvariance}}},
  author = {Castagna, Giuseppe},
  year = {2020},
  month = feb,
  journal = {arXiv:1809.01427 [cs]},
  volume = {16},
  number = {1},
  eprint = {1809.01427},
  eprinttype = {arxiv},
  primaryclass = {cs},
  doi = {10.23638/LMCS-16(1:15)2020},
  url = {http://arxiv.org/abs/1809.01427},
  urldate = {2020-06-22},
  abstract = {Twenty years ago, in an article titled "Covariance and contravariance: conflict without a cause", I argued that covariant and contravariant specialization of method parameters in object-oriented programming had different purposes and deduced that, not only they could, but actually they should both coexist in the same language. In this work I reexamine the result of that article in the light of recent advances in (sub-)typing theory and programming languages, taking a fresh look at this old issue. Actually, the revamping of this problem is just an excuse for writing an essay that aims at explaining sophisticated type-theoretic concepts, in simple terms and by examples, to undergraduate computer science students and/or willing functional programmers. Finally, I took advantage of this opportunity to describe some undocumented advanced techniques of type-systems implementation that are known only to few insiders that dug in the code of some compilers: therefore, even expert language designers and implementers may find this work worth of reading.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Programming Languages}
}
% == BibTeX quality report for castagnaCovarianceControvarianceFresh2020:
% ? Possibly abbreviated journal title arXiv:1809.01427 [cs]

@article{chenComputationalInterpretationCompact2021,
  title = {A Computational Interpretation of Compact Closed Categories: Reversible Programming with Negative and Fractional Types},
  shorttitle = {A Computational Interpretation of Compact Closed Categories},
  author = {Chen, Chao-Hong and Sabry, Amr},
  year = {2021},
  month = jan,
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {5},
  number = {POPL},
  pages = {1--29},
  issn = {2475-1421},
  doi = {10.1145/3434290},
  url = {https://dl.acm.org/doi/10.1145/3434290},
  urldate = {2021-08-04},
  abstract = {CHAO-HONG CHEN, Indiana University, USA AMR SABRY, Indiana University, USA Compact closed categories include objects representing higher-order functions and are well-established as models of linear logic, concurrency, and quantum computing. We show that it is possible to construct such compact closed categories for conventional sum and product types by defining a dual to sum types, a negative type, and a dual to product types, a fractional type. Inspired by the categorical semantics, we define a sound operational semantics for negative and fractional types in which a negative type represents a computational effect that “reverses execution flow” and a fractional type represents a computational effect that “garbage collects” particular values or throws exceptions. Specifically, we extend a first-order reversible language of type isomorphisms with negative and fractional types, specify an operational semantics for each extension, and prove that each extension forms a compact closed category. We furthermore show that both operational semantics can be merged using the standard combination of backtracking and exceptions resulting in a smooth interoperability of negative and fractional types. We illustrate the expressiveness of this combination by writing a reversible SAT solver that uses backtracking search along freshly allocated and de-allocated locations. The operational semantics, most of its meta-theoretic properties, and all examples are formalized in a supplementary Agda package. CCS Concepts: • Theory of computation → Type theory; Abstract machines; Operational semantics.},
  langid = {english}
}
% == BibTeX quality report for chenComputationalInterpretationCompact2021:
% ? unused Journal abbreviation ("Proc. ACM Program. Lang.")
% ? unused Library catalog ("DOI.org (Crossref)")

@article{coniglioEqualityLinearLogic2002,
  ids = {coniglioEQUALITYLINEARLOGIC1996},
  title = {Equality in Linear Logic},
  author = {Coniglio, Marcelo and Miraglia, Francisco},
  year = {2002},
  month = jan,
  journal = {Logique et Analyse},
  volume = {39},
  number = {153/154},
  pages = {113--151},
  publisher = {{Peeters Publishers}},
  issn = {0024-5836},
  url = {https://www.researchgate.net/profile/Marcelo-Coniglio/publication/2387274_Equality_In_Linear_Logic/links/0deec5165a6babbd8a000000/Equality-In-Linear-Logic.pdf},
  abstract = {reference is [Ros]). Quantales were introduced by Mulvey ([Mul]) as an algebraic tool for studying representations of non-commutative C -algebras. Informally, a quantale is a complete lattice Q equipped with a product distributive over arbitrary sup's. The importance of quantales for Linear Logic is revealed in Yetter's work ([Yet]), who proved that semantics of classical linear logic is given by a class of quantales, named Girard quantales, which coincides with Girard's phase semantics. An analogous result is obtained for a sort of non-commutative linear logic, as well as intuitionistic linear logic without negation, which suggest that the utilisation of the theory of quantales (or even weaker structures, such that *-autonomous posets) might be fruitful in studying the semantic of several variants of linear logic. As usual, we denote the order in a lattice by , while W and V denote the operatio}
}
% == BibTeX quality report for coniglioEqualityLinearLogic2002:
% ? unused Library catalog ("JSTOR")

@phdthesis{corbynPracticalStaticMemory2020,
  type = {Bachelor's Thesis},
  title = {Practical Static Memory Management},
  author = {Corbyn, Nathan},
  year = {2020},
  month = may,
  url = {http://nathancorbyn.com/nc513.pdf},
  langid = {english},
  school = {King’s College}
}
% == BibTeX quality report for corbynPracticalStaticMemory2020:
% ? unused Library catalog ("Zotero")
% ? unused Number of pages ("57")

@misc{coxVersionSAT2016,
  title = {Version {{SAT}}},
  author = {Cox, Russ},
  year = {2016},
  month = dec,
  journal = {research!rsc},
  url = {https://research.swtch.com/version-sat},
  urldate = {2021-01-26}
}
% == BibTeX quality report for coxVersionSAT2016:
% ? Title looks like it was stored in title-case in Zotero

@article{crolardFormulaeastypesInterpretationSubtractive2004,
  title = {A Formulae-as-Types Interpretation of Subtractive Logic},
  author = {Crolard, Tristan},
  year = {2004},
  month = aug,
  journal = {Journal of Logic and Computation},
  volume = {14},
  number = {4},
  pages = {529--570},
  publisher = {{Oxford Academic}},
  issn = {0955-792X},
  doi = {10.1093/logcom/14.4.529},
  url = {https://academic.oup.com/logcom/article/14/4/529/933555},
  urldate = {2020-06-18},
  abstract = {Abstract.  We present a formulae-as-types interpretation of Subtractive Logic (i.e. bi-intuitionistic logic). This presentation is two-fold: we first define a v},
  langid = {english}
}
% == BibTeX quality report for crolardFormulaeastypesInterpretationSubtractive2004:
% ? unused Journal abbreviation ("J Logic Computation")
% ? unused Library catalog ("academic.oup.com")

@article{delawareNarcissusCorrectbyconstructionDerivation2019,
  title = {Narcissus: Correct-by-Construction Derivation of Decoders and Encoders from Binary Formats},
  shorttitle = {Narcissus},
  author = {Delaware, Benjamin and Suriyakarn, Sorawit and {Pit-Claudel}, Clément and Ye, Qianchuan and Chlipala, Adam},
  year = {2019},
  month = jul,
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {3},
  number = {ICFP},
  pages = {1--29},
  issn = {2475-1421, 2475-1421},
  doi = {10.1145/3341686},
  url = {https://www.cs.purdue.edu/homes/bendy/Narcissus/narcissus.pdf},
  urldate = {2020-07-26},
  langid = {english}
}
% == BibTeX quality report for delawareNarcissusCorrectbyconstructionDerivation2019:
% ? unused Journal abbreviation ("Proc. ACM Program. Lang.")
% ? unused Library catalog ("DOI.org (Crossref)")

@incollection{dershowitzRewriteSystems1991,
  title = {Rewrite Systems},
  booktitle = {Handbook of Theoretical Computer Science (Vol. {{B}}): Formal Models and Semantics},
  author = {Dershowitz, Nachum and Jouannaud, Jean-Pierre},
  year = {1991},
  month = jan,
  pages = {243--320},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA, USA}},
  isbn = {978-0-444-88074-1}
}
% == BibTeX quality report for dershowitzRewriteSystems1991:
% ? unused Library catalog ("ACM Digital Library")

@book{dicosmoIntroductionLinearLogic2015,
  title = {Introduction to Linear Logic},
  author = {Di Cosmo, Roberto},
  year = {2015},
  publisher = {{MPRI course notes}},
  url = {https://www.dicosmo.org/CourseNotes/LinLog/IntroductionLinearLogic.pdf},
  urldate = {2020-05-13}
}
% == BibTeX quality report for dicosmoIntroductionLinearLogic2015:
% ? unused Number of pages ("86")

@phdthesis{dolanAlgebraicSubtyping2016,
  title = {Algebraic Subtyping},
  author = {Dolan, Stephen},
  year = {2016},
  month = sep,
  url = {https://www.cs.tufts.edu/~nr/cs257/archive/stephen-dolan/thesis.pdf},
  abstract = {Type inference gives programmers the benefit of static, compile-time type checking without the cost of manually specifying types, and has long been a standard feature of functional programming languages. However, it has proven difficult to integrate type inference with subtyping, since the unification engine at the core of classical type inference accepts only equations, not subtyping constraints.},
  langid = {english},
  school = {University of Cambridge}
}
% == BibTeX quality report for dolanAlgebraicSubtyping2016:
% ? unused Library catalog ("Zotero")
% ? unused Number of pages ("157")

@inproceedings{dolanPolymorphismSubtypingType2017,
  title = {Polymorphism, Subtyping, and Type Inference in {{MLsub}}},
  booktitle = {Proceedings of the 44th {{ACM SIGPLAN Symposium}} on {{Principles}} of {{Programming Languages}}},
  author = {Dolan, Stephen and Mycroft, Alan},
  year = {2017},
  month = jan,
  series = {{{POPL}} 2017},
  pages = {60--72},
  publisher = {{Association for Computing Machinery}},
  address = {{Paris, France}},
  doi = {10.1145/3009837.3009882},
  url = {https://doi.org/10.1145/3009837.3009882},
  urldate = {2020-06-15},
  abstract = {We present a type system combining subtyping and ML-style parametric polymorphism. Unlike previous work, our system supports type inference and has compact principal types. We demonstrate this system in the minimal language MLsub, which types a strict superset of core ML programs. This is made possible by keeping a strict separation between the types used to describe inputs and those used to describe outputs, and extending the classical unification algorithm to handle subtyping constraints between these input and output types. Principal types are kept compact by type simplification, which exploits deep connections between subtyping and the algebra of regular languages. An implementation is available online.},
  isbn = {978-1-4503-4660-3},
  keywords = {Algebra,Polymorphism,Subtyping,Type Inference}
}
% == BibTeX quality report for dolanPolymorphismSubtypingType2017:
% ? unused Library catalog ("ACM Digital Library")

@inproceedings{downenMakingFasterCurry2019,
  title = {Making a Faster Curry with Extensional Types},
  booktitle = {Proceedings of the 12th {{ACM SIGPLAN International Symposium}} on {{Haskell}}},
  author = {Downen, Paul and Sullivan, Zachary and Ariola, Zena M. and Peyton Jones, Simon},
  year = {2019},
  month = aug,
  series = {Haskell 2019},
  pages = {58--70},
  publisher = {{Association for Computing Machinery}},
  address = {{Berlin, Germany}},
  doi = {10.1145/3331545.3342594},
  url = {https://doi.org/10.1145/3331545.3342594},
  urldate = {2020-06-14},
  abstract = {Curried functions apparently take one argument at a time, which is slow. So optimizing compilers for higher-order languages invariably have some mechanism for working around currying by passing several arguments at once, as many as the function can handle, which is known as its arity. But such mechanisms are often ad-hoc, and do not work at all in higher-order functions. We show how extensional, call-by-name functions have the correct behavior for directly expressing the arity of curried functions. And these extensional functions can stand side-by-side with functions native to practical programming languages, which do not use call-by-name evaluation. Integrating call-by-name with other evaluation strategies in the same intermediate language expresses the arity of a function in its type and gives a principled and compositional account of multi-argument curried functions. An unexpected, but significant, bonus is that our approach is equally suitable for a call-by-value language and a call-by-need language, and it can be readily integrated into an existing compilation framework.},
  isbn = {978-1-4503-6813-1},
  keywords = {arity,extensionality,type systems}
}
% == BibTeX quality report for downenMakingFasterCurry2019:
% ? unused Library catalog ("ACM Digital Library")

@inproceedings{downenSequentCalculusCompiler2016,
  ids = {downenSequentCalculusCompiler},
  title = {Sequent Calculus as a Compiler Intermediate Language},
  booktitle = {Proceedings of the 21st {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  author = {Downen, Paul and Maurer, Luke and Ariola, Zena M. and Peyton Jones, Simon},
  year = {2016},
  month = sep,
  series = {{{ICFP}} 2016},
  pages = {74--88},
  publisher = {{Association for Computing Machinery}},
  address = {{Nara, Japan}},
  doi = {10.1145/2951913.2951931},
  url = {https://www.microsoft.com/en-us/research/publication/sequent-calculus-as-a-compiler-intermediate-language/},
  urldate = {2020-06-14},
  abstract = {The λ-calculus is popular as an intermediate language for practical compilers. But in the world of logic it has a lesser-known twin, born at the same time, called the sequent calculus. Perhaps that would make for a good intermediate language, too? To explore this question we designed Sequent Core, a practically-oriented core calculus based on the sequent calculus, and used it to re-implement a substantial chunk of the Glasgow Haskell Compiler.},
  isbn = {978-1-4503-4219-3},
  keywords = {Compiler optimizations,Continuations,Haskell,Intermediate representations,Natural deduction,Sequent calculus}
}
% == BibTeX quality report for downenSequentCalculusCompiler2016:
% ? unused Library catalog ("ACM Digital Library")

@inproceedings{dsilvaConflictdrivenConditionalTermination2015,
  title = {Conflict-Driven Conditional Termination},
  booktitle = {Computer Aided Verification},
  author = {D’Silva, Vijay and Urban, Caterina},
  editor = {Kroening, Daniel and Păsăreanu, Corina S.},
  year = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {271--286},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-21668-3_16},
  url = {http://homepages.inf.ed.ac.uk/wadler/papers/dual/dual.pdf},
  abstract = {Conflict-driven learning, which is essential to the performance of sat and smt solvers, consists of a procedure that searches for a model of a formula, and refutation procedure for proving that no model exists. This paper shows that conflict-driven learning can improve the precision of a termination analysis based on abstract interpretation. We encode non-termination as satisfiability in a monadic second-order logic and use abstract interpreters to reason about the satisfiability of this formula. Our search procedure combines decisions with reachability analysis to find potentially non-terminating executions and our refutation procedure uses a conditional termination analysis. Our implementation extends the set of conditional termination arguments discovered by an existing termination analyzer.},
  isbn = {978-3-319-21668-3},
  langid = {english},
  keywords = {Abstract Domain,Conflict Analysis,Ranking Function,Reachability Analysis,Trace Formula}
}
% == BibTeX quality report for dsilvaConflictdrivenConditionalTermination2015:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("Springer Link")

@article{dunfieldBidirectionalTyping2019,
  title = {Bidirectional Typing},
  author = {Dunfield, Joshua and Krishnaswami, Neel},
  year = {2019},
  month = aug,
  journal = {arXiv:1908.05839 [cs]},
  eprint = {1908.05839},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1908.05839},
  urldate = {2020-06-22},
  abstract = {Bidirectional typing combines two modes of typing: type checking, which checks that a program satisfies a known type, and type synthesis, which determines a type from the program. Using checking enables bidirectional typing to break the decidability barrier of Damas-Milner approaches; using synthesis enables bidirectional typing to avoid the large annotation burden of explicitly typed languages. In addition, bidirectional typing improves error locality. We highlight the design principles that underlie bidirectional type systems, survey the development of bidirectional typing from the prehistoric period before Pierce and Turner's local type inference to the present day, and provide guidance for future investigations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Logic in Computer Science,Computer Science - Programming Languages}
}
% == BibTeX quality report for dunfieldBidirectionalTyping2019:
% ? Possibly abbreviated journal title arXiv:1908.05839 [cs]

@article{dyvbigMonadicFrameworkDelimited2007,
  ids = {dyvbigMonadicFrameworkDelimited2007a},
  title = {A Monadic Framework for Delimited Continuations},
  author = {Dyvbig, R. Kent and Peyton Jones, Simon and Sabry, Amr},
  year = {2007},
  month = nov,
  journal = {Journal of Functional Programming},
  volume = {17},
  number = {6},
  pages = {687--730},
  issn = {0956-7968},
  doi = {10.1017/S0956796807006259},
  url = {https://doi.org/10.1017/S0956796807006259},
  urldate = {2020-06-19},
  abstract = {Delimited continuations are more expressive than traditional abortive continuations and they apparently require a framework beyond traditional continuation-passing style (CPS). We show that this is not the case: standard CPS is sufficient to explain the common control operators for delimited continuations. We demonstrate this fact and present an implementation as a Scheme library. We then investigate a typed account of delimited continuations that makes explicit where control effects can occur. This results in a monadic framework for typed and encapsulated delimited continuations, which we design and implement as a Haskell library.}
}
% == BibTeX quality report for dyvbigMonadicFrameworkDelimited2007:
% ? unused Journal abbreviation ("J. Funct. Program.")
% ? unused Library catalog ("November 2007")

@article{eggerEnrichedEffectCalculus2014,
  title = {The Enriched Effect Calculus: Syntax and Semantics},
  shorttitle = {The Enriched Effect Calculus},
  author = {Egger, J. and Mogelberg, R. E. and Simpson, A.},
  year = {2014},
  month = jun,
  journal = {Journal of Logic and Computation},
  volume = {24},
  number = {3},
  pages = {615--654},
  issn = {0955-792X, 1465-363X},
  doi = {10.1093/logcom/exs025},
  url = {https://academic.oup.com/logcom/article-lookup/doi/10.1093/logcom/exs025},
  urldate = {2021-11-09},
  abstract = {This paper introduces the enriched effect calculus, which extends established type theories for computational effects with primitives from linear logic. The new calculus provides a formalism for expressing linear aspects of computational effects; for example, the linear usage of imperative features such as state and/or continuations.},
  langid = {english}
}
% == BibTeX quality report for eggerEnrichedEffectCalculus2014:
% ? unused Library catalog ("DOI.org (Crossref)")

@incollection{erdwegLayoutsensitiveGeneralizedParsing2013,
  title = {Layout-Sensitive Generalized Parsing},
  booktitle = {Software {{Language Engineering}}},
  author = {Erdweg, Sebastian and Rendel, Tillmann and Kästner, Christian and Ostermann, Klaus},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Czarnecki, Krzysztof and Hedin, Görel},
  year = {2013},
  volume = {7745},
  pages = {244--263},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-36089-3_14},
  url = {http://link.springer.com/10.1007/978-3-642-36089-3_14},
  urldate = {2020-06-15},
  abstract = {The theory of context-free languages is well-understood and context-free parsers can be used as off-the-shelf tools in practice. In particular, to use a context-free parser framework, a user does not need to understand its internals but can specify a language declaratively as a grammar. However, many languages in practice are not context-free. One particularly important class of such languages is layout-sensitive languages, in which the structure of code depends on indentation and whitespace. For example, Python, Haskell, F\#, and Markdown use indentation instead of curly braces to determine the block structure of code. Their parsers (and lexers) are not declaratively specified but hand-tuned to account for layout-sensitivity.},
  isbn = {978-3-642-36088-6 978-3-642-36089-3},
  langid = {english}
}
% == BibTeX quality report for erdwegLayoutsensitiveGeneralizedParsing2013:
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Series title ("Lecture Notes in Computer Science")

@inproceedings{erdwegSoundOptimalIncremental2015,
  title = {A Sound and Optimal Incremental Build System with Dynamic Dependencies},
  booktitle = {Proceedings of the 2015 {{ACM SIGPLAN International Conference}} on {{Object-Oriented Programming}}, {{Systems}}, {{Languages}}, and {{Applications}} - {{OOPSLA}} 2015},
  author = {Erdweg, Sebastian and Lichter, Moritz and Weiel, Manuel},
  year = {2015},
  pages = {89--106},
  publisher = {{ACM Press}},
  address = {{Pittsburgh, PA, USA}},
  doi = {10.1145/2814270.2814316},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.725.6063&rep=rep1&type=pdf},
  urldate = {2020-06-15},
  abstract = {Build systems are used in all but the smallest software projects to invoke the right build tools on the right files in the right order. A build system must be sound (after a build, generated files consistently reflect the latest source files) and efficient (recheck and rebuild as few build units as possible). Contemporary build systems provide limited efficiency because they lack support for expressing finegrained file dependencies. We present a build system called pluto that supports the definition of reusable, parameterized, interconnected builders. When run, a builder notifies the build system about dynamically required and produced files as well as about other builders whose results are needed. To support fine-grained file dependencies, we generalize the traditional notion of time stamps to allow builders to declare their actual requirements on a file’s content. pluto collects the requirements and products of a builder with their stamps in a build summary. This enables pluto to provides provably sound and optimal incremental rebuilding. To support dynamic dependencies, our rebuild algorithm interleaves dependency analysis and builder execution and enforces invariants on the dependency graph through a dynamic analysis. We have developed pluto as a Java API and used it to implement more than 25 builders. We describe our experience with migrating a larger Ant build script to pluto and compare the respective build times.},
  isbn = {978-1-4503-3689-5},
  langid = {english}
}
% == BibTeX quality report for erdwegSoundOptimalIncremental2015:
% ? unused Conference name ("the 2015 ACM SIGPLAN International Conference")
% ? unused Library catalog ("DOI.org (Crossref)")

@phdthesis{erkokValueRecursionMonadic2002,
  title = {Value {{Recursion}} in {{Monadic Computations}}},
  author = {Erkok, Levent},
  year = {2002},
  month = oct,
  url = {http://leventerkok.github.io/papers/erkok-thesis.pdf},
  langid = {english},
  school = {Oregon Health and Science University}
}
% == BibTeX quality report for erkokValueRecursionMonadic2002:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Archive ("10.6083/M4SQ8XBW")
% ? unused Library catalog ("Zotero")
% ? unused Number of pages ("170")

@misc{filinskiDeclarativeContinuationsCategorical1989,
  title = {Declarative {{Continuations}} and {{Categorical Duality}}},
  author = {Filinski, Andrzej},
  year = {1989},
  abstract = {This thesis presents a formalism for reasoning about continuations in a categorical setting. It points out how values and continuations ca n be seen as categorically dual concepts, and that this symmetry extends to not only data types, but also control structures, evaluation strategies and higher-order constructs. The central idea is a view of continuations as a declarative concept, rather than an imperative one, and the implicat ions of this make up the spine of the presentation. A symmetrical extension of the typed *-calculus is introduced, where values and continuations are treated as opposites, permitting a mirror-image syntax for dual categorical concepts like products and coproducts. An implementable semantic description and a static type system for this calculus are given. A purely categorical description of the language is also obtained, through a correspondence with a system of combinatory logic, similar to a cartesian closed category, but with a completely symmetrical set of axioms. Finally, a number of possible practical applications and directions for further research are suggested.}
}
% == BibTeX quality report for filinskiDeclarativeContinuationsCategorical1989:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("CiteSeer")

@inproceedings{filinskiLinearContinuations1992,
  title = {Linear Continuations},
  booktitle = {Proceedings of the 19th {{ACM SIGPLAN-SIGACT}} Symposium on {{Principles}} of Programming Languages},
  author = {Filinski, Andrzej},
  year = {1992},
  month = feb,
  series = {{{POPL}} '92},
  pages = {27--38},
  publisher = {{Association for Computing Machinery}},
  address = {{Albuquerque, New Mexico, USA}},
  doi = {10.1145/143165.143174},
  url = {https://doi.org/10.1145/143165.143174},
  urldate = {2020-06-19},
  abstract = {We present a functional interpretation of classical linear logic based on the concept of linear continuations. Unlike their non-linear counterparts, such continuations lead to a model of control that does not inherently impose any particular evaluation strategy. Instead, such additional structure is expressed by admitting closely controlled copying and discarding of continuations. We also emphasize the importance of classicality in obtaining computationally appealing categorical models of linear logic and propose a simple “coreflective subcategory” interpretation of the modality “!”.},
  isbn = {978-0-89791-453-6}
}
% == BibTeX quality report for filinskiLinearContinuations1992:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("ACM Digital Library")

@incollection{forsterQuineNewFoundations2019,
  title = {Quine’s {{New Foundations}}},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  author = {Forster, Thomas},
  editor = {Zalta, Edward N.},
  year = {2019},
  edition = {Summer 2019},
  publisher = {{Metaphysics Research Lab, Stanford University}},
  url = {https://plato.stanford.edu/archives/sum2019/entries/quine-nf/},
  urldate = {2021-03-04},
  abstract = {Quine’s system of axiomatic set theory, NF, takes its name from thetitle (“New Foundations for Mathematical Logic”) of the1937 article which introduced it (Quine [1937a]). The axioms of NF areextensionality:, together with stratified comprehension, which is to say alluniversal closures of formulæ like,  where ‘xxx’ is not free in ΦΦ\textbackslash Phi and ΦΦ\textbackslash Phi is(weakly) stratified. This last condition requires that there should bea function σσ\textbackslash sigma (a “stratification”) fromthe bound variables in ΦΦ\textbackslash Phi to an initial segmentof the natural numbers such that if ‘u∈vu∈vu \textbackslash in v’ is asubformula of ΦΦ\textbackslash Phi then σ(‘v’)=σ(‘u’)+1σ(‘v’)=σ(‘u’)+1\textbackslash sigma(`v\textbackslash rsquo) = \textbackslash sigma(`u\textbackslash rsquo) +1 and if ‘u=v’‘u=v’`u = v\textbackslash rsquo is a subformula of ΦΦ\textbackslash Phi thenσ(‘v’)=σ(‘u’)σ(‘v’)=σ(‘u’)\textbackslash sigma(`v\textbackslash rsquo) = \textbackslash sigma(`u\textbackslash rsquo). The origins of thisconstraint will be explained below., Some illustrations may help: x∈xx∈xx \textbackslash in x is not stratified. x∈yx∈yx \textbackslash iny is. Thus not every substitution-instance of a stratified formulais stratified.  y=℘(x)y=℘(x)y = \textbackslash wp(x) is stratified (the fancy P means powerset), with the variable yyy being given a type one higher than thetype given to xxx. To check this we have to write out ‘y=℘(x)y=℘(x)y =\textbackslash wp(x)’ in primitive notation. (In primitive notation, thisformula becomes: ∀z(z∈y↔∀w(w∈z→w∈x))∀z(z∈y↔∀w(w∈z→w∈x))\textbackslash forall z(z \textbackslash in y \textbackslash leftrightarrow \textbackslash forall w(w \textbackslash in z\textbackslash rightarrow w \textbackslash in x)). One can assign 0 to w,1w,1w, 1 to zzz,and 2 to xxx, to get a stratification of this formula.) In generalit is always necessary to write a formula out in primitivenotation – at least until one gets the hang of it., The observant reader will have spotted the appearance above of theexpression weakly stratified. What is this? The instance ofthe comprehension that says that x∪\{y\}x∪\{y\}x \textbackslash cup \textbackslash\{y\textbackslash\} always exists isstratified, and is therefore an axiom. So x∪\{y\}x∪\{y\}x \textbackslash cup \textbackslash\{y\textbackslash\} alwaysexists. So x∪\{x\}x∪\{x\}x \textbackslash cup \textbackslash\{x\textbackslash\} always exists, by substitution. Howeverthe instance of the comprehension scheme alleging its existence is notstratified. The term ‘x∪\{x\}x∪\{x\}x \textbackslash cup \textbackslash\{x\textbackslash\}’ is said tobe weakly stratified by which it is meant that it can bestratified if we are allowed to give different types to distinctoccurrences offree variables. Weak stratification is what is needed toadmit ab initio those instances of the comprehension schemethat give us substitution instances of stratified instances, and notrequire a detour such as the detour here through theexistence of x∪\{y\}x∪\{y\}x \textbackslash cup \textbackslash\{y\textbackslash\}.}
}
% == BibTeX quality report for forsterQuineNewFoundations2019:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Stanford Encyclopedia of Philosophy")

@inproceedings{girardGeometryInteraction1989,
  ids = {girardGeometryInteraction1989a},
  title = {Towards a Geometry of Interaction},
  booktitle = {Categories in {{Computer Science}} and {{Logic}}},
  author = {Girard, Jean-Yves},
  editor = {Gray, J. W. and Scedrov, A.},
  year = {1989},
  series = {Contemporary {{Mathematics}}},
  volume = {92},
  pages = {69--108},
  publisher = {{American Mathematical Society}},
  address = {{University of Colorado in Boulder}},
  url = {https://jb55.com/linear/pdf/Towards%20a%20geometry%20of%20interaction.pdf}
}
% == BibTeX quality report for girardGeometryInteraction1989:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("Google Scholar")

@article{girardLocusSolumRules2001,
  ids = {girardLocusSolumRules2001a},
  title = {Locus {{Solum}}: {{From}} the Rules of Logic to the Logic of Rules},
  shorttitle = {Locus {{Solum}}},
  author = {Girard, Jean-Yves},
  year = {2001},
  month = jun,
  journal = {Mathematical Structures in Computer Science},
  volume = {11},
  number = {3},
  pages = {301--506},
  publisher = {{Cambridge University Press}},
  issn = {1469-8072, 0960-1295},
  doi = {10.1017/S096012950100336X},
  url = {https://www.cambridge.org/core/journals/mathematical-structures-in-computer-science/article/abs/locus-solum-from-the-rules-of-logic-to-the-logic-of-rules/6318E18EA633F9692D9CDBA9DE4438C9},
  urldate = {2022-03-27},
  abstract = {Go back to An-fang, the Peace Square at An-Fang, the Beginning Place at An-Fang, where all things start (…) An-Fang was near a city, the only living city with a pre-atomic name (…) The headquarters of the People Programmer was at An-Fang, and there the mistake happened: A ruby trembled. Two tourmaline nets failed to rectify the laser beam. A diamond noted the error. Both the error and the correction went into the general computer. Cordwainer SmithThe Dead Lady of Clown Town, 1964.},
  langid = {english}
}

@misc{gravgaardElasticTabstopsBetter,
  title = {Elastic Tabstops - a Better Way to Indent and Align Code},
  author = {Gravgaard, Nick},
  url = {https://nickgravgaard.com/elastic-tabstops/},
  urldate = {2021-02-13},
  abstract = {Elastic tabstops - a better way to indent and align code},
  langid = {english}
}

@inproceedings{guerriniOptimalImplementationInefficient2017,
  title = {Is the Optimal Implementation Inefficient? {{Elementarily}} Not.},
  shorttitle = {Is the Optimal Implementation Inefficient?},
  booktitle = {2nd {{International Conference}} on {{Formal Structures}} for {{Computation}} and {{Deduction}}},
  author = {Guerrini, Stefano and Solieri, Marco},
  year = {2017},
  month = sep,
  pages = {16 pages},
  publisher = {{Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany}},
  doi = {10.4230/LIPICS.FSCD.2017.17},
  url = {http://drops.dagstuhl.de/opus/volltexte/2017/7733/},
  urldate = {2021-09-06},
  abstract = {Sharing graphs are a local and asynchronous implementation of lambda-calculus beta-reduction (or linear logic proof-net cut-elimination) that avoids useless duplications. Empirical benchmarks suggest that they are one of the most efficient machineries, when one wants to fully exploit the higher-order features of lambda-calculus. However, we still lack confirming grounds with theoretical solidity to dispel uncertainties about the adoption of sharing graphs. Aiming at analysing in detail the worst-case overhead cost of sharing operators, we restrict to the case of elementary and light linear logic, two subsystems with bounded computational complexity of multiplicative exponential linear logic. In these two cases, the bookkeeping component is unnecessary, and sharing graphs are simplified to the so-called “abstract algorithm”. By a modular cost comparison over a syntactical simulation, we prove that the overhead of shared reductions is quadratically bounded to cost of the naive implementation, i.e. proof-net reduction. This result generalises and strengthens a previous complexity result, and implies that the price of sharing is negligible, if compared to the obtainable benefits on reductions requiring a large amount of duplication.},
  collaborator = {Herbstritt, Marc},
  langid = {english},
  keywords = {000 Computer science; knowledge; general works,Computer Science}
}
% == BibTeX quality report for guerriniOptimalImplementationInefficient2017:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("DOI.org (Datacite)")
% ? unused Medium ("application/pdf")

@phdthesis{guerriniTheoreticalPracticalIssues1996,
  title = {Theoretical and Practical Issues of Optimal Implementations of Functional Languages},
  author = {Guerrini, Stefano},
  year = {1996},
  url = {https://www-lipn.univ-paris13.fr/~guerrini/mysite/sites/default/files/biblio/PhDThesis.pdf},
  school = {Università di Pisa. Dipartimento di Informatica}
}
% == BibTeX quality report for guerriniTheoreticalPracticalIssues1996:
% ? unused Library catalog ("Google Scholar")

@article{hackettCallbyneedClairvoyantCallbyvalue2019,
  title = {Call-by-Need Is Clairvoyant Call-by-Value},
  author = {Hackett, Jennifer and Hutton, Graham},
  year = {2019},
  month = jul,
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {3},
  number = {ICFP},
  pages = {1--23},
  issn = {2475-1421},
  doi = {10.1145/3341718},
  url = {https://dl.acm.org/doi/10.1145/3341718},
  urldate = {2022-01-20},
  abstract = {Call-by-need evaluation, also known as lazy evaluation, provides two key benefits: compositional programming and infinite data. The standard semantics for laziness is Launchbury’s natural semantics~DBLP:conf/popl/Launchbury93, which uses a heap to memoise the results of delayed evaluations. However, the stateful nature of this heap greatly complicates reasoning about the operational behaviour of lazy programs. In this article, we propose an alternative semantics for laziness,               clairvoyant evaluation               , that replaces the state effect with nondeterminism, and prove this semantics equivalent in a strong sense to the standard semantics. We show how this new semantics greatly simplifies operational reasoning, admitting much simpler proofs of a number of results from the literature, and how it leads to the first               denotational cost semantics               for lazy evaluation.},
  langid = {english}
}
% == BibTeX quality report for hackettCallbyneedClairvoyantCallbyvalue2019:
% ? unused Journal abbreviation ("Proc. ACM Program. Lang.")
% ? unused Library catalog ("DOI.org (Crossref)")

@article{hirokawaDecreasingDiagramsRelative2009,
  title = {Decreasing {{Diagrams}} and {{Relative Termination}}},
  author = {Hirokawa, Nao and Middeldorp, Aart},
  year = {2009},
  month = oct,
  journal = {arXiv:0910.2853 [cs]},
  eprint = {0910.2853},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/0910.2853},
  urldate = {2021-09-14},
  abstract = {In this paper we use the decreasing diagrams technique to show that a left-linear term rewrite system R is confluent if all its critical pairs are joinable and the critical pair steps are relatively terminating with respect to R. We further show how to encode the rule-labeling heuristic for decreasing diagrams as a satisfiability problem. Experimental data for both methods are presented.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Logic in Computer Science,Computer Science - Symbolic Computation}
}
% == BibTeX quality report for hirokawaDecreasingDiagramsRelative2009:
% ? Possibly abbreviated journal title arXiv:0910.2853 [cs]
% ? Title looks like it was stored in title-case in Zotero

@article{hirokawaStrategiesDecreasinglyConfluent2011,
  title = {Strategies for {{Decreasingly Confluent Rewrite Systems}}},
  author = {Hirokawa, Nao and Middeldorp, Aart},
  year = {2011},
  journal = {Reduction Strategies in Rewriting and Programming},
  pages = {23}
}
% == BibTeX quality report for hirokawaStrategiesDecreasinglyConfluent2011:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Google Scholar")

@book{holmesElementarySetTheory1998,
  title = {Elementary Set Theory with a Universal Set},
  author = {Holmes, M. Randall},
  year = {1998},
  publisher = {{Bruylant-Academia}},
  url = {https://randall-holmes.github.io/head.pdf},
  googlebooks = {\_vjuAAAAMAAJ},
  isbn = {978-2-87209-488-2},
  langid = {english}
}
% == BibTeX quality report for holmesElementarySetTheory1998:
% ? unused Library catalog ("Google Books")
% ? unused Number of pages ("252")

@inproceedings{hudakAggregateUpdateProblem1985,
  title = {The Aggregate Update Problem in Functional Programming Systems},
  booktitle = {Proceedings of the 12th {{ACM SIGACT-SIGPLAN}} Symposium on {{Principles}} of Programming Languages  - {{POPL}} '85},
  author = {Hudak, Paul and Bloss, Adrienne},
  year = {1985},
  pages = {300--314},
  publisher = {{ACM Press}},
  address = {{New Orleans, Louisiana, United States}},
  doi = {10.1145/318593.318660},
  url = {http://portal.acm.org/citation.cfm?doid=318593.318660},
  urldate = {2022-01-04},
  isbn = {978-0-89791-147-4},
  langid = {english}
}
% == BibTeX quality report for hudakAggregateUpdateProblem1985:
% ? Unsure about the formatting of the booktitle
% ? unused Conference name ("the 12th ACM SIGACT-SIGPLAN symposium")
% ? unused Library catalog ("DOI.org (Crossref)")

@article{hughesWhyFunctionalProgramming1989,
  title = {Why {{Functional Programming Matters}}},
  author = {Hughes, J.},
  year = {1989},
  journal = {Computer Journal},
  volume = {32},
  number = {2},
  pages = {98--107}
}
% == BibTeX quality report for hughesWhyFunctionalProgramming1989:
% ? Title looks like it was stored in title-case in Zotero

@misc{jakobsDifferentialModularSoftware,
  title = {Differential Modular Software Verification},
  author = {Jakobs, Marie-Christine},
  url = {https://www.sosy-lab.org/research/prs/2019-10-01-CPA19-Differntial-Verification.pdf},
  urldate = {2020-07-25}
}

@inproceedings{jamesTheseusHighLevel2014,
  title = {Theseus: {{A High Level Language}} for {{Reversible Computing}}},
  booktitle = {Work-in-Progress Report at {{Conference}} on {{Reversible Computation}}},
  author = {James, Roshan P and Sabry, Amr},
  year = {2014},
  pages = {12},
  abstract = {Programming in a reversible language remains “different” than programming in conventional irreversible languages, requiring specialized abstractions and unique modes of thinking. We present a high level language for reversible programming, called Theseus, that meshes naturally with conventional programming language abstractions. Theseus has the look and feel of a conventional functional language while maintaining a close correspondence with the low-level family of languages Π based on type isomorphisms [9]. In contrast to the point-free combinators of Π, Theseus has variables and binding forms, algebraic data types, function definitions by pattern matching, and is Turing complete. The language is strongly typed and all well-typed programs are reversible. We explain the semantics of Theseus via a collection of progressively expressive examples and outline its correspondence to Π.},
  langid = {english}
}
% == BibTeX quality report for jamesTheseusHighLevel2014:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Conference name ("Conference on Reversible Computation")
% ? unused Library catalog ("Zotero")

@article{jonesCallbyvalueTerminationUntyped2008,
  title = {Call-by-Value Termination in the Untyped Lambda-Calculus},
  author = {Jones, Neil D. and Bohr, Nina},
  year = {2008},
  month = mar,
  journal = {Logical Methods in Computer Science},
  volume = {4},
  number = {1},
  eprint = {0801.0882},
  eprinttype = {arxiv},
  pages = {3},
  issn = {18605974},
  doi = {10.2168/LMCS-4(1:3)2008},
  url = {http://arxiv.org/abs/0801.0882},
  urldate = {2021-03-06},
  abstract = {A fully-automated algorithm is developed able to show that evaluation of a given untyped lambda-expression will terminate under CBV (call-by-value). The ``size-change principle'' from first-order programs is extended to arbitrary untyped lambda-expressions in two steps. The first step suffices to show CBV termination of a single, stand-alone lambda;-expression. The second suffices to show CBV termination of any member of a regular set of lambda-expressions, defined by a tree grammar. (A simple example is a minimum function, when applied to arbitrary Church numerals.) The algorithm is sound and proven so in this paper. The Halting Problem's undecidability implies that any sound algorithm is necessarily incomplete: some lambda-expressions may in fact terminate under CBV evaluation, but not be recognised as terminating. The intensional power of the termination algorithm is reasonably high. It certifies as terminating many interesting and useful general recursive algorithms including programs with mutual recursion and parameter exchanges, and Colson's ``minimum'' algorithm. Further, our type-free approach allows use of the Y combinator, and so can identify as terminating a substantial subset of PCF.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Programming Languages,D.3.1,F.3.2}
}
% == BibTeX quality report for jonesCallbyvalueTerminationUntyped2008:
% ? unused Journal abbreviation ("Log.Meth.Comput.Sci.")

@book{jonesImplementationFunctionalProgramming1987,
  title = {The Implementation of Functional Programming Languages},
  author = {Jones, Simon Peyton},
  year = {1987},
  publisher = {{Prentice-Hall}},
  url = {https://www.microsoft.com/en-us/research/publication/the-implementation-of-functional-programming-languages/},
  urldate = {2020-08-02},
  abstract = {My 1987 book is now out of print, but it is available~here in its entirety in PDF form.},
  langid = {american}
}
% == BibTeX quality report for jonesImplementationFunctionalProgramming1987:
% ? unused Library catalog ("www.microsoft.com")

@inproceedings{jonesTacklingAwkwardSquad2001,
  ids = {jonesTacklingAwkwardSquad2001a},
  title = {Tackling the Awkward Squad: Monadic Input/Output, Concurrency, Exceptions, and Foreign-Language Calls in {{Haskell}}},
  booktitle = {Engineering Theories of Software Construction},
  author = {Jones, Simon Peyton},
  year = {2001},
  pages = {47--96},
  url = {https://www.microsoft.com/en-us/research/publication/tackling-awkward-squad-monadic-inputoutput-concurrency-exceptions-foreign-language-calls-haskell/},
  abstract = {I’ve revised the notes significantly, with the help of feedback from many people. Last update: 21 Feb 2001. PowerPoint slides Writing High-Performance Server Applications in Haskell, Case Study: A Haskell Web Server, Simon Marlow, Haskell Workshop, Montreal, Canada, Sept 2000. This paper describes the running example in the notes. ~ This tutorial focuses on explaining […]},
  langid = {american}
}
% == BibTeX quality report for jonesTacklingAwkwardSquad2001:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("www.microsoft.com")

@article{jurkiewiczCostAddressTranslation2014,
  title = {The {{Cost}} of {{Address Translation}}},
  author = {Jurkiewicz, Tomasz and Mehlhorn, Kurt},
  year = {2014},
  month = apr,
  journal = {arXiv:1212.0703 [cs]},
  eprint = {1212.0703},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1212.0703},
  urldate = {2022-01-04},
  abstract = {Modern computers are not random access machines (RAMs). They have a memory hierarchy, multiple cores, and virtual memory. In this paper, we address the computational cost of address translation in virtual memory. Starting point for our work is the observation that the analysis of some simple algorithms (random scan of an array, binary search, heapsort) in either the RAM model or the EM model (external memory model) does not correctly predict growth rates of actual running times. We propose the VAT model (virtual address translation) to account for the cost of address translations and analyze the algorithms mentioned above and others in the model. The predictions agree with the measurements. We also analyze the VAT-cost of cache-oblivious algorithms.},
  archiveprefix = {arXiv},
  keywords = {68Q05; 68Q15; 03D15,B.8.2,C.4,Computer Science - Computational Complexity,Computer Science - Data Structures and Algorithms,Computer Science - Performance,F.1.1,F.2.3}
}
% == BibTeX quality report for jurkiewiczCostAddressTranslation2014:
% ? Possibly abbreviated journal title arXiv:1212.0703 [cs]
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{kahrsNonOmegaOverlappingTRSsAre2016,
  title = {Non-{{Omega-Overlapping TRSs}} Are {{UN}}},
  booktitle = {1st {{International Conference}} on {{Formal Structures}} for {{Computation}} and {{Deduction}} ({{FSCD}} 2016)},
  author = {Kahrs, Stefan and Smith, Connor},
  editor = {Kesner, Delia and Pientka, Brigitte},
  year = {2016},
  series = {Leibniz {{International Proceedings}} in {{Informatics}} ({{LIPIcs}})},
  volume = {52},
  pages = {22:1--22:17},
  publisher = {{Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik}},
  address = {{Dagstuhl, Germany}},
  issn = {1868-8969},
  doi = {10.4230/LIPIcs.FSCD.2016.22},
  url = {http://drops.dagstuhl.de/opus/volltexte/2016/5996},
  urldate = {2021-09-11},
  isbn = {978-3-95977-010-1},
  keywords = {consistency,omega-substitutions,uniqueness of normal forms}
}
% == BibTeX quality report for kahrsNonOmegaOverlappingTRSsAre2016:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("Dagstuhl Research Online Publication Server")

@inproceedings{kangFormalMemoryModel2015,
  title = {A Formal {{C}} Memory Model Supporting Integer-Pointer Casts},
  booktitle = {Proceedings of the 36th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author = {Kang, Jeehoon and Hur, Chung-Kil and Mansky, William and Garbuzov, Dmitri and Zdancewic, Steve and Vafeiadis, Viktor},
  year = {2015},
  month = jun,
  pages = {326--335},
  publisher = {{ACM}},
  address = {{Portland OR USA}},
  doi = {10.1145/2737924.2738005},
  url = {https://dl.acm.org/doi/10.1145/2737924.2738005},
  urldate = {2021-06-14},
  abstract = {The ISO C standard does not specify the semantics of many valid programs that use non-portable idioms such as integer-pointer casts. Recent efforts at formal definitions and verified implementation of the C language inherit this feature. By adopting high-level abstract memory models, they validate common optimizations. On the other hand, this prevents reasoning about much low-level code relying on the behavior of common implementations, where formal verification has many applications.},
  isbn = {978-1-4503-3468-6},
  langid = {english}
}
% == BibTeX quality report for kangFormalMemoryModel2015:
% ? unused Conference name ("PLDI '15: ACM SIGPLAN Conference on Programming Language Design and Implementation")
% ? unused Library catalog ("DOI.org (Crossref)")

@article{karazerisFinalCoalgebrasAccessible2011,
  title = {Final Coalgebras in Accessible Categories},
  author = {Karazeris, Panagis and Matzaris, Apostolos and Velebil, Jiří},
  year = {2011},
  month = oct,
  journal = {Mathematical Structures in Computer Science},
  volume = {21},
  number = {5},
  pages = {1067--1108},
  issn = {0960-1295, 1469-8072},
  doi = {10.1017/S0960129511000351},
  url = {https://www.cambridge.org/core/product/identifier/S0960129511000351/type/journal_article},
  urldate = {2021-03-11},
  abstract = {We propose a construction of the final coalgebra for a finitary endofunctor of a finitely accessible category and study conditions under which this construction is available. Our conditions always apply when the accessible category is cocomplete, and is thus a locally finitely presentable (l.f.p.) category, and we give an explicit and uniform construction of the final coalgebra in this case. On the other hand, our results also apply to some interesting examples of final coalgebras beyond the realm of l.f.p. categories. In particular, we construct the final coalgebra for every finitary endofunctor on the category of linear orders, and analyse Freyd's coalgebraic characterisation of the closed unit as an instance of this construction. We use and extend results of Tom Leinster, developed for his study of self-similar objects in topology, relying heavily on his formalism of modules (corresponding to endofunctors) and complexes for a module.},
  langid = {english}
}
% == BibTeX quality report for karazerisFinalCoalgebrasAccessible2011:
% ? unused Journal abbreviation ("Math. Struct. Comp. Sci.")
% ? unused Library catalog ("DOI.org (Crossref)")

@inproceedings{kennawayTransfiniteReductionsOrthogonal1991,
  title = {Transfinite Reductions in Orthogonal Term Rewriting Systems},
  booktitle = {Rewriting {{Techniques}} and {{Applications}}},
  author = {Kennaway, J. R. and Klop, J. W. and Sleep, M. R. and {de Vries}, F. J.},
  editor = {Book, Ronald V.},
  year = {1991},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {1--12},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-53904-2_81},
  abstract = {Strongly convergent reduction is the fundamental notion of reduction in infinitary orthogonal term rewriting systems (OTRSs). For these we prove the Transfinite Parallel Moves Lemma and the Compressing Lemma. Strongness is necessary as shown by counterexamples. Normal forms, which we allow to be infinite, are unique, in contrast to ω-normal forms. Strongly converging fair reductions result in normal forms.In general OTRSs the infinite Church-Rosser Property fails for strongly converging reductions. However for Böhm reduction (as in Lambda Calculus, subterms without head normal forms may be replaced by ⊥) the infinite Church-Rosser property does hold. The infinite Church-Rosser Property for non-unifiable OTRSs follows. The top-terminating OTRSs of Dershowitz c.s. are examples of non-unifiable OTRSs.},
  isbn = {978-3-540-46383-2},
  langid = {english},
  keywords = {68Q50,Böhm Trees,F4.1,F4.2,head normal forms,infinitary rewriting,infinite Church-Rosser Properties,non-unifiable term rewriting systems,normal forms,orthogonal term rewriting systems,strong converging reductions}
}
% == BibTeX quality report for kennawayTransfiniteReductionsOrthogonal1991:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("Springer Link")

@misc{kiselyovManyFacesFixedpoint2013,
  title = {Many Faces of the Fixed-Point Combinator},
  author = {Kiselyov, Oleg},
  year = {2013},
  month = aug,
  journal = {okmij.org},
  url = {http://okmij.org/ftp/Computation/fixed-point-combinators.html},
  urldate = {2020-07-31}
}
% == BibTeX quality report for kiselyovManyFacesFixedpoint2013:
% ? Possibly abbreviated journal title okmij.org

@inproceedings{klopExtendedTermRewriting1991,
  title = {Extended Term Rewriting Systems},
  booktitle = {Conditional and {{Typed Rewriting Systems}}},
  author = {Klop, Jan Willem and {de Vrijer}, Roel},
  editor = {Kaplan, S. and Okada, M.},
  year = {1991},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {26--50},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-54317-1_79},
  abstract = {In this paper we will consider some extensions of the usual term rewrite format, namely: term rewriting with conditions, infinitary term rewriting and term rewriting with bound variables. Rather than aiming at a complete survey, we discuss some aspects of these three extensions.},
  isbn = {978-3-540-47558-3},
  langid = {english},
  keywords = {Combinatory Logic,Normal Form,Reduction Rule,Reduction Sequence,Unique Normal}
}
% == BibTeX quality report for klopExtendedTermRewriting1991:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("Springer Link")

@misc{lafontLinearLogicPages,
  title = {Linear Logic Pages},
  author = {Lafont, Yves},
  url = {http://iml.univ-mrs.fr/~lafont/pub/llpages.pdf},
  langid = {english}
}

@inproceedings{leaJavaForkJoin2000,
  ids = {leaJavaForkJoin},
  title = {A {{Java}} Fork/Join Framework},
  booktitle = {Proceedings of the {{ACM}} 2000 Conference on {{Java Grande}}},
  author = {Lea, Doug},
  year = {2000},
  month = jun,
  series = {{{JAVA}} '00},
  pages = {36--43},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/337449.337465},
  url = {https://doi.org/10.1145/337449.337465},
  urldate = {2021-07-09},
  abstract = {This paper describes the design, implementation, and performance of a Java framework for supporting a style of parallel programming in which problems are solved by (recursively) splitting them into subtasks that are solved in parallel, waiting for them to complete, and then composing results. The general design is a variant of the work−stealing framework devised for Cilk. The main implementation techniques surround efficient construction and management of tasks queues and worker threads. The measured performance shows good parallel speedups for most programs, but also suggests possible improvements.},
  isbn = {978-1-58113-288-5},
  langid = {english}
}
% == BibTeX quality report for leaJavaForkJoin2000:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("ACM Digital Library")

@inproceedings{levyJumboLcalculus2006,
  title = {Jumbo λ-Calculus},
  booktitle = {Automata, {{Languages}} and {{Programming}}},
  author = {Levy, Paul Blain},
  editor = {Bugliesi, Michele and Preneel, Bart and Sassone, Vladimiro and Wegener, Ingo},
  year = {2006},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {444--455},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/11787006_38},
  url = {https://www.cs.bham.ac.uk/~pbl/papers/jumboicalp.pdf},
  abstract = {We make an argument that, for any study involving computational effects such as divergence or continuations, the traditional syntax of simply typed lambda-calculus cannot be regarded as canonical, because standard arguments for canonicity rely on isomorphisms that may not exist in an effectful setting. To remedy this, we define a “jumbo lambda-calculus” that fuses the traditional connectives together into more general ones, so-called “jumbo connectives”. We provide two pieces of evidence for our thesis that the jumbo formulation is advantageous.Firstly, we show that the jumbo lambda-calculus provides a “complete” range of connectives, in the sense of including every possible connective that, within the beta-eta theory, possesses a reversible rule.Secondly, in the presence of effects, we show that there is no decomposition of jumbo connectives into non-jumbo ones that is valid in both call-by-value and call-by-name.},
  isbn = {978-3-540-35908-1},
  langid = {english}
}
% == BibTeX quality report for levyJumboLcalculus2006:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("Springer Link")

@article{maraistCallbynameCallbyvalueCallbyneed1995,
  title = {Call-by-Name, Call-by-Value, Call-by-Need, and the Linear Lambda Calculus},
  author = {Maraist, John and Odersky, Martin and Turner, David N. and Wadler, Philip},
  year = {1995},
  month = jan,
  journal = {Electronic Notes in Theoretical Computer Science},
  series = {{{MFPS XI}}, {{Mathematical Foundations}} of {{Programming Semantics}}, {{Eleventh Annual Conference}}},
  volume = {1},
  pages = {370--392},
  issn = {1571-0661},
  doi = {10.1016/S1571-0661(04)00022-2},
  url = {http://www.sciencedirect.com/science/article/pii/S1571066104000222},
  urldate = {2020-08-23},
  abstract = {Girard described two translations of intuitionistic logic into linear logic, one where A → B maps to (!A) –○ B, and another where it maps to !(A –○ B). We detail the action of these translations on terms, and show that the first corresponds to a call-by-name calculus, while the second corresponds to call-by-value. We further show that if the target of the translation is taken to be an affine calculus, where ! controls contraction but weakening is allowed everywhere, then the second translation corresponds to a call-by-need calculus, as recently defined by Ariola, Felleisen, Maraist, Odersky and Wadler. Thus the different calling mechanisms can be explained in terms of logical translations, bringing them into the scope of the Curry-Howard isomorphism.},
  langid = {english}
}
% == BibTeX quality report for maraistCallbynameCallbyvalueCallbyneed1995:
% ? unused Library catalog ("ScienceDirect")

@inproceedings{marlowDesugaringHaskellDonotation2016,
  title = {Desugaring {{Haskell}}'s Do-Notation into Applicative Operations},
  booktitle = {Proceedings of the 9th {{International Symposium}} on {{Haskell}}},
  author = {Marlow, Simon and Peyton Jones, Simon and Kmett, Edward and Mokhov, Andrey},
  year = {2016},
  month = sep,
  series = {Haskell 2016},
  pages = {92--104},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2976002.2976007},
  url = {https://doi.org/10.1145/2976002.2976007},
  urldate = {2021-07-16},
  abstract = {Monads have taken the world by storm, and are supported by do-notation (at least in Haskell). Programmers are increasingly waking up to the usefulness and ubiquity of Applicatives, but they have so far been hampered by the absence of supporting notation. In this paper we show how to re-use the very same do-notation to work for Applicatives as well, providing efficiency benefits for some types that are both Monad and Applicative, and syntactic convenience for those that are merely Applicative. The result is fully implemented as an optional extension in GHC, and is in use at Facebook to make it easy to write highly-parallel queries in a distributed system.},
  isbn = {978-1-4503-4434-0},
  langid = {american},
  keywords = {Applicative Functors,concurrency,Monads,parallelism}
}
% == BibTeX quality report for marlowDesugaringHaskellDonotation2016:
% ? unused Library catalog ("ACM Digital Library")

@incollection{martiniFineStructureExponential1995,
  ids = {martiniFineStructureExponential1995a},
  title = {On the Fine Structure of the Exponential Rule},
  booktitle = {Advances in {{Linear Logic}}},
  author = {Martini, S. and Masini, A.},
  editor = {Girard, Jean-Yves and Lafont, Yves and Regnier, Laurent},
  year = {1995},
  pages = {197--210},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9780511629150.010},
  url = {https://pdfs.semanticscholar.org/b2cb/538c8ef21af42e48134a17a3c62ce5167837.pdf},
  urldate = {2020-08-01},
  abstract = {We present natural deduction systems for fragments of intuitionistic linear logic obtained by dropping weakening and contractions also on !-pre xed formulas. The systems are based on a twodimensional generalization of the notion of sequent, which accounts for a clean formulation of the introduction/elimination rules of the modality. Moreover, the di erent subsystems are obtained in a modular way, by simple conditions on the elimination rule for !. For the proposed systems we introduce a notion of reduction and we prove a normalization theorem.},
  isbn = {978-0-511-62915-0},
  langid = {english}
}
% == BibTeX quality report for martiniFineStructureExponential1995:
% ? unused Library catalog ("DOI.org (Crossref)")

@article{mauborgneIncrementalUniqueRepresentation2000,
  title = {An {{Incremental Unique Representation}} for {{Regular Trees}}},
  author = {Mauborgne, Laurent},
  year = {2000},
  pages = {22},
  abstract = {In order to deal with infinite regular trees (or other pointed graph structures) efficiently, we give new algorithms to store such structures. The trees are stored in such a way that their representation is unique and shares substructures as much as possible. This maximal sharing allows substantial memory gain and speed up over previous techniques. For example, equality testing becomes constant time (instead of O(n log(n))). The algorithms are incremental, and as such allow good reactive behavior. These new algorithms are then applied in a representation of sets of trees. The expressive power of this new representation is exactly what is needed by the original set-based analyses of Heintze and Jaffar [1990], or Heintze [1994].},
  langid = {english}
}
% == BibTeX quality report for mauborgneIncrementalUniqueRepresentation2000:
% Missing required field 'journal'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@phdthesis{mauborgneRepresentationSetsTrees1999,
  title = {Representation of Sets of Trees for Abstract Interpretation},
  author = {Mauborgne, Laurent},
  year = {1999},
  month = nov,
  journal = {PhD Thesis},
  url = {http://software.imdea.org/~mauborgn/publi/t.pdf},
  school = {Ecole Polytechnique}
}
% == BibTeX quality report for mauborgneRepresentationSetsTrees1999:
% ? unused Library catalog ("Google Scholar")
% ? unused Number of pages ("197")

@incollection{mcdermottExtendedCallbyPushValueReasoning2019,
  title = {Extended {{Call-by-Push-Value}}: {{Reasoning About Effectful Programs}} and {{Evaluation Order}}},
  shorttitle = {Extended {{Call-by-Push-Value}}},
  booktitle = {Programming {{Languages}} and {{Systems}}},
  author = {McDermott, Dylan and Mycroft, Alan},
  editor = {Caires, Luís},
  year = {2019},
  volume = {11423},
  pages = {235--262},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-17184-1_9},
  url = {http://link.springer.com/10.1007/978-3-030-17184-1_9},
  urldate = {2021-11-09},
  abstract = {Traditionally, reasoning about programs under varying evaluation regimes (call-by-value, call-by-name etc.) was done at the metalevel, treating them as term rewriting systems. Levy’s call-by-push-value (CBPV) calculus provides a more powerful approach for reasoning, by treating CBPV terms as a common intermediate language which captures both call-by-value and call-by-name, and by allowing equational reasoning about changes to evaluation order between or within programs. We extend CBPV to additionally deal with call-by-need, which is nontrivial because of shared reductions. This allows the equational reasoning to also support call-by-need. As an example, we then prove that callby-need and call-by-name are equivalent if nontermination is the only side-effect in the source language.},
  isbn = {978-3-030-17183-4 978-3-030-17184-1},
  langid = {english}
}
% == BibTeX quality report for mcdermottExtendedCallbyPushValueReasoning2019:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Series title ("Lecture Notes in Computer Science")

@incollection{middeldorpModularAspectsProperties1989,
  title = {Modular Aspects of Properties of Term Rewriting Systems Related to Normal Forms},
  booktitle = {Rewriting {{Techniques}} and {{Applications}}},
  author = {Middeldorp, Aart},
  editor = {Goos, G. and Hartmanis, J. and Barstow, D. and Brauer, W. and Brinch Hansen, P. and Gries, D. and Luckham, D. and Moler, C. and Pnueli, A. and Seegmüller, G. and Stoer, J. and Wirth, N. and Dershowitz, Nachum},
  year = {1989},
  volume = {355},
  pages = {263--277},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-51081-8_113},
  url = {http://link.springer.com/10.1007/3-540-51081-8_113},
  urldate = {2021-09-14},
  abstract = {In this paper we prove that the property of having unique normal forms is preserved under disjoint union. We show that two related properties do not exhibit this kind of modularity.},
  isbn = {978-3-540-51081-9 978-3-540-46149-4},
  langid = {english}
}
% == BibTeX quality report for middeldorpModularAspectsProperties1989:
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Series title ("Lecture Notes in Computer Science")

@article{mokhovBuildSystemsCarte2020,
  ids = {mokhovBuildSystemsCarte2020a},
  title = {Build Systems à La Carte: Theory and Practice},
  shorttitle = {Build Systems à La Carte},
  author = {Mokhov, Andrey and Mitchell, Neil and Peyton Jones, Simon},
  year = {2020},
  journal = {Journal of Functional Programming},
  volume = {30},
  pages = {e11},
  issn = {0956-7968, 1469-7653},
  doi = {10.1017/S0956796820000088},
  url = {https://ndmitchell.com/downloads/paper-build_systems_a_la_carte_theory_and_practice-21_apr_2020.pdf},
  urldate = {2020-06-11},
  abstract = {Build systems are awesome, terrifying – and unloved. They are used by every developer around the world, but are rarely the object of study. In this paper, we offer a systematic, and executable, framework for developing and comparing build systems, viewing them as related points in a landscape rather than as isolated phenomena. By teasing apart existing build systems, we can recombine their components, allowing us to prototype new build systems with desired properties.},
  langid = {english}
}
% == BibTeX quality report for mokhovBuildSystemsCarte2020:
% ? unused Journal abbreviation ("J. Funct. Prog.")
% ? unused Library catalog ("DOI.org (Crossref)")

@article{naikTypeSystemEquivalent2008,
  title = {A Type System Equivalent to a Model Checker},
  author = {Naik, Mayur and Palsberg, Jens},
  year = {2008},
  month = aug,
  journal = {ACM Transactions on Programming Languages and Systems},
  volume = {30},
  number = {5},
  pages = {1--24},
  issn = {0164-0925, 1558-4593},
  doi = {10.1145/1387673.1387678},
  url = {https://dl.acm.org/doi/10.1145/1387673.1387678},
  urldate = {2021-07-15},
  abstract = {Type systems and model checking are two prevalent approaches to program verification. A prominent difference between them is that type systems are typically defined in a syntactic and modular style whereas model checking is usually performed in a semantic and whole-program style. This difference between the two approaches makes them complementary to each other: type systems are good at explaining why a program was accepted while model checkers are good at explaining why a program was rejected.             We present a type system that is equivalent to a model checker for verifying temporal safety properties of imperative programs. The model checker is natural and may be instantiated with any finite-state abstraction scheme such as predicate abstraction. The type system, which is also parametric, type checks exactly those programs that are accepted by the model checker. It uses a variant of function types to capture flow sensitivity and intersection and union types to capture context sensitivity. Our result sheds light on the relationship between type systems and model checking, provides a methodology for studying their relative expressiveness, is a step towards sharing results between the two approaches, and motivates synergistic program analyses involving interplay between them.},
  langid = {english}
}
% == BibTeX quality report for naikTypeSystemEquivalent2008:
% ? unused Journal abbreviation ("ACM Trans. Program. Lang. Syst.")
% ? unused Library catalog ("DOI.org (Crossref)")

@inproceedings{najafiBisectingCommitsModeling2019,
  title = {Bisecting Commits and Modeling Commit Risk during Testing},
  booktitle = {Proceedings of the 2019 27th {{ACM Joint Meeting}} on {{European Software Engineering Conference}} and {{Symposium}} on the {{Foundations}} of {{Software Engineering}}  - {{ESEC}}/{{FSE}} 2019},
  author = {Najafi, Armin and Rigby, Peter C. and Shang, Weiyi},
  year = {2019},
  pages = {279--289},
  publisher = {{ACM Press}},
  address = {{Tallinn, Estonia}},
  doi = {10.1145/3338906.3338944},
  url = {https://users.encs.concordia.ca/~shang/pubs/Armin_FSE_2019.pdf},
  urldate = {2020-07-06},
  abstract = {Software testing is one of the costliest stages in the software development life cycle. One approach to reducing the test execution cost is to group changes and test them as a batch (i.e. batch testing). However, when tests fail in a batch, commits in the batch need to be re-tested to identify the cause of the failure, i.e. the culprit commit. The re-testing is typically done through bisection (i.e. a binary search through the commits in a batch). Intuitively, the effectiveness of batch testing highly depends on the size of the batch. Larger batches require fewer initial test runs, but have a higher chance of a test failure that can lead to expensive test re-runs to find the culprit. We are unaware of research that investigates and simulates the impact of batch sizes on the cost of testing in industry. In this work, we first conduct empirical studies on the effectiveness of batch testing in three large-scale industrial software systems at Ericsson. Using 9 months of testing data, we simulate batch sizes from 1 to 20 and find the most cost-effective BatchSize for each project. Our results show that batch testing saves 72\% of test executions compared to testing each commit individually. In a second simulation, we incorporate flaky tests that pass and fail on the same commit as they are a significant source of additional test executions on large projects. We model the degree of flakiness for each project and find that test flakiness reduces the cost savings to 42\%. In a third simulation, we guide bisection to reduce the likelihood of batch-testing failures. We model the riskiness of each commit in a batch using a bug model and a test execution history model. The risky commits are tested individually, while the less risky commits are tested in a single larger batch. Culprit predictions with our approach reduce test executions up to 9\% compared to Ericsson’s current bisection approach.},
  isbn = {978-1-4503-5572-8},
  langid = {english}
}
% == BibTeX quality report for najafiBisectingCommitsModeling2019:
% ? unused Conference name ("the 2019 27th ACM Joint Meeting")
% ? unused Library catalog ("DOI.org (Crossref)")

@inproceedings{nigamAlgorithmicSpecificationsLinear2009,
  ids = {nigamAlgorithmicSpecificationsLinear2009a},
  title = {Algorithmic Specifications in Linear Logic with Subexponentials},
  booktitle = {Proceedings of the 11th {{ACM SIGPLAN}} Conference on {{Principles}} and Practice of Declarative Programming - {{PPDP}} '09},
  author = {Nigam, Vivek and Miller, Dale},
  year = {2009},
  pages = {129},
  publisher = {{ACM Press}},
  address = {{Coimbra, Portugal}},
  doi = {10.1145/1599410.1599427},
  url = {http://portal.acm.org/citation.cfm?doid=1599410.1599427},
  urldate = {2021-03-26},
  abstract = {The linear logic exponentials !, ? are not canonical: one can add to linear logic other such operators, say !l, ?l, which may or may not allow contraction and weakening, and where l is from some pre-ordered set of labels. We shall call these additional operators subexponentials and use them to assign locations to multisets of formulas within a linear logic programming setting. Treating locations as subexponentials greatly increases the algorithmic expressiveness of logic. To illustrate this new expressiveness, we show that focused proof search can be precisely linked to a simple algorithmic specification language that contains while-loops, conditionals, and insertion into and deletion from multisets. We also give some general conditions for when a focused proof step can be executed in constant time. In addition, we propose a new logical connective that allows for the creation of new subexponentials, thereby further augmenting the algorithmic expressiveness of logic.},
  isbn = {978-1-60558-568-0},
  langid = {english}
}
% == BibTeX quality report for nigamAlgorithmicSpecificationsLinear2009:
% ? Unsure about the formatting of the booktitle
% ? unused Conference name ("the 11th ACM SIGPLAN conference")
% ? unused Library catalog ("DOI.org (Crossref)")

@book{okasakiPurelyFunctionalData1998,
  title = {Purely Functional Data Structures},
  author = {Okasaki, Chris},
  year = {1998},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, U.K. ; New York}},
  isbn = {978-0-521-63124-2},
  langid = {english},
  lccn = {QA76.9.D35 O35 1998},
  keywords = {Data structures (Computer science),Functional programming languages}
}
% == BibTeX quality report for okasakiPurelyFunctionalData1998:
% ? unused Library catalog ("Library of Congress ISBN")
% ? unused Number of pages ("220")

@article{peytonjonesSecretsGlasgowHaskell2002,
  ids = {jonesSecretsGlasgowHaskell2002},
  title = {Secrets of the {{Glasgow Haskell Compiler}} Inliner},
  author = {Peyton Jones, Simon and Marlow, Simon},
  year = {2002},
  month = jul,
  journal = {Journal of Functional Programming},
  volume = {12},
  number = {4},
  pages = {393--434},
  issn = {0956-7968, 1469-7653},
  doi = {10.1017/S0956796802004331},
  url = {https://www.microsoft.com/en-us/research/wp-content/uploads/2002/07/inline.pdf},
  urldate = {2020-07-01},
  abstract = {Higher-order languages, such as Haskell, encourage the programmer to build abstractions by composing functions. A good compiler must inline many of these calls to recover an e ciently executable program.},
  langid = {english}
}
% == BibTeX quality report for peytonjonesSecretsGlasgowHaskell2002:
% ? unused Journal abbreviation ("J. Funct. Prog.")
% ? unused Library catalog ("DOI.org (Crossref)")

@article{pfenningChurchCurryCombining2012,
  title = {Church and {{Curry}}: {{Combining Intrinsic}} and {{Extrinsic Typing}}},
  author = {Pfenning, Frank},
  year = {2012},
  month = apr,
  pages = {36},
  langid = {english}
}
% == BibTeX quality report for pfenningChurchCurryCombining2012:
% Missing required field 'journal'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@article{pippengerPureImpureLisp1997,
  title = {Pure versus Impure {{Lisp}}},
  author = {Pippenger, Nicholas},
  year = {1997},
  month = mar,
  journal = {ACM Transactions on Programming Languages and Systems},
  volume = {19},
  number = {2},
  pages = {223--238},
  issn = {0164-0925, 1558-4593},
  doi = {10.1145/244795.244798},
  url = {https://dl.acm.org/doi/10.1145/244795.244798},
  urldate = {2022-01-06},
  langid = {english}
}
% == BibTeX quality report for pippengerPureImpureLisp1997:
% ? unused Journal abbreviation ("ACM Trans. Program. Lang. Syst.")
% ? unused Library catalog ("DOI.org (Crossref)")

@techreport{proustASAPStaticPossible2017,
  title = {{{ASAP}}: {{As Static As Possible}} Memory Management},
  author = {Proust, Raphaël L},
  year = {2017},
  month = jul,
  number = {UCAM-CL-TR-908},
  pages = {145},
  institution = {{University of Cambridge Computer Laboratory}},
  url = {https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-908.pdf},
  langid = {english}
}
% == BibTeX quality report for proustASAPStaticPossible2017:
% ? unused Library catalog ("Zotero")

@inproceedings{ramalheteEfficientAlgorithmsPersistent2021,
  title = {Efficient Algorithms for Persistent Transactional Memory},
  booktitle = {Proceedings of the 26th {{ACM SIGPLAN Symposium}} on {{Principles}} and {{Practice}} of {{Parallel Programming}}},
  author = {Ramalhete, Pedro and Correia, Andreia and Felber, Pascal},
  year = {2021},
  month = feb,
  series = {{{PPoPP}} '21},
  pages = {1--15},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3437801.3441586},
  url = {https://doi.org/10.1145/3437801.3441586},
  urldate = {2021-11-11},
  abstract = {Durable techniques coupled with transactional semantics provide to application developers the guarantee that data is saved consistently in persistent memory (PM), even in the event of a non-corrupting failure. Persistence fences and flush instructions are known to have a significant impact on the throughput of persistent transactions. In this paper we explore different trade-offs in terms of memory usage vs. number of fences and flushes. We present two new algorithms, named Trinity and Quadra, for durable transactions on PM and implement each of them in the form of a user-level library persistent transactional memory (PTM). Quadra achieves the lower bound with respect to the number of persistence fences and executes one flush instruction per modified cache line. Trinity can be easily combined with concurrency control techniques based on fine grain locking, and we have integrated it with our TL2 adaptation, with eager locking and write-through update strategy. Moreover, the combination of Trinity and TL2 into a PTM provides good scalability for data structures and workloads with a disjoint access pattern. We used this disjoint PTM to implement a key-value (KV) store with durable linearizable transactions. When compared with previous work, our TL2 KV store provides better throughput in nearly all experiments.},
  isbn = {978-1-4503-8294-6},
  keywords = {crash resilience,persistent memory,transactions}
}
% == BibTeX quality report for ramalheteEfficientAlgorithmsPersistent2021:
% ? unused Library catalog ("ACM Digital Library")

@article{rivasNotionsComputationMonoids2014,
  title = {Notions of {{Computation}} as {{Monoids}}},
  author = {Rivas, Exequiel and Jaskelioff, Mauro},
  year = {2014},
  month = may,
  url = {https://arxiv.org/abs/1406.4823v1},
  urldate = {2021-11-23},
  abstract = {There are different notions of computation, the most popular being monads, applicative functors, and arrows. In this article we show that these three notions can be seen as monoids in a monoidal category. We demonstrate that at this level of abstraction one can obtain useful results which can be instantiated to the different notions of computation. In particular, we show how free constructions and Cayley representations for monoids translate into useful constructions for monads, applicative functors, and arrows. Moreover, the uniform presentation of all three notions helps in the analysis of the relation between them.},
  langid = {english}
}
% == BibTeX quality report for rivasNotionsComputationMonoids2014:
% Missing required field 'journal'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("arxiv.org")

@article{sewellX86TSORigorousUsable2010,
  title = {X86-{{TSO}}: A Rigorous and Usable Programmer's Model for X86 Multiprocessors},
  shorttitle = {X86-{{TSO}}},
  author = {Sewell, Peter and Sarkar, Susmit and Owens, Scott and Nardelli, Francesco Zappa and Myreen, Magnus O.},
  year = {2010},
  month = jul,
  journal = {Communications of the ACM},
  volume = {53},
  number = {7},
  pages = {89--97},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/1785414.1785443},
  url = {https://dl.acm.org/doi/10.1145/1785414.1785443},
  urldate = {2021-07-09},
  abstract = {Exploiting the multiprocessors that have recently become ubiquitous requires high-performance and reliable concurrent systems code, for concurrent data structures, operating system kernels, synchronisation libraries, compilers, and so on. However, concurrent programming, which is always challenging, is made much more so by two problems. First, real multiprocessors typically do not provide the sequentially consistent memory that is assumed by most work on semantics and verification. Instead, they have relaxed memory models, varying in subtle ways between processor families, in which different hardware threads may have only loosely consistent views of a shared memory. Second, the public vendor architectures, supposedly specifying what programmers can rely on, are often in ambiguous informal prose (a particularly poor medium for loose specifications), leading to widespread confusion.},
  langid = {english}
}
% == BibTeX quality report for sewellX86TSORigorousUsable2010:
% ? unused Journal abbreviation ("Commun. ACM")
% ? unused Library catalog ("DOI.org (Crossref)")

@misc{shalBuildSystemRules2009,
  title = {Build System Rules and Algorithms},
  author = {Shal, Mike},
  year = {2009},
  publisher = {{gittup.org}},
  url = {http://gittup.org/tup/build_system_rules_and_algorithms.pdf},
  urldate = {2021-01-22}
}

@phdthesis{shamirFixedpointsRecursiveDefinitions1976,
  title = {The Fixedpoints of Recursive Definitions},
  author = {Shamir, Adi},
  year = {1976},
  month = oct,
  address = {{Rehovot}},
  url = {https://weizmann.primo.exlibrisgroup.com/permalink/972WIS_INST/1d4esio/alma990002185270203596},
  collaborator = {Manna, Zohar},
  langid = {english},
  school = {Weizmann Institute of Science},
  keywords = {WISOA}
}
% == BibTeX quality report for shamirFixedpointsRecursiveDefinitions1976:
% ? unused Number of pages ("316")
% ? unused Type ("PhD")

@article{shirahataFixpointTheoremLinear1999,
  title = {Fixpoint Theorem in Linear Set Theory},
  author = {Shirahata, Masaru},
  year = {1999},
  month = dec,
  pages = {10},
  abstract = {In this paper, we first show that the fixpoint term can be constructed for any formula in the system of linear set theory with equality and pairing. We then prove that all the total recursive functions are numeralwise representable in such a system. Furthermore, we observe that the additive infinitary extension of the system would become inconsistent if the extensionality principle were added.},
  langid = {english}
}
% == BibTeX quality report for shirahataFixpointTheoremLinear1999:
% Missing required field 'journal'
% ? unused Library catalog ("Zotero")

@article{shirahataLinearConservativeExtension1996,
  title = {A Linear Conservative Extension of {{Zermelo-Fraenkel}} Set Theory},
  author = {Shirahata, Masaru},
  year = {1996},
  month = may,
  journal = {Studia Logica},
  volume = {56},
  number = {3},
  pages = {361--392},
  issn = {0039-3215, 1572-8730},
  doi = {10.1007/BF00372772},
  url = {http://link.springer.com/10.1007/BF00372772},
  urldate = {2021-03-06},
  abstract = {In this paper, we develop the system LZF of set theory with the unrestricted comprehension in full linear logic and show that LZF is a conservative extension of ZFi.e., the Zermelo-Fraenkel set theory without the axiom of regularity. We formulate LZF as a sequent calculus with abstraction terms and prove the partial cut-elimination theorem for it. The cut-elimination result ensures the subterm property for those formulas which contain only terms corresponding to sets in ZF-. This implies that LZF is a conservative extension of ZF- and therefore the former is consistent relative to the latter.},
  langid = {english}
}
% == BibTeX quality report for shirahataLinearConservativeExtension1996:
% ? unused Journal abbreviation ("Stud Logica")
% ? unused Library catalog ("DOI.org (Crossref)")

@phdthesis{shirahataLinearSetTheory1994,
  title = {Linear {{Set Theory}}},
  author = {Shirahata, Masaru},
  year = {1994},
  month = feb,
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.29.7077&rep=rep1&type=pdf},
  lccn = {9430011},
  school = {Stanford University}
}
% == BibTeX quality report for shirahataLinearSetTheory1994:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("ProQuest Dissertations Publishing")
% ? unused Type ("PhD Thesis")

@inproceedings{shirahataLinearSetTheory1998,
  title = {Linear Set Theory with Strict Comprehension},
  booktitle = {Proceedings of the {{Sixth Asian Logic Conference}}},
  author = {Shirahata, Masaru},
  year = {1998},
  month = apr,
  pages = {223--245},
  publisher = {{WORLD SCIENTIFIC / S'PORE UNIV PRESS (PTE) LTD}},
  address = {{Beijing, China}},
  doi = {10.1142/9789812812940_0013},
  url = {http://www.worldscientific.com/doi/abs/10.1142/9789812812940_0013},
  urldate = {2021-03-06},
  abstract = {In this paper, we study the extensionality axiom in the set theory with the unrestricted comprehension based on linear logic. We rst review Grishin's result which shows the imcompatibility of the extensionality axiom and the unrestricted comprehesion in linear set theory. As one way to rectify this situation, we introduce the notion of \textbackslash strict comprehension" and formulate a system of linear set theory which contains the extensionality and the strict comprehesion. The consistency of such a system is then proved by a simple cut-elimination argument.},
  isbn = {978-981-02-3432-4 978-981-281-294-0},
  langid = {english}
}
% == BibTeX quality report for shirahataLinearSetTheory1998:
% ? unused Library catalog ("DOI.org (Crossref)")

@inproceedings{shiVirtualMachineShowdown2005,
  ids = {shiVirtualMachineShowdown,shiVirtualMachineShowdown2008},
  title = {Virtual Machine Showdown: Stack versus Registers},
  shorttitle = {Virtual Machine Showdown},
  booktitle = {Proceedings of the 1st {{ACM}}/{{USENIX}} International Conference on {{Virtual}} Execution Environments},
  author = {Shi, Yunhe and Gregg, David and Beatty, Andrew and Ertl, M. Anton},
  year = {2005},
  month = jun,
  series = {{{VEE}} '05},
  pages = {153--163},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1064979.1065001},
  url = {https://dl.acm.org/doi/10.1145/1328195.1328197},
  urldate = {2021-06-29},
  abstract = {Virtual machines (VMs) are commonly used to distribute programs in an architecture-neutral format, which can easily be interpreted or compiled. A long-running question in the design of VMs is whether stack architecture or register architecture can be implemented more efficiently with an interpreter. We extend existing work on comparing virtual stack and virtual register architectures in two ways. Firstly, our translation from stack to register code is much more sophisticated. The result is that we eliminate an average of more than 47\% of executed VM instructions, with the register machine bytecode size only 25\% larger than that of the corresponding stack bytecode. Secondly we present an implementation of a register machine in a fully standard-compliant implementation of the Java VM. We find that, on the Pentium 4, the register architecture requires an average of 32.3\% less time to execute standard benchmarks if dispatch is performed using a C switch statement. Even if more efficient threaded dispatch is available (which requires labels as first class values), the reduction in running time is still approximately 26.5\% for the register architecture.},
  isbn = {978-1-59593-047-7},
  keywords = {interpreter,Interpreter,register architecture,stack architecture,virtual machine}
}
% == BibTeX quality report for shiVirtualMachineShowdown2005:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("ACM Digital Library")

@article{shulmanLinearLogicConstructive2018,
  title = {Linear Logic for Constructive Mathematics},
  author = {Shulman, Michael},
  year = {2018},
  month = may,
  journal = {arXiv:1805.07518 [math]},
  eprint = {1805.07518},
  eprinttype = {arxiv},
  primaryclass = {math},
  url = {http://arxiv.org/abs/1805.07518},
  urldate = {2021-03-04},
  abstract = {We show that numerous distinctive concepts of constructive mathematics arise automatically from an interpretation of "linear higher-order logic" into intuitionistic higher-order logic via a Chu construction. This includes apartness relations, complemented subsets, anti-subgroups and anti-ideals, strict and non-strict order pairs, cut-valued metrics, and apartness spaces. We also explain the constructive bifurcation of classical concepts using the choice between multiplicative and additive linear connectives. Linear logic thus systematically "constructivizes" classical definitions and deals automatically with the resulting bookkeeping, and could potentially be used directly as a basis for constructive mathematics in place of intuitionistic logic.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Logic}
}
% == BibTeX quality report for shulmanLinearLogicConstructive2018:
% ? Possibly abbreviated journal title arXiv:1805.07518 [math]

@phdthesis{shuttFexprsBasisLisp2010,
  title = {Fexprs as the Basis of {{Lisp}} Function Application or \$vau : The Ultimate Abstraction},
  author = {Shutt, John N},
  year = {2010},
  month = aug,
  url = {https://web.wpi.edu/Pubs/ETD/Available/etd-090110-124904/},
  langid = {english},
  school = {WORCESTER POLYTECHNIC INSTITUTE}
}
% == BibTeX quality report for shuttFexprsBasisLisp2010:
% ? unused Library catalog ("Zotero")
% ? unused Number of pages ("416")
% ? unused Type ("PhD Thesis")

@article{sparksSuperstructuralReversibleLogic2014,
  title = {Superstructural {{Reversible Logic}}},
  author = {Sparks, Z A and Sabry, Amr},
  year = {2014},
  pages = {8},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.720.5692&rep=rep1&type=pdf},
  langid = {english}
}
% == BibTeX quality report for sparksSuperstructuralReversibleLogic2014:
% Missing required field 'journal'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@article{sperberGenerationLRParsers2000,
  title = {Generation of {{LR}} Parsers by Partial Evaluation},
  author = {Sperber, Michael and Thiemann, Peter},
  year = {2000},
  month = mar,
  journal = {ACM Transactions on Programming Languages and Systems (TOPLAS)},
  volume = {22},
  number = {2},
  pages = {224--264},
  issn = {0164-0925, 1558-4593},
  doi = {10.1145/349214.349219},
  url = {http://dl.acm.org/doi/10.1145/349214.349219},
  urldate = {2020-06-15},
  langid = {english}
}
% == BibTeX quality report for sperberGenerationLRParsers2000:
% ? unused Journal abbreviation ("ACM Trans. Program. Lang. Syst.")
% ? unused Library catalog ("DOI.org (Crossref)")

@article{strakaFullyPersistentArrays,
  title = {Fully Persistent Arrays with Optimal Worst-Case Complexity},
  author = {Straka, Milan},
  pages = {15},
  abstract = {We describe a RAM implementation of fully persistent array with worst-case O(log log m) time complexity for update and lookup, where m is the number of modifications to the array. The space complexity of such persistent array with n elements is O(n + m).},
  langid = {english}
}
% == BibTeX quality report for strakaFullyPersistentArrays:
% Missing required field 'journal'
% Missing required field 'year'
% ? unused Library catalog ("Zotero")

@article{sutterFamilyLanguages2000,
  title = {The {{C Family}} of {{Languages}}},
  author = {Sutter, Herb},
  year = {2000},
  month = jul,
  url = {http://www.gotw.ca/publications/c_family_interview.htm},
  urldate = {2021-10-28},
  collaborator = {Ritchie, Dennis and Stroustrup, Bjarne and Gosling, James}
}
% == BibTeX quality report for sutterFamilyLanguages2000:
% Missing required field 'journal'
% ? Title looks like it was stored in title-case in Zotero

@article{trinderAlgorithmStrategyParallelism1998,
  title = {Algorithm + {{Strategy}} = {{Parallelism}}},
  author = {Trinder, P. W. and Hammond, K. and Loidl, H.-W. and Jones, Simon Peyton},
  year = {1998},
  month = jan,
  journal = {Journal of Functional Programming},
  volume = {8},
  url = {https://www.microsoft.com/en-us/research/publication/algorithm-strategy-parallelism/},
  urldate = {2020-08-02},
  abstract = {The process of writing large parallel programs is complicated by the eed to specify both the parallel behaviour of the program and the algorithm that is to be used to compute its result. This paper introduces evaluation strategies: lazy higher-order functions that control the parallel evaluation of non-strict functional languages. Using evaluation strategies, it is […]},
  langid = {american}
}
% == BibTeX quality report for trinderAlgorithmStrategyParallelism1998:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("www.microsoft.com")

@article{venturiniReductionGraphsLambda1983,
  title = {Reduction {{Graphs}} in the {{Lambda Calculus}}},
  author = {Venturini, Marisa},
  year = {1983},
  month = apr,
  pages = {25},
  abstract = {In this paper properties of the reduction graphs of lambda terms arc studied and some classes of reduction graphs are ch*lwcterized. Condensed reduction graphs obtained by dividing out ‘cyclic equivalence‘, and spectr.t, the partially ordered set of all reductions, are also considered. The partial ordering in the spectru n can be seen as a measure for the ‘significance’ of B reduction; reductions to the normal form an 1 (nxre generall;\textasciitilde ) cofinal reductions are the most significant reductions. The spectrum is prow 3 to be the completion of the condensed reduction graph.},
  langid = {english}
}
% == BibTeX quality report for venturiniReductionGraphsLambda1983:
% Missing required field 'journal'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@incollection{voigtlanderAsymptoticImprovementComputations2008,
  title = {Asymptotic {{Improvement}} of {{Computations}} over {{Free Monads}}},
  booktitle = {Mathematics of {{Program Construction}}},
  author = {Voigtländer, Janis},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  volume = {5133},
  pages = {388--403},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  issn = {0302-9743, 1611-3349},
  doi = {10.1007/978-3-540-70594-9_20},
  url = {https://www.janis-voigtlaender.eu/papers/AsymptoticImprovementOfComputationsOverFreeMonads.pdf},
  urldate = {2021-07-09},
  abstract = {We present a low-effort program transformation to improve the efficiency of computations over free monads in Haskell. The development is calculational and carried out in a generic setting, thus applying to a variety of datatypes. An important aspect of our approach is the utilisation of type class mechanisms to make the transformation as transparent as possible, requiring no restructuring of code at all. There is also no extra support necessary from the compiler (apart from an up-to-date type checker). Despite this simplicity of use, our technique is able to achieve true asymptotic runtime improvements. We demonstrate this by examples for which the complexity is reduced from quadratic to linear.},
  isbn = {978-3-540-70593-2 978-3-540-70594-9},
  langid = {english}
}
% == BibTeX quality report for voigtlanderAsymptoticImprovementComputations2008:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Series title ("Lecture Notes in Computer Science")

@inproceedings{wadlerCallbyvalueDualCallbyname2003,
  ids = {wadlerCallbyValueDualCallbyName},
  title = {Call-by-Value Is Dual to Call-by-Name},
  booktitle = {Proceedings of the Eighth {{ACM SIGPLAN}} International Conference on {{Functional}} Programming},
  author = {Wadler, Philip},
  year = {2003},
  month = aug,
  series = {{{ICFP}} '03},
  pages = {189--201},
  publisher = {{Association for Computing Machinery}},
  address = {{Uppsala, Sweden}},
  doi = {10.1145/944705.944723},
  url = {http://homepages.inf.ed.ac.uk/wadler/papers/dual/dual.pdf},
  urldate = {2020-06-17},
  abstract = {The rules of classical logic may be formulated in pairs corresponding to De Morgan duals: rules about \& are dual to rules about V. A line of work, including that of Filinski (1989), Griffin (1990), Parigot (1992), Danos, Joinet, and Schellinx (1995), Selinger (1998,2001), and Curien and Herbelin (2000), has led to the startling conclusion that call-by-value is the de Morgan dual of call-by-name.This paper presents a dual calculus that corresponds to the classical sequent calculus of Gentzen (1935) in the same way that the lambda calculus of Church (1932,1940) corresponds to the intuitionistic natural deduction of Gentzen (1935). The paper includes crisp formulations of call-by-value and call-by-name that are obviously dual; no similar formulations appear in the literature. The paper gives a CPS translation and its inverse, and shows that the translation is both sound and complete, strengthening a result in Curien and Herbelin (2000).},
  isbn = {978-1-58113-756-9},
  keywords = {Curry-Howard correspondence,De Morgan dual,lambda calculus,lambda mu calculus,logic,natural deduction,sequent calculus}
}
% == BibTeX quality report for wadlerCallbyvalueDualCallbyname2003:
% ? Unsure about the formatting of the booktitle
% ? unused Conference name ("International Conference on Functional Programming")
% ? unused Library catalog ("ACM Digital Library")

@inproceedings{wadlerEssenceFunctionalProgramming1992,
  title = {The Essence of Functional Programming},
  booktitle = {Proceedings of the 19th {{ACM SIGPLAN-SIGACT}} Symposium on {{Principles}} of Programming Languages  - {{POPL}} '92},
  author = {Wadler, Philip},
  year = {1992},
  pages = {1--14},
  publisher = {{ACM Press}},
  address = {{Albuquerque, New Mexico, United States}},
  doi = {10.1145/143165.143169},
  url = {http://portal.acm.org/citation.cfm?doid=143165.143169},
  urldate = {2021-11-22},
  abstract = {This paper explores the use monads to structure functional programs. No prior knowledge of monads or category theory is required. Monads increase the ease with which programs may be modified. They can mimic the effect of impure features such as exceptions, state, and continuations; and also provide effects not easily achieved with such features. The types of a program reflect which effects occur.},
  isbn = {978-0-89791-453-6},
  langid = {english}
}
% == BibTeX quality report for wadlerEssenceFunctionalProgramming1992:
% ? Unsure about the formatting of the booktitle
% ? unused Conference name ("the 19th ACM SIGPLAN-SIGACT symposium")
% ? unused Library catalog ("DOI.org (Crossref)")

@article{wheelerFullyCounteringTrusting2010,
  title = {Fully Countering Trusting Trust through Diverse Double-Compiling},
  author = {Wheeler, David A.},
  year = {2010},
  month = apr,
  journal = {arXiv:1004.5534 [cs]},
  eprint = {1004.5534},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1004.5534},
  urldate = {2020-09-13},
  abstract = {An Air Force evaluation of Multics, and Ken Thompson's Turing award lecture ("Reflections on Trusting Trust"), showed that compilers can be subverted to insert malicious Trojan horses into critical software, including themselves. If this "trusting trust" attack goes undetected, even complete analysis of a system's source code will not find the malicious code that is running. Previously-known countermeasures have been grossly inadequate. If this attack cannot be countered, attackers can quietly subvert entire classes of computer systems, gaining complete control over financial, infrastructure, military, and/or business systems worldwide. This dissertation's thesis is that the trusting trust attack can be detected and effectively countered using the "Diverse Double-Compiling" (DDC) technique, as demonstrated by (1) a formal proof that DDC can determine if source code and generated executable code correspond, (2) a demonstration of DDC with four compilers (a small C compiler, a small Lisp compiler, a small maliciously corrupted Lisp compiler, and a large industrial-strength C compiler, GCC), and (3) a description of approaches for applying DDC in various real-world scenarios. In the DDC technique, source code is compiled twice: the source code of the compiler's parent is compiled using a trusted compiler, and then the putative compiler source code is compiled using the result of the first compilation. If the DDC result is bit-for-bit identical with the original compiler-under-test's executable, and certain other assumptions hold, then the compiler-under-test's executable corresponds with its putative source code.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Programming Languages}
}
% == BibTeX quality report for wheelerFullyCounteringTrusting2010:
% ? Possibly abbreviated journal title arXiv:1004.5534 [cs]

@article{wikipediaForwardBackwardAlgorithm2020,
  title = {Forward–Backward Algorithm},
  author = {{Wikipedia}},
  year = {2020},
  month = jul,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Forward%E2%80%93backward_algorithm&oldid=966683884},
  urldate = {2020-07-08},
  abstract = {The forward–backward algorithm is an  inference algorithm for hidden Markov models which computes the posterior marginals of all hidden state variables given a sequence of observations/emissions                                    o                        1             :             T                             :=                    o                        1                             ,         …         ,                    o                        T                                     \{\textbackslash displaystyle o\_\{1:T\}:=o\_\{1\},\textbackslash dots ,o\_\{T\}\}   , i.e. it computes, for all hidden state variables                                    X                        t                             ∈         \{                    X                        1                             ,         …         ,                    X                        T                             \}                 \{\textbackslash displaystyle X\_\{t\}\textbackslash in \textbackslash\{X\_\{1\},\textbackslash dots ,X\_\{T\}\textbackslash\}\}   , the distribution                         P         (                    X                        t                                                  |                                       o                        1             :             T                             )                 \{\textbackslash displaystyle P(X\_\{t\}\textbackslash{} |\textbackslash{} o\_\{1:T\})\}   . This inference task is usually called smoothing. The algorithm makes use of the principle of dynamic programming to efficiently compute the values that are required to obtain the posterior marginal distributions in two passes. The first pass goes forward in time while the second goes backward in time; hence the name forward–backward algorithm. The term forward–backward algorithm is also used to refer to any algorithm belonging to the general class of algorithms that operate on sequence models in a forward–backward manner. In this sense, the descriptions in the remainder of this article refer but to one specific instance of this class.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 966683884}
}

@article{wikipediaLogit2020,
  title = {Logit},
  author = {{Wikipedia}},
  year = {2020},
  month = jun,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Logit&oldid=964387041},
  urldate = {2020-07-07},
  abstract = {In statistics, the logit ( LOH-jit) function or the log-odds is the logarithm of the odds                                                 p                            1               −               p                                                  \{\textbackslash displaystyle \{\textbackslash frac \{p\}\{1-p\}\}\}    where p is probability. It is a type of function that creates a map of probability values from                         (         0         ,         1         )                 \{\textbackslash displaystyle (0,1)\}    to                         (         −         ∞         ,         +         ∞         )                 \{\textbackslash displaystyle (-\textbackslash infty ,+\textbackslash infty )\}   . It is the inverse of the sigmoidal "logistic" function or logistic transform used in mathematics, especially in statistics. In deep learning, the term logits layer is popularly used for the last neuron layer of neural networks used for classification tasks, which produce raw prediction values as real numbers ranging from                         (         −         ∞         ,         +         ∞         )                 \{\textbackslash displaystyle (-\textbackslash infty ,+\textbackslash infty )\}   .},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 964387041}
}

@phdthesis{zeilbergerLogicalBasisEvaluation2009,
  title = {The Logical Basis of Evaluation Order and Pattern-Matching},
  author = {Zeilberger, Noam},
  year = {2009},
  month = apr,
  address = {{Pittsburgh, PA}},
  url = {https://software.imdea.org/~noam.zeilberger/thesis.pdf},
  langid = {english},
  school = {Carnegie Mellon University}
}
% == BibTeX quality report for zeilbergerLogicalBasisEvaluation2009:
% ? unused Archive location ("CMU-CS-09-122")
% ? unused Library catalog ("Zotero")
% ? unused Number of pages ("203")

@inproceedings{ziftciWhoBrokeBuild2017,
  title = {Who Broke the Build? {{Automatically}} Identifying Changes That Induce Test Failures in Continuous Integration at {{Google}} Scale},
  shorttitle = {Who Broke the Build?},
  booktitle = {2017 {{IEEE}}/{{ACM}} 39th {{International Conference}} on {{Software Engineering}}: {{Software Engineering}} in {{Practice Track}} ({{ICSE-SEIP}})},
  author = {Ziftci, Celal and Reardon, Jim},
  year = {2017},
  month = may,
  pages = {113--122},
  publisher = {{IEEE}},
  address = {{Buenos Aires}},
  doi = {10.1109/ICSE-SEIP.2017.13},
  url = {https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45794.pdf},
  urldate = {2020-07-06},
  abstract = {Quickly identifying and fixing code changes that introduce regressions is critical to keep the momentum on software development, especially in very large scale software repositories with rapid development cycles, such as at Google. Identifying and fixing such regressions is one of the most expensive, tedious, and time consuming tasks in the software development life-cycle. Therefore, there is a high demand for automated techniques that can help developers identify such changes while minimizing manual human intervention. Various techniques have recently been proposed to identify such code changes. However, these techniques have shortcomings that make them unsuitable for rapid development cycles as at Google. In this paper, we propose a novel algorithm to identify code changes that introduce regressions, and discuss case studies performed at Google on 140 projects. Based on our case studies, our algorithm automatically identifies the change that introduced the regression in the top-5 among thousands of candidates 82\% of the time, and provides considerable savings on manual work developers need to perform.},
  isbn = {978-1-5386-2717-4},
  langid = {english}
}
% == BibTeX quality report for ziftciWhoBrokeBuild2017:
% ? unused Conference name ("2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)")
% ? unused Library catalog ("DOI.org (Crossref)")


