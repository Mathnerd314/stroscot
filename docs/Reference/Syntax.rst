Syntax
######

Almost everything in Stroscot is an expression. Values are numbers, booleans, and character strings of text. But there's also block statements and layout.

Unicode
=======

Practically, most programs will use ASCII. But the Unicode algorithms are robust and supporting other languages isn't too hard. `Lots of languages <https://rosettacode.org/wiki/Unicode_variable_names>`__ have support for Unicode, although the exact set of allowed characters varies.

* Start with bytes. Decode using UTF-8, replacing invalid bytes/characters with Unicode's REPLACEMENT CHARACTER U+FFFD.
* `NFC <http://unicode.org/reports/tr15/#Norm_Forms>`__ normalize the input, warning if input isn't normalized. There is enough software that automatically normalizes to NFC (e.g. web browsers) that it seems safe to require NFC; bugs can be worked around by changing the input (inserting joiners) rather than modifying NFC.
* A warning for weird scripts (listed in `TR31 <http://www.unicode.org/reports/tr31/#Table_Candidate_Characters_for_Exclusion_from_Identifiers>`__) or zero-width characters.

Some combination of the following algorithms to do lexical analysis:
* `line-breaking <https://www.unicode.org/reports/tr14/#BreakingRules>`__ (specifically, to determine hard / mandatory breaks)
* `word-breaking <http://www.unicode.org/reports/tr29/#Word_Boundary_Rules>`__ to split up lines into tokens - it needs to be extended to account for program identifiers / multicharacter symbols
* `identifier syntax <https://www.unicode.org/reports/tr31/#Default_Identifier_Syntax>`__, which specifies sets of valid identifier start/continue characters

Stroscot is case-sensitive.

Layout
======

The most obvious is the initial declaration list, but other constructs introduce clauses as well. For readability, clauses may span multiple lines, so some way of distingishing the start / end of clauses must be defined. Generally, this amounts to adding braces and semicolons so as to make it layout-insensitive. The braces are virtual braces; they don't match with explicit braces.

::

  assertEqual
    {
      a
        b
        c
      d
    }
    { a {b; c}; d}

Generally, behavior of a new line depends on its indentation level, relative to the indentation of the previous line:

* if it is indented more, it's a sequence given as an argument to the previous line, so a virtual open brace is inserted
* if it is at the same level, another item in the sequence, so a (virtual) semicolon is inserted
* if there is a (nonempty) line at lower indentation (or EOF), the sequence is ended as it's a new declaration (`offside rule <https://en.wikipedia.org/wiki/Off-side_rule>`__). A virtual close brace is inserted at the start of the line.

Indentation level is taken to be the sequence of whitespace characters, so "space, tab, space" is different from (incomparable to) "tab, space, space" but is less than "space, tab, space, em space" and more than "space, tab".

Layout handling is complicated by the presence of grammar rules without layout that allow free choice of indentation, e.g.

::

  assertEqual
    a
      + b
      + c
    a {+ b; + c}
    a + (b + c)

It should be possible to handle these with a fixup phase.

Also, closed operators (e.g. parentheses) inhibit layout; this amounts to skipping whitespace layout when inside an explicit delimiter pair. But of course constructs inside the delimiter pair can start another layout. Finally for constructs that usually use layout we still want to parse 1-line things without braces:

::

  assertEqual
    let a = b in c
    let { a = b } in c

Parsing
=======

I've got a basic Earley algorithm working for now. But eventually I'm extending it with BSRs and layout and other fun things. There's also `Yakker <https://github.com/attresearch/yakker>`__, which is the most developed parser I've seen feature-wise. It's only missing incremental parsing.

  A new parsing engine, Yakker, capable of handling the requirements of modern applications including full scannerless context-free grammars with regular expressions as right-hand sides for defining nonterminals. Yakker also includes facilities for binding variables to intermediate parse results and using such bindings within arbitrary constraints to control parsing. Yakker supports both semantic actions and speculative parsing techniques such as backtracking and context-free lookahead and several parsing back ends (including Earley, GLR and backtracking).  In addition, nonterminals may be parameterized by arbitrary values, which gives the system good modularity and abstraction properties in the presence of data-dependent parsing. Finally, legacy parsing libraries, such as sophisticated libraries for dates and times, may be directly incorporated into parser specifications.

I've looked at various algorithms but I think the only way to handle it completely correctly and generically is to have a disambiguating pass on the set of parse tree generated by a nondeterministic automaton. The alternatives involve restricting parsers to be deterministic, for example PEGs. But PEGs have big issues with error detection and reporting, not to mention correct parsing. There's just no information on what possible parses are available or what token is expected. Whereas with Earley you can do "Ruby slippers": scan the sets for what they want next, output "warning: expected ';' at end of statement", and then add that to the parse forest and continue parsing with almost no overhead.

Treesitter implements incremental LR parsing with error recovery, but since it doesn't support ambiguity I don't think it's sufficient for a compiler.

Revisiting this, the goal is to use partial evaluation to generate the parser, by speeding up a naive brute-force algorithm applied to the grammar. There is already a paper on LR parsing by partial evaluation :cite:`sperberGenerationLRParsers2000` and also on specializing Earley, so with sufficiently powerful compiler optimization handling general grammars should be possible.

In particular the parser should be written as a nondeterministic finite state transducer that builds up trees (outputs a list in the style of start-children-end or S-expressions or something).

Formally:

    Q is a finite set, the set of states;
    I is a subset of Q, the set of initial states;
    F is a subset of Q, the set of final states; and
    Σ is a finite set, called the input alphabet;
    Γ is a finite set, called the output alphabet;
    The transition function is of type :math:`Q \times (\Sigma \cup \{\epsilon \})\to P(Q \times (\Gamma \cup \{\epsilon \}))`, where ε is the empty string and P(Q) denotes the power set of Q.

TODO: match this up with Parsec, attoparsec, trifecta, etc. the syntax should be similar except with nondeterministic choice ``|``.

Operators
---------

Operator precedence will be a poset, rather than levels.

::

  precedence _*_ higher than _+_
  precedence _/_ equals _*_

Stroscot supports your typical PEMDAS:

::

  assertEqual
    1 + 2 * 3^2
    19
  assertEqual
    3+1/(7+1/(15+1/1))
    355/113
    3.14159292035...

Most other operators are textual:

::

  assert
    true and false == false
    true or false == true
    true xor true == false
    5 div 2 == 2
    5 mod 2 == 1

New operators can be declared with `mix <http://www.cse.chalmers.se/~nad/publications/danielsson-norell-mixfix.pdf>`__ `fix <http://www.bramvandersanden.com/publication/pdf/sanden2014thesis.pdf>`__ semantics, e.g.

::

   syntax _&&_ associate left above _and_ _or_ _not_ below _||_

Umatched Parentheses
--------------------

For brevity, trailing parentheses can be omitted:

::

  assertEqual
    3+1/(7+1/(15+1/1
    355/113

Although it parses, you can set Stroscot to warn or error on
unmatched parentheses, or run the code formatter which will add them.

Chained Comparison
------------------

::

  assert
    1 <= 2 < 3
    9 > 2 < 3

Variables
=========

There is no kind of syntax or semantics for changing or redefining identifiers (besides :ref:`fexprs <fexprs>`); you can shadow, with warning, but once an identifier is declared in a scope, that's what that identifier refers to for the duration of the scope. OTOH references behave pretty much like mutable variables.

::

  a = mut 1
  a := 2
  raise a by 1

Mutable assignment (``:=``) is completely distinct from name binding (``=``). They have distinct notation.


Functions
=========

::

  f 1 = 1
  f 2 = 2
  f y | y != 1 && y != 2 = 3

::

  f
  | 1 y = 1
  | x 2 = 2
  | x y = 3

Patterns
--------

Patterns all compile to guard conditions on ``$args``. They also check that the arity of ``$args`` is the number of patterns.

::

  _ --> True -- wildcard
  a --> if a then $arga[0] == a else True -- matches symbol a, or binds a if a is not defined
   _a --> True -- hole, binds a even if a is an existing symbol
  ^a --> $args[i] == a -- matches the atom a
  ^f a b c --> $args[0] == f && $args.length >= 4 # matches the symbol tree with atom f
   _f a --> $args.length >= 2 # matches any symbol tree besides a single atom
  [(1, "x"), {c: 'a'}] -> $args[i] == [(1, "x"), {c: 'a'}] -- literal match
  [1, ..., 2] --> $args[i][0] == 1 && $args[i][-1] == 2 -- matches any list starting with 1 and ending with 2
  {a: 1, ...} --> $args[a] == 1 # matches a and the rest of the record
   pat1 AND pat2 --> match $args pat1 and match $args pat2 # matches both patterns simultaneously
   pat1 OR pat2 --> match $args pat1 or match $args pat2 # matches either pattern
  ~pat --> True # desugars to f u_ ... = let pat = u_ in ..., where u_ is a unique name
  (a : b) --> a elemOf b # type tag
  a | f a --> f a # guard, arbitrary function
  (f -> a) --> match (f $args[i]) a # view pattern

Pattern synonyms

::

   pattern F a b = ["f",a,b]

Inline definitions
------------------

Patterns can be made inline; they are lifted to the closest scope that allows definitions.

::

   range = sqrt((dx=x1-x0)*dx + (dy=y1-y0)*dy)

  -- translates to
   dx=x1-x0
   dy=y1-y0
   range = sqrt(dx*dx + dy*dy)


Keyword arguments
-----------------

::

   foo w x y z = z - x / y * w

  v = foo (y:2) (x:4) (w:1) (z:0)
  # 0-4/2*1
  v == foo {x:4,y:2,w:1,z:0}
  # true

Positional arguments
--------------------

::

  v == foo 1 4 2 0
  # true

You can mix positional and keyword arguments freely; positions are
assigned to whatever is not a keyword argument.

::

  v == foo {z:0} {w:1} 4 2
  # true

Arguments are curried:

::

  c y = y+10
  b x = c

  b 2 1
  # 11

Implicit arguments
------------------

These behave similarly to arguments in languages with dynamical scoping.

::

  -- standard library
   log s = if (priority > loglevel) { logPrint s }

  -- components of an application
   foo = log "foo" { priority = DEBUG }
   bar = log "bar" { priority = WARNING }
   baz =
    foo
    bar

  -- main file
   logPrint x = writeFile file x
   file = "a"
   loglevel = WARNING

   main =
     baz
     foo {loglevel=DEBUG}

Positional arguments can be passed implicitly, but this is inhibited by using positional arguments:

::

   foo w x y z = z - x / y * w
   bar = foo + 2
   baz a = bar {x:4,y:2} - a

  ((0-4/2*1)+2)-5 == baz 5 {z:0,w:1}
  # true
   baz 1 2 3 4 5
  # Error: too many arguments to baz, expected [a]

Similarly keyword arguments inhibit passing down that keyword
implicitly:

::

  a k = 1
  b k = k + a

  b {k:2}
  # Error: no definition for k given to a

A proper definition for b would either omit k or pass it explicitly to a:

::

  a k = 1
  b = k + a
  b' k = k + a k

  b {k:2} == b' {k:2}
  # true

For functions with no positional arguments, positions are assigned
implicitly left-to-right:

::

  a = x / y + y
  a 4 1
  # 5

Atoms that are in lexical scope are not assigned positions, hence (/)
and (+) are not implicit positional arguments for a in the example
above. But they are implicit keyword arguments:

::

  a = x / y + y
  assert
    a {(+):(-)} 4 1
    == 4/1-1
    == 3

The namespace scoping mechanism protects against accidental use in large
projects.

Default arguments
-----------------

::

  a {k:1} = k + 1
  a # 2

Modula-3 added keyword arguments and default arguments to Modula-2. But I think they also added a misfeature: positional arguments with default values. In particular this interacts very poorly with currying. If ``foo`` is a function with two positional arguments, the second of them having a default value, then ``foo a b`` is either passing ``b`` to the result of ``f a`` or overriding the default value of the second argument. So specifying/overriding default arguments always requires the use of keyword syntax.

Implicit arguments use keywords as well, so they override default arguments:

::

  a {k:1} = k
  b = a
  c = b {k:2}
  c # 2

Output arguments
----------------

::

  b = out {a:3}; 2
  b + a
  # 5

Output arguments can chain into implicit arguments, so you get something like the state monad:

::

   inc {x} = out {x:x+1}

  x = 1
   inc
  x # 2

It might be worth having a special keyword ``inout`` for this.

Variadic arguments
------------------

Positional variadic arguments:

::

  c = sum $arguments
  c 1 2 3
  # 6
  c {$arguments=[1,2]}
  # 3

Only syntactically adjacent arguments are passed, e.g.

::

  (c 1 2) 3
  # error: 3 3 is not reducible

  a = c 1
  b = a 2
  # error: 1 2 is not reducible

There are also variadic keyword arguments:

::

  s = print $kwargs
  s {a:1,b:2}
  # {a:1,b:2}

Concatenative arguments
-----------------------

Results not assigned to a variable are pushed to a stack:

::

  1
  2
  3

  %stack
  # 1 2 3

``%`` is the most recent result, with ``%2`` ``%3`` etc. referring to
less recent results:

::

  {a = 1}
   extend % {b=2}
   extend % {c=3}
   shuffle
   # {b=2,a=1,c=3}

These stack arguments are used for positional arguments when not
supplied.

Inheritance
-----------

The general idea of inheritance is, for ``Foo`` a child of ``Bar`` to rewrite calls ``exec (Foo ...) a b`` to calls ``exec (Bar ...) a b``, and this can be automated with a macro:

::

  inherit foopat barpat barmethodlist = {
    for (m : barmethodlist) {
      m foopat = m barpat
    }
  }

Lambdas
=======

::

  \a b -> stuff
  \a b. stuff
  lambda {
    a 1 = stuff
    a 2 = other
  }

Pattern-matching
----------------

``match`` is an expression:

::

  f = match (2+2) (5+5) | x y = 2
                        | 1 y = 2

It desugars to a lambda applied to the arguments.


Reduce similarly reduces an expression to normal form using some rules:

::

  reduce x
    x = y
    y = z
  # z

Blocks
======

::

  x = input number
   display x

   foo =
     x = 0
     x += 1
     provide x

   obtain http_server
   main =
     parse_args
     build_folder
     http_server.serve(folder)

The translation rules are based on the continuation monad:

::

  {e} = e
  {e;stmts} = \c -> e ({stmts} c) = e . {stmts}
  {p <- e; stmts} = \c -> e (\x -> (\p -> {stmts}) x c) = e >>= {stmts}

Bang notation
-------------

::

  { f !(g !(print y) !x) }

  // desugars to
  {
    t1 <- print y
    t2 <- x
    t3 <- g t1 t2
    f t3
  }

The notation ``!expr`` within a block means that the expression ``expr`` should be bound in the block to a temporary before computing the surrounding expression. The expression is bound in the nearest enclosing block.
Expressions are lifted leftmost innermost.

Monad comprehensions
--------------------

::

  Expressions: e
  Declarations: d
  Lists of qualifiers: Q,R,S
  Qv is the tuple of variables bound by Q (and used subsequently)
  selQvi is a selector mapping Qv to the ith component of Qv

  -- Basic forms
  D[ e | ] = return e
  D[ e | p <- e, Q ]  =
    p <- e
    D[ e | Q ]
  D[ e | e, Q ] =
    p <- guard e
    D[ e | Q ]
  D[ e | let d, Q ] =
    let d
    D[ e | Q ]

  -- Parallel comprehensions (iterate for multiple parallel branches)
  D[ e | (Q | R), S ] =
    (Qv,Rv) <- mzip D[ Qv | Q ] D[ Rv | R ]
    D[ e | S ]

  -- Transform comprehensions
  D[ e | Q then f, R ] =
    Qv <- f D[ Qv | Q ]
    D[ e | R ]

  D[ e | Q then f by b, R ] =
    Qv <- f (\Qv -> b) D[ Qv | Q ]
    D[ e | R ]

  D[ e | Q then group using f, R ] =\
    ys <- f D[ Qv | Q ]
    let Qv = (fmap selQv1 ys, ..., fmap selQvn ys)
    D[ e | R ]

  D[ e | Q then group by b using f, R ] =
    ys <- f (\Qv -> b) D[ Qv | Q ]
    let Qv = (fmap selQv1 ys, ..., fmap selQvn ys)
    D[ e | R ]



Control structures
==================

These are things that can show up in blocks and have blocks as arguments.

::

  a = if true then 1 else 2 -- just a function if_then_else : Bool -> a -> a -> a
  x = emptyRef; if true { x := 1 } else { x := 2 }; print x -- if on blocks
  repeat while x > 0 { x -= 1 }
  repeat until x == 0 { x -= 1 }
  repeat 10 times { x -= 1 }
  repeat { x -= 1 } while x > 0
  repeat
    x = x * 2
    if (x % 2 == 0)
      break

::

  check {
     risky_procedure
  } error {
     fix(error) or error("wtf")
  } regardless {
     save_logs
  }

More here: https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/computation-expressions

Programs
========

A program is a block, and every declaration is a macro or control structure.

So for example you can implement a conditional definition:

::

   if condition
      a = 1
   else
      a = 2


Comments
========

::

  // comment
  /* multiline
      comment */
  {- nesting {- comment -} -}
   if(false) { code_comment - lexed but not parsed except for start/end }
  #! shebang at beginning of file

Type declarations
=================

::

  a = 2 : s8
  a = s8 2

DSL
===

Stroscot aims to be a "pluggable" language, where you can write syntax, type checking, etc. for a DSL.
Due to the fexpr semantics any expression can be used and pattern-matched, like ``javascript (1 + "abc" { 234 })``.

E.g. we could write a small DSL like SQL and then use it in a larger program with some embedding syntax.

::

  run_sql_statement { SELECT ... }

The idea extends further, embedding lower-level and incompatible languages like assembly and C++.

::

  result = asm { sumsq (toregister x), (toregister y) }
  my_func = load("foo.cpp").lookup("my_func")

Another useful one might be TeX / mathematical expressions:

::

   tex { result = ax^4+cx^2 }
   math { beta = phi lambda }

These are particularly useful with functions that fuse multiple operations such as expmod and accuracy optimizers that figure out the best way to stage a computation.


Namespacing
===========

Identifiers can be qualified by periods: ``a.b.c``. ``.`` is an infix left-associative operator that binds tighter than juxtaposition.
